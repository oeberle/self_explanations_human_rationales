{"content": "Beautifully crafted, engaging filmmaking that should attract upscale audiences hungry for quality and a nostalgic, twisty yarn that will keep them guessing.", "true_label": 1, "gold_label_rationales": [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_0": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Beautifully crafted, engaging filmmaking that should attract upscale audiences hungry for quality and a nostalgic, twisty yarn that will keep them guessing. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_0": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 27315, 1114, 10717, 1054, 29493, 20407, 3734, 15495, 1137, 1791, 7610, 1350, 6473, 25228, 17928, 1122, 4813, 1072, 1032, 19866, 13162, 1062, 29493, 21514, 29492, 1105, 2099, 1137, 1390, 2608, 1474, 5870, 1056, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.40625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"beautifully\"}, {\"rationales\": \"engaging\"}, {\"rationales\": \"quality\"}]"}
{"content": "Bread, My Sweet has so many flaws it would be easy for critics to shred it.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_1": "(b) This review is overall rather negative. The statement \"so many flaws it would be easy for critics to shred it\" suggests that the movie has multiple significant issues.", "annotation_request": "Consider the following movie review: Bread, My Sweet has so many flaws it would be easy for critics to shred it. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_1": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1133, 1691, 29493, 2752, 23361, 1427, 1347, 2055, 1740, 6963, 1146, 1450, 1115, 4179, 1122, 21325, 1066, 1248, 1661, 1146, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"flaws\"},\n{\"rationales\": \"shred\"},\n{\"rationales\": \"critics\"},\n{\"rationales\": \"easy\"},\n{\"rationales\": \"shred\"},\n{\"rationales\": \"it\"},\n{\"rationales\": \"so\"},\n{\"rationales\": \"many\"},\n{\"rationales\": \"flaws\"}\n]"}
{"content": "Ultimately feels empty and unsatisfying, like swallowing a Communion wafer without the wine.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_2": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Ultimately feels empty and unsatisfying, like swallowing a Communion wafer without the wine. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_2": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 20344, 10575, 9083, 5374, 1072, 10982, 28614, 3751, 29493, 1505, 26761, 1056, 1032, 6563, 1064, 7846, 1410, 2439, 1040, 8956, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.15625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"empty\"]}, {\"rationales\": [\"unsatisfying\"]}]"}
{"content": "Exudes the fizz of a Busby Berkeley musical and the visceral excitement of a sports extravaganza.", "true_label": 1, "gold_label_rationales": [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], "response_3": "(a) This review is overall rather positive. The use of the words \"fizz,\" \"Busby Berkeley musical,\" and \"visceral excitement\" suggest the reviewer found the movie energizing, lively, and entertaining. The comparison to a sports extravaganza implies a sense of thrill and exhilaration. These are generally positive adjectives and indicators that the reviewer enjoyed the film.", "annotation_request": "Consider the following movie review: Exudes the fizz of a Busby Berkeley musical and the visceral excitement of a sports extravaganza. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_3": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2297, 6655, 1040, 1053, 6537, 1070, 1032, 6882, 2171, 28810, 9926, 1072, 1040, 2485, 3510, 1050, 17931, 1070, 1032, 9425, 10005, 1262, 13306, 2934, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.046875], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"fizz\"},\n{\"rationales\": \"Busby Berkeley musical\"},\n{\"rationales\": \"visceral excitement\"},\n{\"rationales\": \"sports extravaganza\"},\n{\"rationales\": \"enjoyed\"}\n]"}
{"content": "The film rehashes several old themes and is capped with pointless extremes -- it's insanely violent and very graphic.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0], "response_4": "(b) This review is overall rather negative. The review mentions that the film rehashes old themes and ends with unnecessary extremes, implying that it is insanely violent and graphic. These are generally unfavorable characteristics in a movie review.", "annotation_request": "Consider the following movie review: The film rehashes several old themes and is capped with pointless extremes -- it's insanely violent and very graphic. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_4": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 1080, 4305, 2821, 3624, 2339, 19746, 1072, 1117, 1045, 4622, 1163, 2073, 2271, 6983, 1042, 2707, 1146, 29510, 29481, 2256, 1044, 1491, 15411, 1072, 1983, 23461, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.046875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"rehashes\"},\n{\"rationales\": \"pointless\"},\n{\"rationales\": \"insanely\"},\n{\"rationales\": \"graphic\"}\n]"}
{"content": "Ryan Gosling is, in a word, brilliant as the conflicted Daniel.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "response_5": "(a) This review is overall rather positive. The use of \"brilliant\" suggests a high level of praise for Ryan Gosling's performance in the movie. The term \"conflicted Daniel\" also suggests that the character is complex and well-portrayed, further supporting a positive review.", "annotation_request": "Consider the following movie review: Ryan Gosling is, in a word, brilliant as the conflicted Daniel. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_5": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 13962, 1188, 1153, 2673, 1117, 29493, 1065, 1032, 2475, 29493, 15192, 1158, 1040, 11086, 1054, 8871, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.421875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"brilliant\"}]"}
{"content": "The film often achieves a mesmerizing poetry.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1], "response_6": "(a) This review is overall rather positive. The use of the words \"mesmerizing poetry\" suggests that the reviewer finds the film to be beautiful, captivating, and perhaps even profound.", "annotation_request": "Consider the following movie review: The film often achieves a mesmerizing poetry. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_6": 1, "relevance_lrp": [15.734375, 0.00026488304138183594, 0.25927734375, 0.06805419921875, 0.25537109375, -0.041656494140625, 0.1322021484375, 0.1536865234375, 0.030303955078125, -0.037353515625, 0.0797119140625, -0.0178375244140625, 0.0128936767578125, -0.0667724609375, -0.045684814453125, -0.0261383056640625, 0.02667236328125, -0.07476806640625, -0.01788330078125, -0.2017822265625, 1.59375, 0.1400146484375, 0.25146484375, 0.156982421875, 0.10662841796875, 0.1114501953125, 0.392822265625, 0.4052734375, 0.0693359375, -0.004222869873046875, 0.147216796875, 0.5263671875, 0.2254638671875, 0.087646484375, 0.3662109375, 0.7548828125, 0.4130859375, 0.1654052734375, 0.395263671875, 1.1005859375, 2.052734375, 0.2188720703125, -0.0120086669921875, 0.1610107421875, 0.04364013671875, 0.135986328125, 0.0899658203125, 0.2452392578125, 0.1527099609375, 0.1304931640625, 0.1741943359375, 0.89697265625, 0.05706787109375, 0.0144195556640625, 0.01556396484375, 0.0163726806640625, 0.0218505859375, 0.0137176513671875, 0.04656982421875, 0.049835205078125, 0.08087158203125, 0.23779296875, 0.240478515625, 0.1961669921875, 0.03369140625, 2.654296875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 3376, 5278, 2623, 1032, 6740, 1562, 4632, 16659, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"mesmerizing\"}, {\"rationales\": \"poetry\"}]"}
{"content": "A work of astonishing delicacy and force.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 1], "response_7": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A work of astonishing delicacy and force. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_7": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1539, 1070, 21779, 6364, 1650, 1062, 3194, 1072, 5042, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"astonishing\"}, {\"rationales\": \"delicacy\"}, {\"rationales\": \"force\"}]"}
{"content": "The movie's plot is almost entirely witless and inane, carrying every gag two or three times beyond its limit to sustain a laugh.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], "response_8": "(b) This review is overall rather negative. The repeated use of words like \"witless\" and \"inane\" in relation to the plot, as well as \"gags being carried beyond their limit,\" suggest a critique of the movie. The use of phrases such as \"sustain a laugh\" often imply an attempt that falls short of its objective.", "annotation_request": "Consider the following movie review: The movie's plot is almost entirely witless and inane, carrying every gag two or three times beyond its limit to sustain a laugh. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_8": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 29510, 29481, 10010, 1117, 3547, 8902, 1043, 1047, 2271, 1072, 1065, 2332, 29493, 11607, 1780, 1087, 1125, 1757, 1210, 2480, 3189, 6066, 1639, 4375, 1066, 12523, 1032, 6531, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.21875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"witless\"},\n{\"rationales\": \"inane\"},\n{\"rationales\": \"carrying\"},\n{\"rationales\": \"beyond\"},\n{\"rationales\": \"limit\"},\n{\"rationales\": \"sustain\"}\n]"}
{"content": "The acting is stiff, the story lacks all trace of wit, the sets look like they were borrowed from Gilligan's Island -- and the CGI Scooby might well be the worst special-effects creation of the year.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], "response_9": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The acting is stiff, the story lacks all trace of wit, the sets look like they were borrowed from Gilligan's Island -- and the CGI Scooby might well be the worst special-effects creation of the year. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_9": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 11369, 1117, 17284, 29493, 1040, 3606, 6270, 29481, 1312, 11486, 1070, 1043, 1047, 29493, 1040, 7259, 1681, 1505, 1358, 1422, 14987, 1054, 1245, 25472, 10032, 29510, 29481, 8401, 2707, 1072, 1040, 1102, 23344, 1086, 1883, 14208, 2427, 1930, 1115, 1040, 9516, 3609, 29501, 10614, 29481, 10081, 1070, 1040, 1647, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.21875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"stiff\"},\n{\"rationales\": \"lacks\"},\n{\"rationales\": \"trace\"},\n{\"rationales\": \"wit\"},\n{\"rationales\": \"borrowed\"},\n{\"rationales\": \"Gilligan's Island\"},\n{\"rationales\": \"worst\"},\n{\"rationales\": \"special-effects\"},\n{\"rationales\": \"creation\"}\n]"}
{"content": "There's no palpable chemistry between Lopez and male lead Ralph Fiennes, plus the script by Working Girl scribe Kevin Wade is workmanlike in the extreme.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], "response_10": "(b) This review is overall rather negative. The review mentions a lack of chemistry between the main actors, Lopez and Ralph Fiennes, and criticizes the script as \"workmanlike in the extreme\", which generally implies it is of poor quality.", "annotation_request": "Consider the following movie review: There's no palpable chemistry between Lopez and male lead Ralph Fiennes, plus the script by Working Girl scribe Kevin Wade is workmanlike in the extreme. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_10": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2155, 29510, 29481, 1476, 5553, 29488, 1290, 26459, 2212, 1161, 2613, 29532, 1072, 8630, 2504, 24141, 1169, 2143, 5279, 29493, 4053, 1040, 7535, 1254, 19615, 11618, 1520, 6516, 14357, 1162, 1538, 1117, 1539, 2062, 4859, 1065, 1040, 13058, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.9375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"no palpable chemistry\"},\n{\"rationales\": \"workmanlike in the extreme\"},\n{\"rationales\": \"lack\"},\n{\"rationales\": \"criticizes\"},\n{\"rationales\": \"poor quality\"},\n{\"rationales\": \"literally means poor quality or low-grade\"},\n{\"rationales\": \"extreme\"}\n]"}
{"content": "A first-class, thoroughly involving B movie that effectively combines two surefire, beloved genres -- the prison flick and the fight film.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_11": "(a) This review is overall rather positive. The use of words like \"first-class,\" \"thoroughly involving,\" and \"effectively combines\" implies a positive tone towards the movie. The mention of the movie being a B movie may suggest a lower budget, but it is still praised for its execution.", "annotation_request": "Consider the following movie review: A first-class, thoroughly involving B movie that effectively combines two surefire, beloved genres -- the prison flick and the fight film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_11": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1675, 29501, 2657, 29493, 20645, 15739, 1133, 6762, 1137, 12234, 3774, 2071, 1757, 2632, 10025, 29493, 22476, 3420, 1179, 2707, 1040, 7355, 16618, 1072, 1040, 4760, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.765625], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"first-class\"},\n{\"rationales\": \"thoroughly involving\"},\n{\"rationales\": \"effectively combines\"},\n{\"rationales\": \"beloved genres\"}\n]"}
{"content": "The film is so bad it doesn't improve upon the experience of staring at a blank screen.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_12": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The film is so bad it doesn't improve upon the experience of staring at a blank screen. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_12": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 1117, 1347, 3375, 1146, 3136, 29510, 29475, 5684, 4482, 1040, 3427, 1070, 13912, 1206, 1032, 10290, 5689, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.796875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"bad\"]}, {\"rationales\": [\"blank\"]}]"}
{"content": "Another Best of the Year selection.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 1, 0], "response_13": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Another Best of the Year selection. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_13": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 7648, 6238, 1070, 1040, 8369, 8263, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.65625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Another Best of the Year selection\"}]"}
{"content": "I love the robust middle of this picture.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0], "response_14": "(a) This review is overall rather positive. The word \"love\" suggests a positive sentiment towards the movie, and the term \"robust middle\" generally suggests that the reviewer appreciates the development or structure of the movie's middle section.", "annotation_request": "Consider the following movie review: I love the robust middle of this picture. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_14": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 2784, 1040, 17226, 5754, 1070, 1224, 6522, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"love\"}]"}
{"content": "The soundtrack alone is worth the price of admission.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 0, 1, 0, 0], "response_15": "(a) This review is overall rather positive. The opinion expressed in the review indicates a high level of appreciation for the movie's soundtrack. The phrase \"worth the price of admission\" typically implies that the evaluator regards something as being exceptionally good or valuable. Hence, we can infer that the reviewer has a positive opinion about the movie.", "annotation_request": "Consider the following movie review: The soundtrack alone is worth the price of admission. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_15": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3390, 8590, 5179, 1117, 5175, 1040, 4912, 1070, 24256, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.078125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"soundtrack\"}, {\"rationales\": \"worth\"}]"}
{"content": "For the rest of us, sitting through Dahmer's two hours amounts to little more than punishment.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_16": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: For the rest of us, sitting through Dahmer's two hours amounts to little more than punishment. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_16": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2031, 1040, 2614, 1070, 1360, 29493, 7166, 1827, 1152, 1680, 1562, 29510, 29481, 1757, 4084, 15606, 1066, 2396, 1448, 1589, 21175, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.328125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"punishment\"}, {\"rationales\": \"little\"}, {\"rationales\": \"amounts\"}]"}
{"content": "Featuring a dangerously seductive performance from the great Daniel Auteuil, ``Sade'' covers the same period as Kaufmann's ``Quills'' with more unsettlingly realistic results.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "response_17": "(a) This review is overall rather positive. The reviewer uses words like \"dangerously seductive,\" \"great,\" \"unsettlingly realistic results\" to describe the movie and the performance of Daniel Auteuil. This suggests the reviewer found aspects of the movie to be engaging, effective, and perhaps even impressive.", "annotation_request": "Consider the following movie review: Featuring a dangerously seductive performance from the great Daniel Auteuil, ``Sade'' covers the same period as Kaufmann's ``Quills'' with more unsettlingly realistic results. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_17": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5383, 1038, 2146, 1032, 6783, 5787, 9946, 4467, 1263, 5165, 1245, 1040, 2366, 8871, 1098, 2491, 29486, 1077, 29493, 5776, 29503, 1538, 6205, 13552, 1040, 2116, 3984, 1158, 1292, 8165, 7250, 29510, 29481, 5776, 2958, 3535, 6205, 1163, 1448, 23121, 29475, 2673, 1114, 20363, 3671, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.46875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"dangerously seductive\"},{\"rationales\": \"great\"},{\"rationales\": \"unsettlingly realistic results\"}]"}
{"content": "Beautifully observed, miraculously unsentimental comedy-drama.", "true_label": 1, "gold_label_rationales": [1, 0, 0, 0, 0], "response_18": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Beautifully observed, miraculously unsentimental comedy-drama. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_18": 1, "relevance_lrp": [15.578125, 0.00031304359436035156, 0.299072265625, 0.0618896484375, 0.222412109375, -0.06927490234375, 0.0858154296875, 0.147216796875, 0.011383056640625, -0.01517486572265625, -0.010589599609375, 0.011749267578125, 0.034515380859375, 0.0070953369140625, 0.01548004150390625, 0.025726318359375, 0.0029392242431640625, -0.00026035308837890625, -0.01198577880859375, -0.0233612060546875, 0.0027217864990234375, -0.00290679931640625, 0.005870819091796875, -0.1883544921875, 1.39453125, 0.1392822265625, 0.2198486328125, 0.132080078125, 0.1005859375, 0.12017822265625, 0.403076171875, 0.396728515625, 0.06146240234375, 0.004085540771484375, 0.130126953125, 0.490234375, 0.22216796875, 0.08233642578125, 0.33349609375, 0.72900390625, 0.421875, 0.1708984375, 0.41748046875, 1.1552734375, 2.109375, 0.20947265625, 0.0428466796875, 0.13818359375, 0.048248291015625, 0.11328125, 0.059356689453125, 0.223876953125, 0.1497802734375, 0.125732421875, 0.1376953125, 0.77685546875, 0.056549072265625, 0.016632080078125, 0.00814056396484375, 0.01434326171875, 0.0180206298828125, 0.00623321533203125, 0.0240936279296875, 0.042266845703125, 0.0810546875, 0.2301025390625, 0.2427978515625, 0.190185546875, 0.03375244140625, 2.630859375], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 27315, 1114, 8743, 29493, 6844, 1091, 27112, 10982, 1076, 16170, 19755, 29501, 3690, 3554, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.046875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"beautifully\"}, {\"rationales\": \"miraculously\"}, {\"rationales\": \"comedy-drama\"}]"}
{"content": "What makes How I Killed My Father compelling, besides its terrific performances, is Fontaine's willingness to wander into the dark areas of parent-child relationships without flinching.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_19": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: What makes How I Killed My Father compelling, besides its terrific performances, is Fontaine's willingness to wander into the dark areas of parent-child relationships without flinching. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_19": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2592, 3638, 2370, 1083, 1292, 3404, 2752, 12200, 27063, 29493, 19300, 1639, 5230, 1689, 18255, 29493, 1117, 16232, 5030, 29510, 29481, 8581, 2235, 1066, 1043, 5195, 1546, 1040, 3967, 5788, 1070, 3332, 29501, 5425, 10159, 2439, 1740, 1030, 11865, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.8125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"compelling\"}, {\"rationales\": \"terrific\"}, {\"rationales\": \"willingness\"}]"}
{"content": "This hastily mounted production exists only to capitalize on Hopkins' inclination to play Hannibal Lecter again, even though Harris has no immediate inclination to provide a fourth book.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_20": "(b) This review is overall rather negative. The use of words like \"hastily,\" \"capitalize,\" and \"inclination\" indicate criticism towards the production and its motives, while mentioning Harris having \"no immediate inclination\" to provide a fourth book suggests dissatisfaction with the storyline or continuation of the series.", "annotation_request": "Consider the following movie review: This hastily mounted production exists only to capitalize on Hopkins' inclination to play Hannibal Lecter again, even though Harris has no immediate inclination to provide a fourth book. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_20": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 25785, 1874, 19311, 5653, 7376, 1633, 1066, 6333, 1421, 1124, 16174, 9066, 29510, 1939, 3003, 1066, 1924, 15158, 1361, 1050, 1161, 1298, 1031, 1844, 29493, 1787, 2838, 17460, 1427, 1476, 12167, 1939, 3003, 1066, 3852, 1032, 10804, 2588, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.15625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"hastily\"},\n{\"rationales\": \"capitalize\"},\n{\"rationales\": \"inclination\"},\n{\"rationales\": \"even\"},\n{\"rationales\": \"though\"},\n{\"rationales\": \"Harris\"},\n{\"rationales\": \"immediate\"},\n{\"rationales\": \"provide\"},\n{\"rationales\": \"fourth\"},\n{\"rationales\": \"book\"}\n]"}
{"content": "Bullock's complete lack of focus and ability quickly derails the film.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0], "response_21": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Bullock's complete lack of focus and ability quickly derails the film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_21": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 17766, 1397, 29510, 29481, 4928, 6270, 1070, 4000, 1072, 6305, 5145, 1659, 2782, 1040, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.703125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"lack\"}, {\"rationales\": \"focus\"}, {\"rationales\": \"ability\"}, {\"rationales\": \"quickly\"}, {\"rationales\": \"derails\"}, {\"rationales\": \"film\"}]"}
{"content": "... a plotline that's as lumpy as two-day old porridge... the filmmakers' paws, sad to say, were all over this ``un-bear-able'' project!", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], "response_22": "(b) This review is overall rather negative. The use of phrases like \"lumpy plotline,\" \"two-day old porridge,\" and the negative connotation in \"un-bear-able\" project imply that the movie is not well-received by the reviewer. Additionally, the mention of \"the filmmakers' paws\" suggests a criticism towards the directors' handling of the project.", "annotation_request": "Consider the following movie review: ... a plotline that's as lumpy as two-day old porridge... the filmmakers' paws, sad to say, were all over this ``un-bear-able'' project! \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_22": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 10010, 1849, 1137, 29510, 29481, 1158, 1073, 14964, 1158, 1757, 29501, 2234, 2339, 2727, 9931, 1869, 1040, 3734, 22784, 29510, 1052, 6963, 29493, 8224, 1066, 2083, 29493, 1422, 1312, 1522, 1224, 5776, 1138, 29501, 25882, 29501, 1290, 6205, 3256, 29576, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.109375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"lumpy\"},\n{\"rationales\": \"two-day old porridge\"},\n{\"rationales\": \"un-bear-able\"},\n{\"rationales\": \"project\"},\n{\"rationales\": \"sad\"},\n{\"rationales\": \"filmmakers\"},\n{\"rationales\": \"paws\"}\n]"}
{"content": "Crush could be the worst film a man has made about women since Valley of the Dolls.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "response_23": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Crush could be the worst film a man has made about women since Valley of the Dolls. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_23": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5371, 2194, 1597, 1115, 1040, 9516, 3734, 1032, 1444, 1427, 2037, 1452, 3293, 2622, 11277, 1070, 1040, 1152, 1561, 29481, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.734375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"worst\"}, {\"rationales\": \"since Valley of the Dolls\"}, {\"rationales\": \"man\"}]"}
{"content": "Reassuring, retro uplifter.", "true_label": 1, "gold_label_rationales": [1, 0, 1], "response_24": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Reassuring, retro uplifter. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_24": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2066, 1257, 2146, 29493, 25520, 1100, 1220, 1103, 1128, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.65625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Reassuring\"}, {\"rationales\": \"uplifter\"}]"}
{"content": "Flaccid drama and exasperatingly slow journey.", "true_label": 0, "gold_label_rationales": [1, 0, 0, 1, 1, 0], "response_25": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Flaccid drama and exasperatingly slow journey. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_25": 0, "relevance_lrp": [14.375, -2.8789043426513672e-05, 0.252685546875, 0.0562744140625, 0.2264404296875, -0.03619384765625, 0.044708251953125, 0.11004638671875, 0.0307769775390625, -0.050140380859375, 0.0237884521484375, -0.045074462890625, 0.01392364501953125, 0.00955963134765625, 0.021636962890625, 0.019195556640625, 0.006923675537109375, 0.00936126708984375, 0.028900146484375, 0.03082275390625, -0.182861328125, 1.55078125, 0.17626953125, 0.273681640625, 0.194580078125, 0.1248779296875, 0.11370849609375, 0.392333984375, 0.456787109375, 0.0033588409423828125, -0.2203369140625, 0.12091064453125, 0.537109375, 0.1673583984375, 0.065185546875, 0.26220703125, 0.6572265625, 0.40283203125, 0.181396484375, 0.352783203125, 0.53857421875, 1.1259765625, 0.3408203125, 0.043304443359375, 0.1810302734375, 0.08367919921875, 0.1668701171875, 0.048553466796875, 0.318603515625, 0.1978759765625, 0.1944580078125, 0.56396484375, 2.216796875, 0.050628662109375, 0.01678466796875, 0.04296875, 0.01605224609375, -0.007762908935546875, 0.03033447265625, 0.137939453125, 0.046112060546875, 0.084716796875, 0.250732421875, 0.226806640625, 0.1783447265625, 0.0306396484375, 2.32421875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3262, 5141, 1081, 14560, 1072, 1207, 25945, 1845, 1114, 4712, 8891, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.203125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"flaccid\"}, {\"rationales\": \"exasperatingly\"}, {\"rationales\": \"slow\"}]"}
{"content": "The Movie will reach far beyond its core demographic.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 0, 1, 1], "response_26": "(a) This review is overall rather positive. The phrase \"The Movie will reach far beyond its core demographic\" suggests that the reviewer believes the movie will appeal to more than just its intended audience, indicating a broad, positive reception.", "annotation_request": "Consider the following movie review: The Movie will reach far beyond its core demographic. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_26": 1, "relevance_lrp": [15.3046875, -1.6093254089355469e-06, 0.291259765625, 0.082275390625, 0.277587890625, -0.024932861328125, 0.150146484375, 0.1729736328125, 0.03375244140625, -0.04376220703125, 0.0218963623046875, -0.0260772705078125, 0.02410888671875, 0.01316070556640625, 0.002368927001953125, 0.0233917236328125, -0.0013027191162109375, 0.003681182861328125, 0.00994873046875, -0.175537109375, 1.4482421875, 0.1448974609375, 0.256591796875, 0.1650390625, 0.11053466796875, 0.10565185546875, 0.36962890625, 0.380859375, 0.0689697265625, -0.0035114288330078125, 0.139892578125, 0.4990234375, 0.2177734375, 0.08074951171875, 0.331787109375, 0.763671875, 0.400390625, 0.158203125, 0.378173828125, 1.0087890625, 1.8876953125, 0.236572265625, 0.025787353515625, 0.1500244140625, 0.056365966796875, 0.1290283203125, 0.1065673828125, 0.2191162109375, 0.16162109375, 0.1422119140625, 0.230224609375, 0.9716796875, 0.058929443359375, 0.0150604248046875, 0.01245880126953125, 0.017364501953125, 0.023040771484375, 0.0225372314453125, 0.0474853515625, 0.04766845703125, 0.080810546875, 0.2362060546875, 0.2283935546875, 0.18505859375, 0.03240966796875, 2.6640625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 23976, 1390, 5331, 2850, 6066, 1639, 7189, 2261, 13061, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.171875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"far\"}, {\"rationales\": \"beyond\"}, {\"rationales\": \"core\"}, {\"rationales\": \"demographic\"}, {\"rationales\": \"reach\"}, {\"rationales\": \"appeal\"}]"}
{"content": "How did it ever get made?", "true_label": 0, "gold_label_rationales": [1, 1, 1, 1, 1, 1], "response_27": "(b) This review is overall rather negative. The phrase \"How did it ever get made?\" often implies criticism or surprise at a film's production, suggesting a less favorable review.", "annotation_request": "Consider the following movie review: How did it ever get made? \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_27": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2370, 1631, 1146, 3038, 1393, 2037, 29572, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.921875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"How\"},\n{\"rationales\": \"ever\"},\n{\"rationales\": \"get\"},\n{\"rationales\": \"made\"},\n{\"rationales\": \"surprise\"},\n{\"rationales\": \"criticism\"}\n]"}
{"content": "I like the new footage and still love the old stuff.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0], "response_28": "(a) This review is overall rather positive. The reviewer expresses a liking for the new footage and continues to express love for the old stuff, indicating a general appreciation for the movie.", "annotation_request": "Consider the following movie review: I like the new footage and still love the old stuff. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_28": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 1505, 1040, 1401, 27304, 1072, 2077, 2784, 1040, 2339, 5473, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.796875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"like\"}, {\"rationales\": \"love\"}, {\"rationales\": \"new footage\"}]"}
{"content": "Could The Country Bears really be as bad as its trailers?", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0], "response_29": "(b) This review is overall rather negative. The question itself seems to imply a negative sentiment towards the movie \"The Country Bears,\" as the reviewer is asking whether it could be as bad as its trailers suggested.", "annotation_request": "Consider the following movie review: Could The Country Bears really be as bad as its trailers? \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_29": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 14723, 1183, 13776, 1133, 6708, 2296, 1115, 1158, 3375, 1158, 1639, 8773, 1172, 29572, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.578125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Could\"}, {\"rationales\": \"really\"}, {\"rationales\": \"be\"}, {\"rationales\": \"bad\"}]"}
{"content": "At times, the movie looks genuinely pretty.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1], "response_30": "(a) This review is overall rather positive. The word \"pretty\" is typically used as a compliment, so the fact that the reviewer describes the movie as \"genuinely pretty\" at times indicates a positive impression of the film's visual aspects.", "annotation_request": "Consider the following movie review: At times, the movie looks genuinely pretty. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_30": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2562, 3189, 29493, 1040, 6762, 5442, 23216, 4236, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [27.5625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"pretty\"}]"}
{"content": "The stupidest, most insulting movie of 2002's first quarter.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0], "response_31": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The stupidest, most insulting movie of 2002's first quarter. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_31": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 9478, 1142, 29493, 1848, 18209, 1056, 6762, 1070, 29473, 29518, 29502, 29502, 29518, 29510, 29481, 1675, 9017, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.296875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"stupidest\"}, {\"rationales\": \"insulting\"}, {\"rationales\": \"most\"}]"}
{"content": "The film seems a dead weight.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1], "response_32": "(b) This review is overall rather negative. The phrase \"dead weight\" generally implies something that is burdensome, unproductive, or unimportant, which suggests that the reviewer did not have a favorable opinion of the film.", "annotation_request": "Consider the following movie review: The film seems a dead weight. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_32": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 4737, 1032, 4462, 5104, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.484375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"dead\"]}, {\"rationales\": [\"weight\"]}]"}
{"content": "Sparkling, often hilarious romantic jealousy comedy... Attal looks so much like a young Robert DeNiro that it seems the film should instead be called `My Husband Is Travis Bickle'.", "true_label": 1, "gold_label_rationales": [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_33": "(a) This review is overall rather positive. The use of words such as 'sparkling' and 'hilarious' indicates a positive attitude towards the movie, and the comparison to Robert DeNiro suggests a favorable impression of Attal's performance. The mention of 'romantic jealousy comedy' suggests the genre is being appreciated as intended, and the reference to Attal resembling a young DeNiro could be seen as a compliment. However, the title suggestion", "annotation_request": "Consider the following movie review: Sparkling, often hilarious romantic jealousy comedy... Attal looks so much like a young Robert DeNiro that it seems the film should instead be called `My Husband Is Travis Bickle'. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_33": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2438, 1487, 2673, 29493, 3376, 28181, 1693, 17302, 21944, 29492, 19755, 1869, 6056, 1050, 5442, 1347, 1956, 1505, 1032, 3286, 6374, 2111, 29527, 5580, 1137, 1146, 4737, 1040, 3734, 1791, 4287, 1115, 2755, 2320, 5951, 23119, 4553, 2459, 2087, 20445, 1133, 1449, 1059, 4903, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.9375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"sparkling\"}, {\"rationales\": \"hilarious\"}, {\"rationales\": \"romantic\"}]"}
{"content": "I did go back and check out the last 10 minutes, but these were more repulsive than the first 30 or 40 minutes.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], "response_34": "(b) This review is overall rather negative. The reviewer expresses that the last 10 minutes were more repulsive than the initial part of the movie, which generally suggests a negative or poor evaluation of the film's ending. The fact the reviewer needed to rewatch the latter part to make this conclusion also implies some level of dissatisfaction with the movie.", "annotation_request": "Consider the following movie review: I did go back and check out the last 10 minutes, but these were more repulsive than the first 30 or 40 minutes. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_34": 0, "relevance_lrp": [14.7734375, 0.00177001953125, 0.322265625, 0.08404541015625, 0.2393798828125, -0.09820556640625, 0.083984375, 0.142578125, -0.00213623046875, -0.005889892578125, 0.023406982421875, 0.00965118408203125, 0.014129638671875, 0.029541015625, 0.01611328125, -0.037353515625, -0.01479339599609375, 0.01010894775390625, 0.0018320083618164062, 0.003936767578125, -0.041900634765625, 0.0196990966796875, 0.025421142578125, 0.035491943359375, 0.0002422332763671875, -0.006389617919921875, -0.04168701171875, -0.00749969482421875, 0.00870513916015625, 0.00229644775390625, -0.0232696533203125, 0.0300140380859375, -0.0030422210693359375, 0.007171630859375, 0.0002357959747314453, 0.0261993408203125, -0.0036296844482421875, 0.006755828857421875, 0.006916046142578125, -0.00675201416015625, 0.00469207763671875, -0.1798095703125, 1.58984375, 0.1845703125, 0.27587890625, 0.1871337890625, 0.129150390625, 0.1087646484375, 0.384521484375, 0.44580078125, 0.0003807544708251953, -0.212890625, 0.1324462890625, 0.5390625, 0.15576171875, 0.06396484375, 0.248046875, 0.7275390625, 0.399169921875, 0.18212890625, 0.34814453125, 0.5146484375, 1.1181640625, 0.33984375, 0.05316162109375, 0.209228515625, 0.09033203125, 0.19091796875, 0.050506591796875, 0.351806640625, 0.1890869140625, 0.200927734375, 0.5771484375, 2.228515625, 0.049591064453125, 0.0092010498046875, 0.0411376953125, 0.0141143798828125, -0.00939178466796875, 0.033905029296875, 0.1318359375, 0.035888671875, 0.0870361328125, 0.271484375, 0.2401123046875, 0.1785888671875, 0.03045654296875, 2.345703125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 1631, 1344, 1620, 1072, 2645, 1343, 1040, 2200, 29473, 29508, 29502, 4254, 29493, 1330, 1935, 1422, 1448, 2326, 8318, 1263, 1589, 1040, 1675, 29473, 29538, 29502, 1210, 29473, 29549, 29502, 4254, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.9375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"repulsive\"]}, {\"rationales\": [\"rewatch\"]}]"}
{"content": "A lousy movie that's not merely unwatchable, but also unlistenable.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 1, 0, 0, 1], "response_35": "(b) This review is overall rather negative because the words \"lousy,\" \"unwatchable,\" and \"unlistenable\" indicate negative qualities about the movie.", "annotation_request": "Consider the following movie review: A lousy movie that's not merely unwatchable, but also unlistenable. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_35": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1073, 1375, 29492, 6762, 1137, 29510, 29481, 1227, 11551, 1289, 11098, 1290, 29493, 1330, 1603, 1289, 2471, 8003, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.578125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"lousy\"}, {\"rationales\": \"unwatchable\"}, {\"rationales\": \"unlistenable\"}]"}
{"content": "One of the best films of the year with its exploration of the obstacles to happiness faced by five contemporary individuals... a psychological masterpiece.", "true_label": 1, "gold_label_rationales": [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "response_36": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: One of the best films of the year with its exploration of the obstacles to happiness faced by five contemporary individuals... a psychological masterpiece. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_36": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3155, 1070, 1040, 2257, 10690, 1070, 1040, 1647, 1163, 1639, 23851, 1070, 1040, 14132, 15163, 1066, 15847, 13333, 1254, 4127, 14389, 7760, 1869, 1032, 19603, 6736, 17920, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.890625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"best\"}, {\"rationales\": \"exploration\"}, {\"rationales\": \"obstacles\"}, {\"rationales\": \"happiness\"}, {\"rationales\": \"psychological\"}, {\"rationales\": \"masterpiece\"}]"}
{"content": "A strong script, powerful direction and splendid production design allows us to be transported into the life of Wladyslaw Szpilman, who is not only a pianist, but a good human being.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_37": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A strong script, powerful direction and splendid production design allows us to be transported into the life of Wladyslaw Szpilman, who is not only a pianist, but a good human being. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_37": 1, "relevance_lrp": [15.6796875, 0.002048492431640625, 0.309326171875, 0.07843017578125, 0.2490234375, -0.0728759765625, 0.09075927734375, 0.1346435546875, 0.01303863525390625, 0.0234832763671875, -0.05126953125, 0.0156402587890625, 0.02008056640625, -0.027587890625, 0.00695037841796875, -0.0004525184631347656, 0.004375457763671875, 0.0078887939453125, -0.0186614990234375, 0.00836944580078125, 0.0294189453125, -0.0003743171691894531, 0.002696990966796875, 0.00968170166015625, -0.00765228271484375, 0.004329681396484375, 0.010040283203125, -0.0175628662109375, -0.01548004150390625, 0.0143585205078125, 0.011138916015625, -5.942583084106445e-05, 0.00696563720703125, 0.0095977783203125, -0.019073486328125, -0.0022125244140625, 0.01079559326171875, 0.00255584716796875, 0.0042572021484375, 0.00791168212890625, 0.0123443603515625, -0.0033779144287109375, 0.0027332305908203125, -0.034149169921875, 0.01409149169921875, 0.004451751708984375, -0.004180908203125, 0.00847625732421875, -0.0401611328125, 0.019500732421875, 0.007171630859375, 0.0227813720703125, -0.0005578994750976562, -0.18115234375, 1.4697265625, 0.1348876953125, 0.21435546875, 0.136474609375, 0.108642578125, 0.1173095703125, 0.388671875, 0.3876953125, 0.052001953125, 0.051300048828125, 0.1270751953125, 0.51171875, 0.246337890625, 0.09039306640625, 0.3359375, 0.8408203125, 0.412109375, 0.178955078125, 0.412841796875, 1.173828125, 2.203125, 0.214599609375, 0.03900146484375, 0.12841796875, 0.042083740234375, 0.10101318359375, 0.0472412109375, 0.2138671875, 0.1395263671875, 0.11541748046875, 0.1510009765625, 0.78564453125, 0.05450439453125, 0.0123748779296875, 0.0002484321594238281, 0.011444091796875, 0.0148773193359375, 0.00661468505859375, 0.018951416015625, 0.04168701171875, 0.0743408203125, 0.2218017578125, 0.238037109375, 0.19970703125, 0.032257080078125, 2.6328125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 3735, 7535, 29493, 7555, 5775, 1072, 8922, 1184, 1081, 5653, 3389, 6744, 1360, 1066, 1115, 6977, 1054, 1546, 1040, 2179, 1070, 1162, 10731, 1614, 11424, 9486, 29488, 1077, 2062, 29493, 1461, 1117, 1227, 1633, 1032, 22392, 1160, 29493, 1330, 1032, 1947, 3698, 2018, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.5], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"strong\"}, {\"rationales\": \"powerful\"}, {\"rationales\": \"splendid\"}, {\"rationales\": \"transported\"}, {\"rationales\": \"good\"}, {\"rationales\": \"human being\"}]"}
{"content": "But here's the real damn: It isn't funny, either.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1, 0], "response_38": "(b) This review is overall rather negative. The use of the word \"real damn\" and \"isn't funny\" suggests the reviewer did not enjoy the movie or find it amusing.", "annotation_request": "Consider the following movie review: But here's the real damn: It isn't funny, either. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_38": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1860, 2004, 29510, 29481, 1040, 2121, 10509, 29515, 1429, 3925, 29510, 29475, 10800, 29493, 3245, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.4375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"real damn\"}, {\"rationales\": \"isn't funny\"}]"}
{"content": "... something appears to have been lost in the translation this time.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], "response_39": "(b) This review is overall rather negative. The statement \"something appears to have been lost in the translation this time\" suggests that the reviewer is unhappy with something about the movie, possibly the quality of the translation or the overall production.", "annotation_request": "Consider the following movie review: ... something appears to have been lost in the translation this time. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_39": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 2313, 8813, 1066, 1274, 1518, 4422, 1065, 1040, 14614, 1224, 1495, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.203125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"lost\"}, {\"rationales\": \"translation\"}, {\"rationales\": \"this\"}, {\"rationales\": \"time\"}]"}
{"content": "Stephen Rea, Aidan Quinn, and Alan Bates play Desmond's legal eagles, and when joined by Brosnan, the sight of this grandiloquent quartet lolling in pretty Irish settings is a pleasant enough thing, `tis.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], "response_40": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Stephen Rea, Aidan Quinn, and Alan Bates play Desmond's legal eagles, and when joined by Brosnan, the sight of this grandiloquent quartet lolling in pretty Irish settings is a pleasant enough thing, `tis. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_40": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 13100, 2066, 29476, 29493, 1098, 28734, 28712, 29493, 1072, 16212, 1133, 1770, 1924, 3303, 8793, 29510, 29481, 6416, 1085, 27432, 29493, 1072, 1507, 8066, 1254, 1133, 3505, 16481, 29493, 1040, 8507, 1070, 1224, 4255, 11398, 1132, 1076, 14838, 1067, 1073, 1561, 1056, 1065, 4236, 12108, 7240, 1117, 1032, 18132, 2834, 2738, 29493, 2320, 29475, 1046, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [32.0625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"pleasant\"}, {\"rationales\": \"grandiloquent\"}, {\"rationales\": \"pretty\"}]"}
{"content": "It's a powerful though flawed movie, guaranteed to put a lump in your throat while reaffirming Washington as possibly the best actor working in movies today.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], "response_41": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's a powerful though flawed movie, guaranteed to put a lump in your throat while reaffirming Washington as possibly the best actor working in movies today. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_41": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1032, 7555, 2838, 23672, 1054, 6762, 29493, 18581, 1066, 2426, 1032, 1073, 2572, 1065, 1342, 11575, 2080, 1080, 2914, 3548, 1056, 6692, 1158, 8957, 1040, 2257, 11732, 3507, 1065, 11383, 3922, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.671875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"powerful\"}, {\"rationales\": \"reaffirming\"}, {\"rationales\": \"best actor\"}, {\"rationales\": \"guaranteed\"}]"}
{"content": "An intriguing and entertaining introduction to Johnson.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 0, 0, 0], "response_42": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: An intriguing and entertaining introduction to Johnson. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_42": 1, "relevance_lrp": [15.7109375, 0.0006008148193359375, 0.289306640625, 0.06451416015625, 0.25830078125, -0.06939697265625, 0.08831787109375, 0.1253662109375, -0.04132080078125, -0.0814208984375, -0.0709228515625, -0.0198211669921875, 0.0175628662109375, -0.0298309326171875, -0.0174407958984375, 0.03900146484375, 0.0211029052734375, -0.03570556640625, -0.1676025390625, 1.5, 0.163330078125, 0.256103515625, 0.1634521484375, 0.113037109375, 0.1220703125, 0.414306640625, 0.40576171875, 0.049041748046875, 0.003269195556640625, 0.142578125, 0.517578125, 0.2398681640625, 0.08477783203125, 0.35498046875, 0.79833984375, 0.42431640625, 0.171875, 0.397705078125, 1.1220703125, 2.119140625, 0.220947265625, 0.006053924560546875, 0.1546630859375, 0.0479736328125, 0.11602783203125, 0.08154296875, 0.244384765625, 0.1484375, 0.12225341796875, 0.161865234375, 0.82958984375, 0.0550537109375, 0.01546478271484375, 0.0124359130859375, 0.0167999267578125, 0.0186767578125, 0.010650634765625, 0.03472900390625, 0.044891357421875, 0.07904052734375, 0.1953125, 0.2357177734375, 0.2005615234375, 0.032562255859375, 2.63671875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 8445, 9267, 1056, 1072, 25929, 15068, 1066, 10138, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"intriguing\"}, {\"rationales\": \"entertaining\"}]"}
{"content": "Everything was as superficial as the forced New Jersey lowbrow accent Uma had.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], "response_43": "(b) This review is overall rather negative because the author uses negative language to describe the film, such as describing it as superficial and criticizing Uma Thurman's acting.", "annotation_request": "Consider the following movie review: Everything was as superficial as the forced New Jersey lowbrow accent Uma had. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_43": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 13858, 1171, 1158, 2963, 29490, 6635, 1158, 1040, 7975, 2218, 14775, 3627, 29494, 1439, 20208, 1268, 1473, 1321, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.015625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"superficial\"}, {\"rationales\": \"forced\"}, {\"rationales\": \"lowbrow\"}]"}
{"content": "It is supremely unfunny and unentertaining to watch middle-age and older men drink to excess, piss on trees, b.s. one another and put on a show in drag.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_44": "(b) This review is overall rather negative. The reviewer uses repeated negatives such as \"unfunny,\" \"unentertaining,\" \"drink to excess,\" and \"put on a show in drag,\" suggesting a critical view of the film. Additionally, the terms \"middle-age and older men\" and \"piss on trees\" imply a dislike for certain aspects of the movie's content.", "annotation_request": "Consider the following movie review: It is supremely unfunny and unentertaining to watch middle-age and older men drink to excess, piss on trees, b.s. one another and put on a show in drag. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_44": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 1117, 2229, 2337, 1491, 1289, 2523, 2548, 1072, 1289, 1076, 1698, 2549, 1066, 3822, 5754, 29501, 1233, 1072, 7170, 2451, 5431, 1066, 12222, 29493, 18713, 1124, 7867, 29493, 1055, 29491, 29481, 29491, 1392, 2466, 1072, 2426, 1124, 1032, 2115, 1065, 8979, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.078125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"unfunny\"}, {\"rationales\": \"unentertaining\"}, {\"rationales\": \"b.s.\"}]"}
{"content": "Showtime is one of the hapless victims of the arrogant ``if we put together a wry white man and a chatty black man and give them guns, the movie will be funny'' syndrome.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_45": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Showtime is one of the hapless victims of the arrogant ``if we put together a wry white man and a chatty black man and give them guns, the movie will be funny'' syndrome. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_45": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9378, 2304, 1117, 1392, 1070, 1040, 1063, 1145, 2271, 14748, 1070, 1040, 29095, 1208, 5776, 1103, 1246, 2426, 3321, 1032, 1043, 1411, 3843, 1444, 1072, 1032, 11474, 1652, 3455, 1444, 1072, 2879, 1474, 12228, 29493, 1040, 6762, 1390, 1115, 10800, 6205, 28249, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.21875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"hapless victims\"}, {\"rationales\": \"arrogant\"}, {\"rationales\": \"syndrome\"}, {\"rationales\": \"put together\"}, {\"rationales\": \"wry white man\"}]"}
{"content": "Whatever heartwarming scene the impressively discreet filmmakers may have expected to record with their mini DV, they show a remarkable ability to document both sides of this emotional car-wreck.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0], "response_46": "(b) This review is overall rather negative. The use of phrases like \"emotional car-wreck\" and \"they show a remarkable ability to document both sides\" seems to suggest a less favorable view of the movie, as the reviewer implies that the scenes were unwanted events.", "annotation_request": "Consider the following movie review: Whatever heartwarming scene the impressively discreet filmmakers may have expected to record with their mini DV, they show a remarkable ability to document both sides of this emotional car-wreck. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_46": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}
{"content": "A zombie movie in every sense of the word -- mindless, lifeless, meandering, loud, painful, obnoxious.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_47": "(b) This review is overall rather negative. The words \"mindless,\" \"lifeless,\" \"meandering,\" \"loud,\" \"painful,\" and \"obnoxious\" suggest a negative assessment of the movie.", "annotation_request": "Consider the following movie review: A zombie movie in every sense of the word -- mindless, lifeless, meandering, loud, painful, obnoxious. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_47": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 29205, 1180, 6762, 1065, 1780, 4135, 1070, 1040, 2475, 2707, 3041, 2271, 29493, 6446, 6967, 29493, 1296, 1159, 2899, 29493, 10382, 29493, 18108, 29493, 1586, 29479, 1910, 1693, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.796875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"mindless\"}, {\"rationales\": \"lifeless\"}, {\"rationales\": \"meandering\"}, {\"rationales\": \"loud\"}, {\"rationales\": \"painful\"}, {\"rationales\": \"obnoxious\"}]"}
{"content": "It has fun with the quirks of family life, but it also treats the subject with fondness and respect.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], "response_48": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It has fun with the quirks of family life, but it also treats the subject with fondness and respect. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_48": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 1427, 1514, 1163, 1040, 1294, 1129, 3053, 1070, 2773, 2179, 29493, 1330, 1146, 1603, 28146, 1040, 4585, 1163, 9755, 2235, 1072, 3884, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"fun\"}, {\"rationales\": \"fondness\"}, {\"rationales\": \"respect\"}]"}
{"content": "Novak manages to capture a cruelly hilarious vein of black comedy in the situation with his cast of non-actors and a gritty, no-budget approach.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_49": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Novak manages to capture a cruelly hilarious vein of black comedy in the situation with his cast of non-actors and a gritty, no-budget approach. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_49": 1, "relevance_lrp": [15.9921875, 0.0026531219482421875, 0.316650390625, 0.0821533203125, 0.258056640625, -0.037689208984375, 0.0888671875, 0.1666259765625, 0.026702880859375, 0.01436614990234375, 0.007442474365234375, -0.01092529296875, 0.0158538818359375, 0.015472412109375, -0.03411865234375, 0.0182952880859375, 0.0111541748046875, -0.0084228515625, 0.002460479736328125, -0.0260009765625, -0.00696563720703125, 0.0045928955078125, 0.00577545166015625, -0.0242767333984375, 0.0183258056640625, -0.01308441162109375, 0.016571044921875, 0.0004596710205078125, 0.01375579833984375, -0.0252838134765625, 0.003833770751953125, 0.0137176513671875, -0.00861358642578125, -0.01486968994140625, 0.0022106170654296875, 0.0030002593994140625, -0.0307159423828125, -0.01375579833984375, -0.0100555419921875, -0.00774383544921875, 0.0176239013671875, -0.016448974609375, -0.00445556640625, 0.0039520263671875, -0.0026912689208984375, 0.0193023681640625, -0.154052734375, 1.47265625, 0.126708984375, 0.21533203125, 0.160888671875, 0.11376953125, 0.1204833984375, 0.384765625, 0.36279296875, 0.05596923828125, -0.006656646728515625, 0.12646484375, 0.479248046875, 0.2119140625, 0.08770751953125, 0.348876953125, 0.75439453125, 0.420166015625, 0.1630859375, 0.412841796875, 1.1103515625, 2.111328125, 0.21484375, 0.03631591796875, 0.154541015625, 0.054901123046875, 0.107177734375, 0.08160400390625, 0.259521484375, 0.1495361328125, 0.1317138671875, 0.17431640625, 0.85888671875, 0.05499267578125, 0.0132904052734375, 0.01122283935546875, 0.0153961181640625, 0.021209716796875, 0.0136566162109375, 0.050445556640625, 0.04241943359375, 0.07598876953125, 0.23193359375, 0.2496337890625, 0.1929931640625, 0.032745361328125, 2.6328125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9283, 1259, 1444, 2059, 1066, 12087, 1032, 6105, 10753, 28181, 1693, 2541, 1030, 1070, 3455, 19755, 1065, 1040, 5388, 1163, 1284, 5583, 1070, 2611, 29501, 1340, 1502, 1072, 1032, 1615, 12800, 29493, 1476, 29501, 17213, 1295, 5199, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.796875], "answer": 29476, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"captures\",\n\"rationales\": \"cruelly\",\n\"rationales\": \"hilarious\",\n\"rationales\": \"vein\",\n\"rationales\": \"black comedy\",\n\"rationales\": \"situation\",\n\"rationales\": \"cast\",\n\"rationales\": \"gritty\",\n\"rationales\": \"no-budget\"\n]", "rationales_checked": "[\n  {\n    \"rationales\": \"captures\"\n  },\n  {\n    \"rationales\": \"cruelly\"\n  },\n  {\n    \"rationales\": \"hilarious\"\n  },\n  {\n    \"rationales\": \"vein\"\n  },\n  {\n    \"rationales\": \"black comedy\"\n  },\n  {\n    \"rationales\": \"situation\"\n  },\n  {\n    \"rationales\": \"cast\"\n  },\n  {\n    \"rationales\": \"gritty\"\n  },\n  {\n    \"rationales\": \"no-budget\"\n  }\n]"}
{"content": "The movie is almost completely lacking in suspense, surprise and consistent emotional conviction.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], "response_50": "(b) This review is overall rather negative. The review implies that the movie is deficient in suspense, surprise, and emotional depth. This is generally considered to be negative criticism in the context of a movie review.", "annotation_request": "Consider the following movie review: The movie is almost completely lacking in suspense, surprise and consistent emotional conviction. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_50": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 1117, 3547, 5484, 27447, 1065, 19502, 1826, 29493, 9750, 1072, 11420, 11294, 25362, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.75], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"lacking\"}, {\"rationales\": \"surprise\"}, {\"rationales\": \"consistent emotional conviction\"}]"}
{"content": "But it's too long and too convoluted and it ends in a muddle.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1], "response_51": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: But it's too long and too convoluted and it ends in a muddle. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_51": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1860, 1146, 29510, 29481, 2136, 1811, 1072, 2136, 4989, 2188, 1054, 1072, 1146, 10443, 1065, 1032, 1058, 13138, 1059, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.953125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"too long\"}, {\"rationales\": \"too convoluted\"}, {\"rationales\": \"muddle\"}, {\"rationales\": \"ends\"}, {\"rationales\": \"convoluted\"}]"}
{"content": "This thing works on no level whatsoever for me.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 1, 0, 0], "response_52": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: This thing works on no level whatsoever for me. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_52": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 2738, 4559, 1124, 1476, 2952, 1535, 1435, 2316, 1122, 1296, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.796875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"this\"}, {\"rationales\": \"doesn't\"}, {\"rationales\": \"work\"}, {\"rationales\": \"no\"}, {\"rationales\": \"levels\"}]"}
{"content": "... a bland murder-on-campus yawner.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1], "response_53": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: ... a bland murder-on-campus yawner. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_53": 0, "relevance_lrp": [14.6484375, -0.00091552734375, 0.218505859375, 0.0318603515625, 0.2000732421875, -0.088134765625, 0.0102691650390625, 0.14013671875, 0.1800537109375, -0.07818603515625, -0.12164306640625, -0.0030002593994140625, -0.008331298828125, 0.0188140869140625, -0.0157928466796875, 0.04791259765625, 0.0282745361328125, 0.0582275390625, 0.0243988037109375, 0.0199127197265625, 0.01221466064453125, -0.171630859375, 1.3837890625, 0.173583984375, 0.27392578125, 0.2137451171875, 0.135498046875, 0.123046875, 0.41455078125, 0.491455078125, -0.003070831298828125, -0.2147216796875, 0.1263427734375, 0.5263671875, 0.1668701171875, 0.06884765625, 0.26220703125, 0.72314453125, 0.43115234375, 0.193603515625, 0.3515625, 0.51904296875, 1.150390625, 0.33154296875, 0.041656494140625, 0.1795654296875, 0.09075927734375, 0.1912841796875, 0.055267333984375, 0.3095703125, 0.206787109375, 0.2000732421875, 0.59912109375, 2.326171875, 0.0537109375, 0.00971221923828125, 0.04290771484375, 0.01525115966796875, -0.00453948974609375, 0.0304107666015625, 0.131591796875, 0.045928955078125, 0.0870361328125, 0.275634765625, 0.24755859375, 0.18017578125, 0.0309906005859375, 2.3359375], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 24262, 7600, 29501, 1034, 29501, 19173, 1149, 10897, 1648, 1031, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.6875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"yawner\"]}, {\"rationales\": [\"bland\"]}]"}
{"content": "In comparison to his earlier films it seems a disappointingly thin slice of lower-class London life; despite the title... amounts to surprisingly little.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_54": "(b) This review is overall rather negative because the reviewer mentions the film seems disappointing, only a thin slice of lower-class London life, the title amounts to surprisingly little, and possibly inferring a negative sentiment from the words \"lower-class\" and \"thin\".", "annotation_request": "Consider the following movie review: In comparison to his earlier films it seems a disappointingly thin slice of lower-class London life; despite the title... amounts to surprisingly little. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_54": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1328, 11135, 1066, 1284, 6353, 10690, 1146, 4737, 1032, 11502, 8149, 9794, 16931, 1070, 4657, 29501, 2657, 4990, 2179, 29513, 8345, 1040, 4709, 1869, 15606, 1066, 23875, 2396, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.75], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"disappointingly\"}, {\"rationales\": \"thin\"}, {\"rationales\": \"little\"}, {\"rationales\": \"lower-class\"}, {\"rationales\": \"surprisingly\"}, {\"rationales\": \"little\"}]"}
{"content": "One of the finest, most humane and important Holocaust movies ever made.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0], "response_55": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: One of the finest, most humane and important Holocaust movies ever made. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_55": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3155, 1070, 1040, 22329, 29493, 1848, 2765, 2332, 1072, 3046, 4938, 9440, 1237, 11383, 3038, 2037, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"finest\"}, {\"rationales\": \"humane\"}, {\"rationales\": \"important\"}, {\"rationales\": \"made\"}]"}
{"content": "Suffers from rambling, repetitive dialogue and the visual drabness endemic to digital video.", "true_label": 0, "gold_label_rationales": [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0], "response_56": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Suffers from rambling, repetitive dialogue and the visual drabness endemic to digital video. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_56": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1086, 2060, 1172, 1245, 16123, 7125, 29493, 22203, 3236, 19966, 1072, 1040, 9577, 2373, 1143, 2235, 1716, 11539, 1066, 7921, 4566, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.84375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"rambling\"}, {\"rationales\": \"repetitive\"}, {\"rationales\": \"drabness\"}, {\"rationales\": \"digital\"}, {\"rationales\": \"video\"}]"}
{"content": "Features one of the most affecting depictions of a love affair ever committed to film.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_57": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Features one of the most affecting depictions of a love affair ever committed to film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_57": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 21668, 1392, 1070, 1040, 1848, 28585, 5947, 20119, 1070, 1032, 2784, 19947, 3038, 11020, 1066, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.421875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"affecting\"}, {\"rationales\": \"love affair\"}, {\"rationales\": \"committed\"}]"}
{"content": "It is intensely personal and yet -- unlike Quills -- deftly shows us the temper of the times.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_58": "(a) This review is overall rather positive. The reviewer notes that the movie is intensely personal, which often suggests a deep emotional impact, and it also deftly shows the temper of the times, indicating a good historical accuracy or relevance to societal conditions. The comparison with Quills implies a higher standard, and yet the movie is not found wanting in this regard.", "annotation_request": "Consider the following movie review: It is intensely personal and yet -- unlike Quills -- deftly shows us the temper of the times. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_58": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 1117, 17466, 1491, 4095, 1072, 3551, 2707, 16111, 3100, 3535, 2707, 1108, 1400, 1114, 5138, 1360, 1040, 5794, 1070, 1040, 3189, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.9375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"intensely personal\"}, {\"rationales\": \"deftly shows\"}]"}
{"content": "Even as I valiantly struggled to remain interested, or at least conscious, I could feel my eyelids... getting... very... heavy...", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], "response_59": "(b) This review is overall rather negative. The reviewer indicates difficulty remaining interested, growing tired, and even falling asleep while watching the movie, suggesting a negative viewing experience.", "annotation_request": "Consider the following movie review: Even as I valiantly struggled to remain interested, or at least conscious, I could feel my eyelids... getting... very... heavy... \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_59": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4895, 1158, 1083, 2182, 4674, 1114, 20042, 1066, 7112, 7116, 29493, 1210, 1206, 3197, 10762, 29493, 1083, 1597, 2369, 1354, 2514, 1069, 3066, 1869, 3487, 1869, 1983, 1869, 6685, 1869, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"struggled\"},\n{\"rationales\": \"remain interested\"},\n{\"rationales\": \"conscious\"},\n{\"rationales\": \"heavy\"},\n{\"rationales\": \"eyelids\"},\n{\"rationales\": \"falling asleep\"}\n]"}
{"content": "... a solid, well-formed satire.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1], "response_60": "(a) This review is overall rather positive. The use of words like \"solid,\" \"well-formed,\" and \"satire\" suggests a positive assessment of the movie's structure and content.", "annotation_request": "Consider the following movie review: ... a solid, well-formed satire. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_60": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 7629, 29493, 1930, 29501, 13682, 3263, 1304, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.09375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"solid\"},{\"rationales\": \"well-formed\"},{\"rationales\": \"satire\"}]"}
{"content": "Read My Lips is to be viewed and treasured for its extraordinary intelligence and originality as well as its lyrical variations on the game of love.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_61": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Read My Lips is to be viewed and treasured for its extraordinary intelligence and originality as well as its lyrical variations on the game of love. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_61": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5707, 2752, 1161, 3198, 1117, 1066, 1115, 17629, 1072, 3423, 1061, 3098, 1122, 1639, 18577, 11663, 1072, 4261, 1240, 1158, 1930, 1158, 1639, 1073, 5137, 1513, 20486, 1124, 1040, 2807, 1070, 2784, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.140625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"extraordinary\"}, {\"rationales\": \"originality\"}, {\"rationales\": \"lyrical\"}, {\"rationales\": \"treasured\"}]"}
{"content": "The Movie is what happens when you blow up small potatoes to 10 times their natural size, and it ain't pretty.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_62": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The Movie is what happens when you blow up small potatoes to 10 times their natural size, and it ain't pretty. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_62": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 23976, 1117, 1535, 7649, 1507, 1136, 10484, 1350, 2509, 25521, 1066, 29473, 29508, 29502, 3189, 1420, 4997, 2437, 29493, 1072, 1146, 18291, 29510, 29475, 4236, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"blow up small potatoes to 10 times their natural size\"}, {\"rationales\": \"it ain't pretty\"}]"}
{"content": "Even a hardened voyeur would require the patience of Job to get through this interminable, shapeless documentary about the swinging subculture.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0], "response_63": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Even a hardened voyeur would require the patience of Job to get through this interminable, shapeless documentary about the swinging subculture. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_63": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4895, 1032, 2624, 2874, 16313, 7861, 1450, 3467, 1040, 22637, 1070, 15401, 1066, 1393, 1827, 1224, 1559, 2008, 1290, 29493, 1248, 1145, 6967, 22822, 1452, 1040, 14856, 1056, 1851, 29485, 8753, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.9375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"hardened\", \"interminable\", \"shapeless\"]}]"}
{"content": "A lame romantic comedy about an unsympathetic character and someone who would not likely be so stupid as to get involved with her.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "response_64": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A lame romantic comedy about an unsympathetic character and someone who would not likely be so stupid as to get involved with her. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_64": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1073, 1201, 17302, 19755, 1452, 1164, 10982, 1850, 28410, 4001, 1072, 3261, 1461, 1450, 1227, 4685, 1115, 1347, 9478, 1158, 1066, 1393, 6058, 1163, 1327, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.78125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"lame\"}, {\"rationales\": \"unsympathetic\"}, {\"rationales\": \"stupid\"}]"}
{"content": "Rob Schneider's infantile cross-dressing routines fill The Hot Chick, the latest gimmick from this unimaginative comedian.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "response_65": "(b) This review is overall rather negative. The language used suggests that the reviewer does not find Rob Schneider's performance or the movie, The Hot Chick, to be particularly amusing or well-executed.", "annotation_request": "Consider the following movie review: Rob Schneider's infantile cross-dressing routines fill The Hot Chick, the latest gimmick from this unimaginative comedian. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_65": 0, "relevance_lrp": [14.875, 0.001110076904296875, 0.278564453125, 0.0709228515625, 0.2281494140625, -0.0170135498046875, 0.1357421875, 0.1632080078125, 0.01088714599609375, 0.002941131591796875, -0.00504302978515625, 0.003925323486328125, -0.017913818359375, 0.004413604736328125, 0.043182373046875, 0.0170745849609375, -0.0016431808471679688, -0.0029735565185546875, 0.00302886962890625, 0.01358795166015625, 0.009185791015625, 0.02239990234375, 0.0340576171875, 0.029510498046875, 0.00527191162109375, 0.01276397705078125, -0.00861358642578125, -0.005680084228515625, 0.0284423828125, 0.0006308555603027344, 0.0382080078125, -0.007373809814453125, -0.012115478515625, 0.0048675537109375, -0.0034847259521484375, -0.033599853515625, 0.0072479248046875, -0.00815582275390625, 0.00569915771484375, 0.00826263427734375, -0.0235595703125, 0.01274871826171875, 0.007717132568359375, -0.1585693359375, 1.384765625, 0.130859375, 0.243896484375, 0.201171875, 0.131591796875, 0.1190185546875, 0.388671875, 0.45068359375, -0.0007300376892089844, -0.2039794921875, 0.1036376953125, 0.5, 0.1593017578125, 0.0712890625, 0.25, 0.66162109375, 0.407958984375, 0.183837890625, 0.328857421875, 0.470947265625, 1.1064453125, 0.337890625, 0.039093017578125, 0.18359375, 0.0906982421875, 0.1700439453125, 0.04833984375, 0.318115234375, 0.196044921875, 0.1982421875, 0.5712890625, 2.259765625, 0.05548095703125, 0.0123138427734375, 0.037628173828125, 0.01250457763671875, -0.004322052001953125, 0.032379150390625, 0.1507568359375, 0.05169677734375, 0.082275390625, 0.265869140625, 0.2388916015625, 0.177001953125, 0.0302734375, 2.435546875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6544, 2377, 1253, 1952, 29510, 29481, 23884, 1314, 4661, 29501, 29483, 1406, 1056, 7124, 2071, 5979, 1183, 7663, 1457, 1449, 29493, 1040, 8113, 1087, 9413, 1449, 1245, 1224, 1289, 25837, 1030, 1965, 27445, 1521, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.859375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"infantile\"]}, {\"rationales\": [\"gimmick\"]}, {\"rationales\": [\"unimaginative\"]}, {\"rationales\": [\"cross-dressing\"]}, {\"rationales\": [\"fill\"]}, {\"rationales\": [\"unimaginative\"]}, {\"rationales\": [\"unamusing\"]}, {\"rationales\": [\"unwell-executed\"]}]"}
{"content": "At 78 minutes it just zings along with vibrance and warmth.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_66": "(a) This review is overall rather positive. The words \"just zings along,\" \"vibrance,\" and \"warmth\" suggest a pleasant, energetic, and positive experience. Additionally, the fact that the movie is 78 minutes long, but still moves quickly and efficiently, is also typically considered a positive aspect.", "annotation_request": "Consider the following movie review: At 78 minutes it just zings along with vibrance and warmth. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_66": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2562, 29473, 29555, 29551, 4254, 1146, 1544, 1454, 1510, 3035, 1163, 14314, 1385, 1072, 22374, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.3125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"zings\"}, {\"rationales\": \"vibrance\"}, {\"rationales\": \"warmth\"}, {\"rationales\": \"quickly\"}, {\"rationales\": \"efficiently\"}, {\"rationales\": \"78 minutes\"}]"}
{"content": "Only an epic documentary could get it all down, and Spike Lee's Jim Brown: All American at long last gives its subject a movie worthy of his talents.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], "response_67": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Only an epic documentary could get it all down, and Spike Lee's Jim Brown: All American at long last gives its subject a movie worthy of his talents. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_67": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 7120, 1164, 24533, 22822, 1597, 1393, 1146, 1312, 1828, 29493, 1072, 2438, 3242, 8949, 29510, 29481, 7483, 9132, 29515, 2450, 3324, 1206, 1811, 2200, 5980, 1639, 4585, 1032, 6762, 21988, 1070, 1284, 27487, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.59375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"epic documentary\"}, {\"rationales\": \"movie worthy\"}, {\"rationales\": \"subject a movie\"}, {\"rationales\": \"talents\"}]"}
{"content": "As quiet, patient and tenacious as Mr. Lopez himself, who approaches his difficult, endless work with remarkable serenity and discipline.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], "response_68": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: As quiet, patient and tenacious as Mr. Lopez himself, who approaches his difficult, endless work with remarkable serenity and discipline. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_68": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1904, 6651, 29493, 8517, 1072, 3863, 18060, 1158, 3732, 29491, 1161, 2613, 29532, 3490, 29493, 1461, 14713, 1284, 4564, 29493, 19052, 1539, 1163, 17727, 1969, 1037, 1240, 1072, 19482, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.328125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"quiet\"}, {\"rationales\": \"patient\"}, {\"rationales\": \"tenacious\"}, {\"rationales\": \"remarkable\"}]"}
{"content": "Instead of hiding Pinocchio from critics, Miramax should have hidden it from everyone.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_69": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Instead of hiding Pinocchio from critics, Miramax should have hidden it from everyone. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_69": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 8930, 1070, 17390, 18697, 1170, 28655, 1245, 21325, 29493, 9922, 1082, 1665, 1791, 1274, 8686, 1146, 1245, 4144, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.015625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Instead of hiding\"}, {\"rationales\": \"hiding\"}, {\"rationales\": \"Miramax\"}, {\"rationales\": \"should\"}, {\"rationales\": \"hidden\"}, {\"rationales\": \"everyone\"}]"}
{"content": "What a great shame that such a talented director as Chen Kaige has chosen to make his English-language debut with a film so poorly plotted and scripted.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], "response_70": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: What a great shame that such a talented director as Chen Kaige has chosen to make his English-language debut with a film so poorly plotted and scripted. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_70": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2592, 1032, 2366, 15485, 1137, 2027, 1032, 22480, 7627, 1158, 17806, 16889, 4348, 1427, 9497, 1066, 1806, 1284, 5068, 29501, 12672, 10696, 1163, 1032, 3734, 1347, 24890, 1317, 10520, 1072, 7535, 1054, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"poorly plotted\"}, {\"rationales\": \"scripted\"}, {\"rationales\": \"shame\"}, {\"rationales\": \"talented director\"}, {\"rationales\": \"English-language debut\"}]"}
{"content": "Jeffs has created a breathtakingly assured and stylish work of spare dialogue and acute expressiveness.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], "response_71": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Jeffs has created a breathtakingly assured and stylish work of spare dialogue and acute expressiveness. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_71": 1, "relevance_lrp": [15.9921875, 0.0019130706787109375, 0.30859375, 0.08282470703125, 0.25927734375, -0.089111328125, 0.06494140625, 0.171142578125, 0.06536865234375, 0.0084381103515625, 0.06744384765625, -0.002460479736328125, -0.050750732421875, -0.0304412841796875, -0.01555633544921875, -0.0182037353515625, -0.0029506683349609375, -0.0215911865234375, 0.01235198974609375, -0.003429412841796875, -0.003070831298828125, -0.0219573974609375, -0.008880615234375, 0.00726318359375, -0.079833984375, -0.00679779052734375, -0.0128326416015625, 0.0110015869140625, 0.00888824462890625, 0.01151275634765625, -0.0083770751953125, -0.16748046875, 1.212890625, 0.139404296875, 0.2259521484375, 0.12286376953125, 0.1026611328125, 0.121337890625, 0.3916015625, 0.392578125, 0.057464599609375, 0.0167236328125, 0.1368408203125, 0.5146484375, 0.2271728515625, 0.08367919921875, 0.3388671875, 0.767578125, 0.402099609375, 0.1689453125, 0.405029296875, 1.095703125, 2.087890625, 0.2049560546875, -0.0012674331665039062, 0.1553955078125, 0.04730224609375, 0.10888671875, 0.0576171875, 0.23828125, 0.1456298828125, 0.12890625, 0.176025390625, 0.826171875, 0.053070068359375, 0.0127716064453125, 0.0108184814453125, 0.01509857177734375, 0.018157958984375, 0.0092926025390625, 0.03515625, 0.04290771484375, 0.08050537109375, 0.22607421875, 0.239990234375, 0.1993408203125, 0.034088134765625, 2.57421875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9446, 29481, 1427, 4627, 1032, 13873, 1175, 2056, 1114, 18671, 1072, 10944, 3063, 1539, 1070, 18325, 19966, 1072, 1951, 2491, 4840, 10760, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"breathtakingly\"}, {\"rationales\": \"assured\"}, {\"rationales\": \"stylish\"}, {\"rationales\": \"spare\"}, {\"rationales\": \"acute\"}]"}
{"content": "Just about the best straight-up, old-school horror film of the last 15 years.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_72": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Just about the best straight-up, old-school horror film of the last 15 years. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_72": 1, "relevance_lrp": [15.7734375, 6.288290023803711e-05, 0.34033203125, 0.07476806640625, 0.25927734375, -0.073974609375, 0.0677490234375, 0.1505126953125, -0.0124053955078125, -0.0167388916015625, -0.028045654296875, -0.02423095703125, -0.015655517578125, -0.01427459716796875, 0.00099945068359375, 0.00013625621795654297, -0.0128326416015625, -0.014251708984375, -0.0117645263671875, -0.037872314453125, -0.052825927734375, -0.00478363037109375, -0.03082275390625, 0.0038814544677734375, -0.0085601806640625, -0.008331298828125, 0.0225982666015625, 0.0253753662109375, -0.006504058837890625, -0.1915283203125, 1.4794921875, 0.159912109375, 0.2548828125, 0.1585693359375, 0.11151123046875, 0.11676025390625, 0.411376953125, 0.391357421875, 0.060760498046875, 0.04736328125, 0.1451416015625, 0.517578125, 0.224853515625, 0.0804443359375, 0.3193359375, 0.7666015625, 0.43310546875, 0.1680908203125, 0.41357421875, 1.138671875, 2.1171875, 0.2144775390625, 0.0289154052734375, 0.13623046875, 0.04095458984375, 0.105224609375, 0.055023193359375, 0.2166748046875, 0.156494140625, 0.1270751953125, 0.152587890625, 0.76416015625, 0.055389404296875, 0.0146942138671875, 0.0078277587890625, 0.01125335693359375, 0.017730712890625, 0.005191802978515625, 0.02813720703125, 0.042572021484375, 0.08502197265625, 0.2406005859375, 0.255859375, 0.1943359375, 0.032318115234375, 2.5703125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3962, 1452, 1040, 2257, 5623, 29501, 1483, 29493, 2339, 29501, 19953, 15800, 3734, 1070, 1040, 2200, 29473, 29508, 29550, 2035, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.234375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"best\"},{\"rationales\": \"old-school\"},{\"rationales\": \"horror\"},{\"rationales\": \"last\"},{\"rationales\": \"15\"},{\"rationales\": \"years\"}]"}
{"content": "Gosling creates a staggeringly compelling character, a young man whose sharp intellect is at the very root of his contradictory, self-hating, self-destructive ways.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_73": "(a) This review is overall rather positive. The use of words like \"staggeringly compelling,\" \"sharp intellect,\" and \"self-destructive ways\" suggests that the character played by Gosling is intriguing, well-developed, and complex, all of which are generally positive attributes in a movie review.", "annotation_request": "Consider the following movie review: Gosling creates a staggeringly compelling character, a young man whose sharp intellect is at the very root of his contradictory, self-hating, self-destructive ways. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_73": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1188, 1153, 2673, 13420, 1032, 25900, 8149, 27063, 4001, 29493, 1032, 3286, 1444, 5404, 10995, 12380, 1117, 1206, 1040, 1983, 6325, 1070, 1284, 16003, 1616, 1463, 29493, 1776, 29501, 29484, 1845, 29493, 1776, 29501, 6124, 1634, 1263, 5110, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.75], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"staggeringly compelling\"}, {\"rationales\": \"sharp intellect\"}]"}
{"content": "I thought the relationships were wonderful, the comedy was funny, and the love `real'.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], "response_74": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: I thought the relationships were wonderful, the comedy was funny, and the love `real'. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_74": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 2422, 1040, 10159, 1422, 9358, 29493, 1040, 19755, 1171, 10800, 29493, 1072, 1040, 2784, 2320, 7255, 4903, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.234375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"wonderful\"}, {\"rationales\": \"funny\"}, {\"rationales\": \"real\"}]"}
{"content": "Better at putting you to sleep than a sound machine.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 0, 0, 0, 0], "response_75": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Better at putting you to sleep than a sound machine. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_75": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 19630, 1206, 8958, 1136, 1066, 5057, 1589, 1032, 3390, 6367, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.65625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"putting\"}, {\"rationales\": \"sleep\"}, {\"rationales\": \"sound\"}, {\"rationales\": \"machine\"}]"}
{"content": "Feels less like a cousin to Blade Runner than like a bottom-feeder sequel in the Escape From New York series.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_76": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Feels less like a cousin to Blade Runner than like a bottom-feeder sequel in the Escape From New York series. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_76": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5383, 1958, 2876, 1505, 1032, 17790, 1066, 2793, 1538, 7088, 1847, 1589, 1505, 1032, 6627, 29501, 2280, 3633, 6099, 1069, 1065, 1040, 1181, 9719, 4440, 2218, 3494, 4286, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.046875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"bottom-feeder\"]},{\"rationales\": [\"sequel\"]}]"}
{"content": "Elegantly produced and expressively performed, the six musical numbers crystallize key plot moments into minutely detailed wonders of dreamlike ecstasy.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1], "response_77": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Elegantly produced and expressively performed, the six musical numbers crystallize key plot moments into minutely detailed wonders of dreamlike ecstasy. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_77": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1181, 2714, 4986, 7531, 1072, 4840, 3028, 8653, 29493, 1040, 4290, 9926, 6319, 26916, 1223, 1421, 2713, 10010, 10003, 1546, 29038, 1491, 11305, 1043, 19526, 1070, 5767, 4859, 12121, 1071, 6594, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.296875], "answer": 29476, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"elegantly\"\n},\n{\n\"rationales\": \"expressively\"\n},\n{\n\"rationales\": \"crystallize\"\n},\n{\n\"rationales\": \"minutely\"\n},\n{\n\"rationales\": \"detailed\"\n},\n{\n\"rationales\": \"wonders\"\n},\n{\n\"rationales\": \"dreamlike\"\n}\n]"}
{"content": "Celebrated at Sundance, this slight comedy of manners has winning performances and a glossy, glib charm that's hard to beat.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1], "response_78": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Celebrated at Sundance, this slight comedy of manners has winning performances and a glossy, glib charm that's hard to beat. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_78": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 25547, 2241, 1369, 1206, 7489, 1385, 29493, 1224, 6311, 19755, 1070, 1444, 6717, 1427, 10589, 18255, 1072, 1032, 2040, 2926, 29492, 29493, 2040, 1361, 23301, 1137, 29510, 29481, 2624, 1066, 9007, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Celebrated\"}, {\"rationales\": \"slight comedy of manners\"}, {\"rationales\": \"winning performances\"}, {\"rationales\": \"glossy\"}, {\"rationales\": \"glib charm\"}, {\"rationales\": \"hard\"}, {\"rationales\": \"to beat\"}]"}
{"content": "Apparently, romantic comedy with a fresh point of view just doesn't figure in the present Hollywood program.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0], "response_79": "(b) This review is overall rather negative. The statement \"Apparently, romantic comedy with a fresh point of view just doesn't figure in the present Hollywood program\" suggests that the reviewer is expressing disappointment or frustration that such a movie is not currently being produced or appreciated by Hollywood. Additionally, the use of the word \"apparently\" suggests a lack of agreement or surprise, which can often indicate criticism or disappointment.", "annotation_request": "Consider the following movie review: Apparently, romantic comedy with a fresh point of view just doesn't figure in the present Hollywood program. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_79": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 24866, 29493, 17302, 19755, 1163, 1032, 6906, 2073, 1070, 2972, 1544, 3136, 29510, 29475, 6016, 1065, 1040, 2937, 14825, 2775, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.65625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Apparently\"}, {\"rationales\": \"doesn't\"}, {\"rationales\": \"figure\"}]"}
{"content": "That Haynes can both maintain and dismantle the facades that his genre and his character construct is a wonderous accomplishment of veracity and narrative grace.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], "response_80": "(a) This review is overall rather positive. The reviewer is praising the filmmaker's ability to both maintain and dismantle facades, suggesting that the movie is skillfully crafted and thought-provoking. The use of words like 'wonderous' and 'veracity' often imply a positive assessment.", "annotation_request": "Consider the following movie review: That Haynes can both maintain and dismantle the facades that his genre and his character construct is a wonderous accomplishment of veracity and narrative grace. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_80": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2493, 12179, 5279, 1309, 2328, 9855, 1072, 1472, 29487, 1208, 1059, 1040, 4020, 3318, 1137, 1284, 16694, 1072, 1284, 4001, 5890, 1117, 1032, 4151, 1375, 10373, 13011, 1070, 2197, 5574, 1072, 16297, 14522, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.53125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"wonderous\"}, {\"rationales\": \"veracity\"}]"}
{"content": "No French people were harmed during the making of this movie, but they were insulted and the audience was put through torture for an hour and a half.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], "response_81": "(b) This review is overall rather negative. The repetitive use of the word \"insulted\" and describing the audience as being \"put through torture\" suggests a negative experience. Additionally, the statement \"No French people were harmed during the making of this movie\" may be a sarcastic or ironic comment implying that something else, often more important, was neglected or damaged.", "annotation_request": "Consider the following movie review: No French people were harmed during the making of this movie, but they were insulted and the audience was put through torture for an hour and a half. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_81": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2538, 5717, 1673, 1422, 5180, 2359, 2706, 1040, 3260, 1070, 1224, 6762, 29493, 1330, 1358, 1422, 18209, 1054, 1072, 1040, 8706, 1171, 2426, 1827, 26794, 1122, 1164, 5883, 1072, 1032, 3563, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.234375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"insulted\"},\n{\"rationales\": \"torture\"},\n{\"rationales\": \"hour and a half\"},\n{\"rationales\": \"audience\"},\n{\"rationales\": \"neglected\"},\n{\"rationales\": \"damaged\"}\n]"}
{"content": "I was feeling this movie until it veered off too far into the Exxon zone, and left me behind at the station looking for a return ticket to realism.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], "response_82": "(b) This review is overall rather negative. The reviewer expresses disappointment with the movie for veering too far into unrealistic territory and leaving the viewer stranded in a surreal, inauthentic world. This suggests that the reviewer was expecting a more grounded, realistic film and found the opposite.", "annotation_request": "Consider the following movie review: I was feeling this movie until it veered off too far into the Exxon zone, and left me behind at the station looking for a return ticket to realism. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_82": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 1171, 5390, 1224, 6762, 2764, 1146, 2541, 2860, 1573, 2136, 2850, 1546, 1040, 2297, 29512, 1034, 9628, 29493, 1072, 2517, 1296, 3678, 1206, 1040, 5854, 3294, 1122, 1032, 1372, 14258, 1066, 2121, 2211, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"veered\"},\n{\"rationales\": \"Exxon\"},\n{\"rationales\": \"left\"},\n{\"rationales\": \"behind\"},\n{\"rationales\": \"station\"},\n{\"rationales\": \"return\"},\n{\"rationales\": \"ticket\"},\n{\"rationales\": \"realism\"},\n{\"rationales\": \"disappointment\"},\n{\"rationales\": \"unrealistic\"},\n{\"rationales\": \"surreal\"}\n]"}
{"content": "Exceptionally well acted by Diane Lane and Richard Gere.", "true_label": 1, "gold_label_rationales": [1, 1, 1, 0, 0, 0, 0, 0, 0], "response_83": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Exceptionally well acted by Diane Lane and Richard Gere. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_83": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 7779, 1346, 1930, 21152, 1254, 1152, 19629, 19797, 1072, 7127, 1188, 1165, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Exceptionally\"}, {\"rationales\": \"well acted\"}, {\"rationales\": \"Diane Lane\"}]"}
{"content": "A stupid, derivative horror film that substitutes extreme gore for suspense.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_84": "(b) This review is overall rather negative. The reviewer uses words like \"stupid,\" \"derivative,\" and \"extreme gore\" to express a negative opinion about the movie, and the phrase \"substitutes extreme gore for suspense\" also indicates a criticism of the film's quality.", "annotation_request": "Consider the following movie review: A stupid, derivative horror film that substitutes extreme gore for suspense. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_84": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 9478, 29493, 26123, 15800, 3734, 1137, 12149, 20313, 13058, 1087, 1199, 1122, 19502, 1826, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.484375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"stupid\"]}, {\"rationales\": [\"derivative\"]}, {\"rationales\": [\"gore\"]}, {\"rationales\": [\"substitutes\"]}]"}
{"content": "It's a great American adventure and a wonderful film to bring to IMAX.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], "response_85": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's a great American adventure and a wonderful film to bring to IMAX. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_85": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1032, 2366, 3324, 16750, 1072, 1032, 9358, 3734, 1066, 3736, 1066, 1083, 6346, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.328125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"great\"}, {\"rationales\": \"wonderful\"}, {\"rationales\": \"IMAX\"}, {\"rationales\": \"American adventure\"}]"}
{"content": "A miraculous movie, I'm Going Home is so slight, yet overflows with wisdom and emotion.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], "response_86": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: A miraculous movie, I'm Going Home is so slight, yet overflows with wisdom and emotion. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_86": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 6844, 1091, 10272, 6762, 29493, 1083, 29510, 29487, 26427, 7202, 1117, 1347, 6311, 29493, 3551, 1522, 1902, 4379, 1163, 17447, 1072, 13965, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"miraculous\"}, {\"rationales\": \"slight\"}, {\"rationales\": \"overflows\"}, {\"rationales\": \"wisdom\"}, {\"rationales\": \"emotion\"}, {\"rationales\": \"I'm Going Home\"}, {\"rationales\": \"positive\"}]"}
{"content": "A fiercely clever and subtle film, capturing the precarious balance between the extravagant confidence of the exiled aristocracy and the cruel earnestness of the victorious revolutionaries.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_87": "(a) This review is overall rather positive. The use of words such as \"fiercely clever,\" \"subtle,\" and the mention of the film capturing a balance between contrasting themes often indicates a positive viewpoint. The reviewer's appreciation for the film's characteristics suggests a favorable response.", "annotation_request": "Consider the following movie review: A fiercely clever and subtle film, capturing the precarious balance between the extravagant confidence of the exiled aristocracy and the cruel earnestness of the victorious revolutionaries. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_87": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 17075, 29485, 1491, 20113, 1072, 19610, 3734, 29493, 5054, 2146, 1040, 5235, 1051, 1693, 8641, 2212, 1040, 10005, 1262, 1125, 1208, 10611, 1070, 1040, 1207, 5128, 26806, 4572, 3194, 1072, 1040, 19733, 7152, 1142, 2235, 1070, 1040, 5569, 17232, 11797, 5606, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.46875], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"fiercely\"},\n{\"rationales\": \"clever\"},\n{\"rationales\": \"subtle\"}\n]"}
{"content": "It's as if you're watching a movie that was made in 1978 but not released then because it was so weak, and it has been unearthed and released now, when it has become even weaker.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_88": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: It's as if you're watching a movie that was made in 1978 but not released then because it was so weak, and it has been unearthed and released now, when it has become even weaker. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_88": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1158, 1281, 1136, 29510, 1035, 7033, 1032, 6762, 1137, 1171, 2037, 1065, 29473, 29508, 29542, 29555, 29551, 1330, 1227, 6010, 1636, 1864, 1146, 1171, 1347, 7102, 29493, 1072, 1146, 1427, 1518, 2987, 1212, 1655, 1072, 6010, 1823, 29493, 1507, 1146, 1427, 3495, 1787, 1246, 5544, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.28125], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"weak\"},\n{\"rationales\": \"unearthed\"},\n{\"rationales\": \"released\"},\n{\"rationales\": \"so weak\"},\n{\"rationales\": \"even weaker\"},\n{\"rationales\": \"1978\"},\n{\"rationales\": \"not released\"}\n]"}
{"content": "Thanks to a small star with big heart, this family film sequel is plenty of fun for all.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], "response_89": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Thanks to a small star with big heart, this family film sequel is plenty of fun for all. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_89": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9636, 1066, 1032, 2509, 5348, 1163, 2800, 3799, 29493, 1224, 2773, 3734, 6099, 1069, 1117, 9737, 1070, 1514, 1122, 1312, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.140625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"fun\"}, {\"rationales\": \"big heart\"}, {\"rationales\": \"plenty\"}, {\"rationales\": \"sequel\"}, {\"rationales\": \"family\"}]"}
{"content": "Festers in just such a dungpile that you'd swear you were watching monkeys flinging their feces at you.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0], "response_90": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Festers in just such a dungpile that you'd swear you were watching monkeys flinging their feces at you. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_90": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1169, 1042, 2300, 1065, 1544, 2027, 1032, 1049, 1737, 29488, 1314, 1137, 1136, 29510, 29483, 24177, 1136, 1422, 7033, 2094, 7566, 1740, 25599, 1420, 1469, 2145, 1206, 1136, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.5625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"dungpile\"}, {\"rationales\": \"flinging\"}, {\"rationales\": \"feces\"}]"}
{"content": "under-rehearsed and lifeless", "true_label": 0, "gold_label_rationales": [1, 0, 1], "response_91": "(b) This review is overall rather negative. The terms \"under-rehearsed\" and \"lifeless\" suggest that the person writing the review found the performance or production lacking in some way.", "annotation_request": "Consider the following movie review: under-rehearsed and lifeless \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_91": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1684, 29501, 1035, 1033, 1936, 1054, 1072, 6446, 6967, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.03125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"under-rehearsed\"]}, {\"rationales\": [\"lifeless\"]}]"}
{"content": "For those for whom the name Woody Allen was once a guarantee of something fresh, sometimes funny, and usually genuinely worthwhile, Hollywood Ending is a depressing experience.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_92": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: For those for whom the name Woody Allen was once a guarantee of something fresh, sometimes funny, and usually genuinely worthwhile, Hollywood Ending is a depressing experience. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_92": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2031, 2163, 1122, 6873, 1040, 1909, 8778, 29492, 14963, 1171, 3095, 1032, 13355, 1070, 2313, 6906, 29493, 5430, 10800, 29493, 1072, 5080, 23216, 5175, 6181, 29493, 14825, 6532, 1056, 1117, 1032, 29053, 1056, 3427, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"depressing\"]}, {\"rationales\": [\"worthwhile\"]}]"}
{"content": "The fun of the movie is the chance it affords to watch Jackson, who also served as executive producer, take his smooth, shrewd, powerful act abroad.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], "response_93": "(a) This review is overall rather positive because the reviewer mentions the enjoyment of watching Jackson's performance abroad, which implies they enjoyed the movie.", "annotation_request": "Consider the following movie review: The fun of the movie is the chance it affords to watch Jackson, who also served as executive producer, take his smooth, shrewd, powerful act abroad. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_93": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1514, 1070, 1040, 6762, 1117, 1040, 5444, 1146, 2979, 5086, 1066, 3822, 10723, 29493, 1461, 1603, 6885, 1158, 12980, 14644, 29493, 2156, 1284, 8666, 29493, 1248, 3284, 29483, 29493, 7555, 1728, 19604, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.59375], "answer": 29476, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"fun\"\n},\n{\n\"rationales\": \"watch\"\n},\n{\n\"rationales\": \"enjoy\"\n},\n{\n\"rationales\": \"smooth\"\n},\n{\n\"rationales\": \"powerful\"\n}\n]"}
{"content": "What should have been a cutting Hollywood satire is instead about as fresh as last week's issue of Variety.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], "response_94": "(b) This review is overall rather negative. The use of phrases such as \"as fresh as last week's issue of Variety\" suggests critique or disappointment with the movie, indicating a negative review.", "annotation_request": "Consider the following movie review: What should have been a cutting Hollywood satire is instead about as fresh as last week's issue of Variety. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_94": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2592, 1791, 1274, 1518, 1032, 12932, 14825, 3263, 1304, 1117, 4287, 1452, 1158, 6906, 1158, 2200, 2587, 29510, 29481, 5059, 1070, 13528, 3407, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"cutting\"},\n{\"rationales\": \"Hollywood\"},\n{\"rationales\": \"satire\"},\n{\"rationales\": \"fresh\"},\n{\"rationales\": \"Variety\"},\n{\"rationales\": \"last\"},\n{\"rationales\": \"weeks\"},\n{\"rationales\": \"issue\"}\n]"}
{"content": "Cox offers plenty of glimpses at existing photos, but there are no movies of Nijinsky, so instead the director treats us to an aimless hodgepodge.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_95": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Cox offers plenty of glimpses at existing photos, but there are no movies of Nijinsky, so instead the director treats us to an aimless hodgepodge. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_95": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1102, 1910, 6519, 9737, 1070, 2040, 1089, 1550, 1042, 1206, 7362, 9654, 29493, 1330, 1504, 1228, 1476, 11383, 1070, 1186, 1998, 27747, 29493, 1347, 4287, 1040, 7627, 28146, 1360, 1066, 1164, 7271, 2271, 1063, 13935, 29488, 13935, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.46875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"hodgepodge\"]}, {\"rationales\": [\"aimless\"]}]"}
{"content": "Mr. Soderbergh's direction and visual style struck me as unusually and unimpressively fussy and pretentious.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], "response_96": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Mr. Soderbergh's direction and visual style struck me as unusually and unimpressively fussy and pretentious. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_96": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3732, 29491, 1086, 6490, 1305, 1359, 29510, 29481, 5775, 1072, 9577, 4006, 12146, 1296, 1158, 13217, 2091, 1072, 1289, 1089, 2170, 3028, 1053, 23983, 1072, 10293, 1076, 1693, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.140625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"fussy\"}, {\"rationales\": \"unusually\"}, {\"rationales\": \"unimpressively\"}, {\"rationales\": \"pretentious\"}]"}
{"content": "Mazel tov to a film about a family's joyous life acting on the Yiddish stage.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "response_97": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Mazel tov to a film about a family's joyous life acting on the Yiddish stage. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_97": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 25899, 1069, 1066, 29496, 1066, 1032, 3734, 1452, 1032, 2773, 29510, 29481, 10954, 1375, 2179, 11369, 1124, 1040, 1395, 3326, 1557, 6198, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.359375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"joyous\"}, {\"rationales\": \"Mazel\"}, {\"rationales\": \"family's life\"}]"}
{"content": "An inspiring and heart-affecting film about the desperate attempts of Vietnamese refugees living in U.S. relocation camps to keep their hopes alive in 1975.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], "response_98": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: An inspiring and heart-affecting film about the desperate attempts of Vietnamese refugees living in U.S. relocation camps to keep their hopes alive in 1975. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_98": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 6455, 6317, 1072, 3799, 29501, 2914, 1298, 1056, 3734, 1452, 1040, 18121, 13967, 1070, 11992, 6657, 29474, 26379, 4455, 1065, 1268, 29491, 29503, 29491, 1784, 10769, 19265, 1066, 2608, 1420, 16489, 9398, 1065, 29473, 29508, 29542, 29555, 29550, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"inspiring\"}, {\"rationales\": \"heart-affecting\"}, {\"rationales\": \"desperate attempts\"}, {\"rationales\": \"keep their hopes alive\"}]"}
{"content": "Loud, chaotic and largely unfunny.", "true_label": 0, "gold_label_rationales": [1, 1, 0, 0, 1], "response_99": "(b) This review is overall rather negative. The use of adjectives such as \"loud,\" \"chaotic,\" and \"unfunny\" generally imply a negative opinion about the movie being reviewed.", "annotation_request": "Consider the following movie review: Loud, chaotic and largely unfunny. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_99": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1161, 3224, 29493, 11123, 8607, 1072, 13050, 1289, 2523, 2548, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [29.9375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"loud\"}, {\"rationales\": \"chaotic\"}, {\"rationales\": \"unfunny\"}]"}
{"content": "The immersive powers of the giant screen and its hyper-realistic images are put to perfect use in the breathtakingly beautiful outer-space documentary Space Station 3D.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], "response_100": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: The immersive powers of the giant screen and its hyper-realistic images are put to perfect use in the breathtakingly beautiful outer-space documentary Space Station 3D. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_100": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 5261, 1172, 1263, 12518, 1070, 1040, 13119, 5689, 1072, 1639, 12271, 29501, 7255, 4088, 6971, 1228, 2426, 1066, 4427, 1706, 1065, 1040, 13873, 1175, 2056, 1114, 5440, 13627, 29501, 4371, 22822, 14265, 14122, 29473, 29538, 29525, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"immersive\"}, {\"rationales\": \"breathtakingly beautiful\"}, {\"rationales\": \"giant screen\"}, {\"rationales\": \"hyper-realistic images\"}]"}
{"content": "It's everything you don't go to the movies for.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0], "response_101": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: It's everything you don't go to the movies for. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_101": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 3673, 1136, 1717, 29510, 29475, 1344, 1066, 1040, 11383, 1122, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.40625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"everything you don't go to the movies for\"}]"}
{"content": "Allen's funniest and most likeable movie in years.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 1, 0, 0, 0], "response_102": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Allen's funniest and most likeable movie in years. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_102": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 14963, 29510, 29481, 1514, 3791, 1142, 1072, 1848, 1505, 1290, 6762, 1065, 2035, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.296875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"funniest\"}, {\"rationales\": \"likeable\"}, {\"rationales\": \"years\"}]"}
{"content": "For those who pride themselves on sophisticated, discerning taste, this might not seem like the proper cup of tea, however it is almost guaranteed that even the stuffiest cinema goers will laugh their 1*** off for an hour-and-a-half.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], "response_103": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: For those who pride themselves on sophisticated, discerning taste, this might not seem like the proper cup of tea, however it is almost guaranteed that even the stuffiest cinema goers will laugh their 1*** off for an hour-and-a-half. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_103": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2031, 2163, 1461, 15152, 4660, 1124, 23981, 29493, 3080, 1031, 1739, 9998, 29493, 1224, 2427, 1227, 2477, 1505, 1040, 5747, 6979, 1070, 10278, 29493, 4313, 1146, 1117, 3547, 18581, 1137, 1787, 1040, 5473, 12049, 23673, 1344, 1172, 1390, 6531, 1420, 29473, 29508, 17391, 1573, 1122, 1164, 5883, 29501, 1159, 29501, 29476, 29501, 19350, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.5], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"laugh...\"}, {\"rationales\": \"hour-and-a-half\"}]"}
{"content": "There is a refreshing absence of cynicism in Stuart Little 2 -- quite a rarity, even in the family film market.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_104": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: There is a refreshing absence of cynicism in Stuart Little 2 -- quite a rarity, even in the family film market. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_104": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2155, 1117, 1032, 25111, 3067, 14609, 1070, 1045, 1803, 26931, 1065, 24501, 10767, 29473, 29518, 2707, 4216, 1032, 1176, 12678, 29493, 1787, 1065, 1040, 2773, 3734, 3436, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.4375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"refreshing\"}, {\"rationales\": \"absence\"}, {\"rationales\": \"cynicism\"}, {\"rationales\": \"rarity\"}]"}
{"content": "There are plot holes big enough for Shamu the killer whale to swim through.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_105": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: There are plot holes big enough for Shamu the killer whale to swim through. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_105": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2155, 1228, 10010, 15898, 2800, 2834, 1122, 2063, 1082, 29486, 1040, 19121, 1156, 1651, 1066, 11691, 1827, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.734375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"plot\"]}, {\"rationales\": [\"holes\"]}]"}
{"content": "... always remains movingly genuine.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1], "response_106": "(a) This review is overall rather positive. The use of words like \"movingly genuine\" typically conveys a positive sentiment towards the movie being reviewed.", "annotation_request": "Consider the following movie review: ... always remains movingly genuine. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_106": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 2511, 8288, 6040, 1114, 17736, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"movingly\"}, {\"rationales\": \"genuine\"}]"}
{"content": "Stitch is a bad mannered, ugly and destructive little ****.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 0, 1, 0, 1], "response_107": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Stitch is a bad mannered, ugly and destructive little ****. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_107": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1430, 2754, 1117, 1032, 3375, 9485, 1054, 29493, 20047, 1072, 26042, 1263, 2396, 29473, 1333, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [29.78125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"bad mannered\"}, {\"rationales\": \"ugly\"}, {\"rationales\": \"destructive\"}, {\"rationales\": \"little\"}, {\"rationales\": \"****\"}]"}
{"content": "The cast is top-notch and I predict there will be plenty of female audience members drooling over Michael Idemoto as Michael.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0], "response_108": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The cast is top-notch and I predict there will be plenty of female audience members drooling over Michael Idemoto as Michael. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_108": 1, "relevance_lrp": [16.046875, 0.002292633056640625, 0.3291015625, 0.0836181640625, 0.26025390625, -0.0718994140625, 0.1025390625, 0.1484375, 0.0180206298828125, -0.089111328125, 0.025909423828125, -0.0148773193359375, -0.010284423828125, -0.0041351318359375, -0.0007295608520507812, 0.041961669921875, 0.028289794921875, 0.08538818359375, 0.021240234375, 0.024688720703125, -0.002410888671875, 0.00420379638671875, 0.0065765380859375, -0.03424072265625, -0.0007290840148925781, 0.0221710205078125, -0.0026302337646484375, 0.004055023193359375, 0.0124359130859375, 0.0266265869140625, -0.004001617431640625, 0.030029296875, 0.0369873046875, 0.0223846435546875, -0.016143798828125, 0.0249481201171875, -0.0002593994140625, -0.1650390625, 1.33203125, 0.1358642578125, 0.2413330078125, 0.140625, 0.110595703125, 0.10992431640625, 0.392822265625, 0.3671875, 0.05145263671875, 0.02880859375, 0.1455078125, 0.51220703125, 0.2298583984375, 0.08050537109375, 0.32958984375, 0.77099609375, 0.390869140625, 0.169921875, 0.407958984375, 1.0693359375, 2.0234375, 0.2352294921875, 0.0163421630859375, 0.1431884765625, 0.03985595703125, 0.10040283203125, 0.06573486328125, 0.2342529296875, 0.1375732421875, 0.12939453125, 0.181640625, 0.87939453125, 0.057037353515625, 0.00887298583984375, 0.010345458984375, 0.014129638671875, 0.0241851806640625, 0.01168060302734375, 0.050811767578125, 0.04425048828125, 0.07330322265625, 0.2220458984375, 0.2281494140625, 0.2001953125, 0.032989501953125, 2.6953125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 5583, 1117, 2598, 29501, 2246, 1106, 1072, 1083, 7550, 1504, 1390, 1115, 9737, 1070, 8510, 8706, 4106, 4251, 1096, 1056, 1522, 6227, 7086, 1134, 3355, 1158, 6227, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"top-notch\"}, {\"rationales\": \"plenty\"}, {\"rationales\": \"drooling\"}, {\"rationales\": \"Michael\"}, {\"rationales\": \"predicate\"}, {\"rationales\": \"female audience members\"}]"}
{"content": "Kirshner and Monroe seem to be in a contest to see who can out-bad-act the other.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1], "response_109": "(b) This review is overall rather negative", "annotation_request": "Consider the following movie review: Kirshner and Monroe seem to be in a contest to see who can out-bad-act the other. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_109": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9574, 1579, 1847, 1072, 3985, 23802, 2477, 1066, 1115, 1065, 1032, 14736, 1066, 1800, 1461, 1309, 1343, 29501, 12204, 29501, 1340, 1040, 1567, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.84375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Kirshner\"}, {\"rationales\": \"Monroe\"}, {\"rationales\": \"contest\"}, {\"rationales\": \"out-bad-act\"}, {\"rationales\": \"other\"}, {\"rationales\": \"negative\"}]"}
{"content": "This is one of those war movies that focuses on human interaction rather than battle and action sequences... and it's all the stronger because of it.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], "response_110": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: This is one of those war movies that focuses on human interaction rather than battle and action sequences... and it's all the stronger because of it. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_110": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 1117, 1392, 1070, 2163, 2264, 11383, 1137, 21933, 1124, 3698, 11954, 3978, 1589, 7419, 1072, 3760, 23224, 1869, 1072, 1146, 29510, 29481, 1312, 1040, 13542, 1864, 1070, 1146, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.5], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"one\"},{\"rationales\": \"stronger\"},{\"rationales\": \"war\"},{\"rationales\": \"human\"},{\"rationales\": \"interaction\"},{\"rationales\": \"all\"},{\"rationales\": \"positive\"}]"}
{"content": "Like life on the island, the movie grows boring despite the scenery.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], "response_111": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Like life on the island, the movie grows boring despite the scenery. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_111": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6178, 2179, 1124, 1040, 9687, 29493, 1040, 6762, 21150, 20525, 8345, 1040, 1520, 1558, 29492, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"boring\"]}, {\"rationales\": [\"grow\"]}]"}
{"content": "It's anchored by splendid performances from an honored screen veteran and a sparkling newcomer who instantly transform themselves into a believable mother/daughter pair.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "response_112": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: It's anchored by splendid performances from an honored screen veteran and a sparkling newcomer who instantly transform themselves into a believable mother/daughter pair. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_112": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 25491, 3223, 1254, 8922, 1184, 1081, 18255, 1245, 1164, 4011, 3223, 5689, 24728, 1072, 1032, 14891, 2673, 1401, 1443, 1031, 1461, 16971, 6284, 4660, 1546, 1032, 2757, 29496, 1290, 3825, 29516, 29483, 5530, 6732, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"splendid\"}, {\"rationales\": \"honored\"}, {\"rationales\": \"sparkling\"}, {\"rationales\": \"believable\"}, {\"rationales\": \"transform\"}]"}
{"content": "An atonal estrogen opera that demonizes feminism while gifting the most sympathetic male of the piece with a nice vomit bath at his wedding.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "response_113": "(b) This review is overall rather negative. The phrases like \"atonal estrogen opera,\" \"demonizes feminism,\" and \"nice vomit bath\" suggest a critical or unfavorable stance towards the movie.", "annotation_request": "Consider the following movie review: An atonal estrogen opera that demonizes feminism while gifting the most sympathetic male of the piece with a nice vomit bath at his wedding. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_113": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 1206, 14689, 1702, 26270, 19627, 1137, 6530, 5772, 14194, 2211, 2080, 1087, 13888, 1040, 1848, 5065, 28410, 8630, 1070, 1040, 6279, 1163, 1032, 5939, 10090, 1047, 7812, 1206, 1284, 9968, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.71875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"atonal\"}, {\"rationales\": \"demonizes\"}, {\"rationales\": \"vomit bath\"}]"}
{"content": "Even by the intentionally low standards of frat-boy humor, Sorority Boys is a bowser.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1], "response_114": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Even by the intentionally low standards of frat-boy humor, Sorority Boys is a bowser. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_114": 0, "relevance_lrp": [14.6171875, 0.0005321502685546875, 0.273193359375, 0.06427001953125, 0.2197265625, -0.06341552734375, 0.057403564453125, 0.152099609375, 0.040771484375, 0.0140838623046875, -0.03436279296875, 0.0289459228515625, 0.01128387451171875, 0.0257110595703125, 0.006145477294921875, 0.0125274658203125, -0.0012989044189453125, 0.00214385986328125, -0.0083160400390625, 0.00689697265625, 0.0134735107421875, -0.00569915771484375, -0.0213775634765625, -0.0159759521484375, -0.005054473876953125, -0.01117706298828125, -0.0008568763732910156, -0.045684814453125, 0.0361328125, 0.045745849609375, -0.01399993896484375, -0.1602783203125, 1.3583984375, 0.1751708984375, 0.27001953125, 0.20849609375, 0.135986328125, 0.11480712890625, 0.389892578125, 0.494140625, 0.0026149749755859375, -0.1903076171875, 0.127197265625, 0.5263671875, 0.182373046875, 0.0732421875, 0.266357421875, 0.767578125, 0.40625, 0.1912841796875, 0.348388671875, 0.50634765625, 1.1552734375, 0.31689453125, 0.0271148681640625, 0.1336669921875, 0.081787109375, 0.1651611328125, 0.034637451171875, 0.272705078125, 0.1876220703125, 0.196533203125, 0.60009765625, 2.287109375, 0.056732177734375, 0.0119476318359375, 0.034515380859375, 0.00940704345703125, 0.00017142295837402344, 0.0240936279296875, 0.11981201171875, 0.038909912109375, 0.0853271484375, 0.26220703125, 0.234375, 0.178466796875, 0.031463623046875, 2.44921875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4895, 1254, 1040, 13550, 1346, 3627, 10658, 1070, 1872, 1038, 29501, 15571, 18044, 29493, 22244, 1039, 1240, 21112, 1117, 1032, 7215, 1225, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.609375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"frat-boy humor\"}, {\"rationales\": \"bowser\"}, {\"rationales\": \"intentionally low standards\"}]"}
{"content": "Director of photography Benoit Delhomme shot the movie in delicious colors, and the costumes and sets are grand.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1], "response_115": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Director of photography Benoit Delhomme shot the movie in delicious colors, and the costumes and sets are grand. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_115": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 10066, 1070, 20592, 4889, 29477, 1047, 6294, 12734, 1895, 5948, 1040, 6762, 1065, 16760, 10072, 29493, 1072, 1040, 3202, 10511, 1072, 7259, 1228, 4255, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.5], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"delicious\"}, {\"rationales\": \"grand\"}, {\"rationales\": \"shot\"}, {\"rationales\": \"costumes\"}]"}
{"content": "The only entertainment you'll derive from this choppy and sloppy affair will be from unintentional giggles -- several of them.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], "response_116": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The only entertainment you'll derive from this choppy and sloppy affair will be from unintentional giggles -- several of them. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_116": 0, "relevance_lrp": [15.4140625, 0.003162384033203125, 0.29296875, 0.07818603515625, 0.24951171875, -0.056396484375, 0.097900390625, 0.138916015625, 0.03216552734375, 0.040679931640625, -0.04638671875, -0.037261962890625, -0.0108642578125, -0.02227783203125, -0.052947998046875, 0.005458831787109375, -0.0159149169921875, 0.037139892578125, 0.003093719482421875, 0.021484375, 0.0262451171875, 0.023193359375, 0.020355224609375, -0.0018978118896484375, 0.0167236328125, 0.0025653839111328125, 0.004886627197265625, -0.01036834716796875, -0.0103759765625, -0.0018053054809570312, -0.0887451171875, -0.0281219482421875, 0.01837158203125, -0.0361328125, -0.01335906982421875, 0.0035610198974609375, -0.03619384765625, -0.059417724609375, 0.6533203125, 0.1937255859375, 0.28955078125, 0.204345703125, 0.130126953125, 0.1260986328125, 0.397705078125, 0.481201171875, 0.007080078125, -0.1766357421875, 0.1287841796875, 0.55908203125, 0.1727294921875, 0.0770263671875, 0.284912109375, 0.7236328125, 0.419921875, 0.1953125, 0.343017578125, 0.51611328125, 1.1357421875, 0.336181640625, 0.0308837890625, 0.18115234375, 0.08740234375, 0.200439453125, 0.0545654296875, 0.336669921875, 0.1895751953125, 0.199462890625, 0.59423828125, 2.30078125, 0.051239013671875, 0.0085296630859375, 0.0457763671875, 0.02056884765625, -0.00824737548828125, 0.031005859375, 0.1260986328125, 0.0496826171875, 0.08428955078125, 0.265380859375, 0.2423095703125, 0.1962890625, 0.0302734375, 2.39453125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1633, 15943, 1136, 29510, 1352, 24826, 1245, 1224, 17579, 3602, 1072, 1903, 1178, 3602, 19947, 1390, 1115, 1245, 1289, 29327, 2247, 14558, 17752, 2707, 3624, 1070, 1474, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"choppy\"},\n{\"rationales\": \"sloppy\"},\n{\"rationales\": \"affair\"},\n{\"rationales\": \"giggles\"},\n{\"rationales\": \"unintentional\"}\n]"}
{"content": "A bittersweet contemporary comedy about benevolent deception, which, while it may not rival the filmmaker's period pieces, is still very much worth seeing.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_117": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A bittersweet contemporary comedy about benevolent deception, which, while it may not rival the filmmaker's period pieces, is still very much worth seeing. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_117": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 3054, 2300, 13291, 14389, 19755, 1452, 3566, 1596, 27114, 1108, 2045, 29493, 1458, 29493, 2080, 1146, 1761, 1227, 17332, 1040, 3734, 20731, 29510, 29481, 3984, 8537, 29493, 1117, 2077, 1983, 1956, 5175, 7020, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.796875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"bittersweet\"}, {\"rationales\": \"benevolent\"}, {\"rationales\": \"contemporary\"}, {\"rationales\": \"comedy\"}, {\"rationales\": \"worth\"}, {\"rationales\": \"seeing\"}]"}
{"content": "Attal pushes too hard to make this a comedy or serious drama.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_118": "(b) This review is overall rather negative. The critique about pushing too hard suggests a disapproval of the director's approach, which indicates a less favorable review.", "annotation_request": "Consider the following movie review: Attal pushes too hard to make this a comedy or serious drama. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_118": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6056, 1050, 1052, 18393, 2136, 2624, 1066, 1806, 1224, 1032, 19755, 1210, 5360, 14560, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.15625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Attal pushes\"}, {\"rationales\": \"comedy\"}, {\"rationales\": \"serious drama\"}]"}
{"content": "Isabelle Huppert excels as the enigmatic Mika and Anna Mouglalis is a stunning new young talent in one of Chabrol's most intense psychological mysteries.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_119": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Isabelle Huppert excels as the enigmatic Mika and Anna Mouglalis is a stunning new young talent in one of Chabrol's most intense psychological mysteries. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_119": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 22042, 1059, 1150, 1483, 3250, 3591, 1958, 1158, 1040, 1249, 1094, 20863, 1119, 6780, 1072, 11874, 1119, 1048, 2495, 12324, 1117, 1032, 21265, 1401, 3286, 10002, 1065, 1392, 1070, 1457, 1143, 2206, 29510, 29481, 1848, 15141, 19603, 16860, 1265, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.640625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Isabelle Huppert excels\"}, {\"rationales\": \"stunning new young talent\"}, {\"rationales\": \"Chabrol's most intense\"}, {\"rationales\": \"psychological mystery\"}]"}
{"content": "A small movie with a big impact.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1], "response_120": "(a) This review is overall rather positive. The phrase \"A small movie with a big impact\" suggests that despite the movie being small in scale, it has had a profound effect or impact, which is typically a positive characteristic noted in reviews.", "annotation_request": "Consider the following movie review: A small movie with a big impact. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_120": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 2509, 6762, 1163, 1032, 2800, 5856, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.65625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"big impact\"}]"}
{"content": "This bold and lyrical first feature from Raja Amari expands the pat notion that middle-aged women just wanna have fun into a rousing treatise of sensual empowerment.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_121": "(a) This review is overall rather positive. The language used, such as \"bold,\" \"lyrical,\" \"rousing,\" and \"treatise of sensual empowerment,\" indicate a positive critique of the movie. The reviewer also expresses a positive sentiment when they describe the film as expanding a \"pat notion\" into a \"reatise of sensual empowerment.\"", "annotation_request": "Consider the following movie review: This bold and lyrical first feature from Raja Amari expands the pat notion that middle-aged women just wanna have fun into a rousing treatise of sensual empowerment. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_121": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 16628, 1072, 1073, 5137, 1513, 1675, 5248, 1245, 1167, 12977, 3508, 2668, 3133, 3119, 1040, 2676, 14854, 1137, 5754, 29501, 3337, 3293, 1544, 24825, 1274, 1514, 1546, 1032, 1176, 24059, 4131, 1632, 1070, 4332, 1608, 22525, 1234, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.265625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"bold\"}, {\"rationales\": \"lyrical\"}, {\"rationales\": \"rousing\"}, {\"rationales\": \"treatise\"}, {\"rationales\": \"sensual empowerment\"}]"}
{"content": "After that, it just gets stupid and maudlin.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 0, 1], "response_122": "(b) This review is overall rather negative. The phrases \"just gets stupid\" and \"maudlin\" suggest a negative opinion about the movie's development or tone.", "annotation_request": "Consider the following movie review: After that, it just gets stupid and maudlin. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_122": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3298, 1137, 29493, 1146, 1544, 5507, 9478, 1072, 4896, 1322, 3062, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"stupid\"}, {\"rationales\": \"maudlin\"}]"}
{"content": "The stunning, dreamlike visuals will impress even those viewers who have little patience for Euro-film pretension.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_123": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The stunning, dreamlike visuals will impress even those viewers who have little patience for Euro-film pretension. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_123": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 21265, 29493, 5767, 4859, 9577, 29481, 1390, 8663, 1787, 2163, 25654, 1461, 1274, 2396, 22637, 1122, 15637, 29501, 16884, 10293, 3353, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"stunning\"}, {\"rationales\": \"dreamlike\"}, {\"rationales\": \"impress\"}, {\"rationales\": \"viewers\"}]"}
{"content": "Impresses as a skillfully assembled, highly polished and professional adaptation... just about as chilling and unsettling as `Manhunter' was.", "true_label": 1, "gold_label_rationales": [1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_124": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Impresses as a skillfully assembled, highly polished and professional adaptation... just about as chilling and unsettling as `Manhunter' was. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_124": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3004, 2170, 1042, 1158, 1032, 11114, 3839, 27077, 29493, 7184, 1928, 2265, 1072, 5792, 26429, 1869, 1544, 1452, 1158, 1252, 9085, 1072, 23121, 29475, 2673, 1158, 2320, 3124, 29484, 17210, 29510, 1171, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"skillfully\"}, {\"rationales\": \"polished\"}, {\"rationales\": \"adaptation\"}, {\"rationales\": \"chilling\"}, {\"rationales\": \"unsettling\"}, {\"rationales\": \"`Manhunter`\"}]"}
{"content": "For the most part, it's a work of incendiary genius, steering clear of knee-jerk reactions and quick solutions.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_125": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: For the most part, it's a work of incendiary genius, steering clear of knee-jerk reactions and quick solutions. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_125": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2031, 1040, 1848, 1512, 29493, 1146, 29510, 29481, 1032, 1539, 1070, 3026, 1184, 29478, 1396, 22795, 29493, 3478, 2899, 3849, 1070, 16997, 29501, 29536, 7519, 22087, 1072, 3704, 7919, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"incendiary\"}, {\"rationales\": \"genius\"}]"}
{"content": "It's badly acted, blandly directed, and could have been scripted by someone who just graduated from elementary school.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_126": "(b) This review is overall rather negative because the words \"badly acted,\" \"blandly directed,\" and \"scribed by someone who just graduated from elementary school\" suggest poor performance, unengaging direction, and an unsophisticated script, all of which are generally negative criticisms in the context of a movie review.", "annotation_request": "Consider the following movie review: It's badly acted, blandly directed, and could have been scripted by someone who just graduated from elementary school. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_126": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 16262, 21152, 29493, 24262, 1114, 11434, 29493, 1072, 1597, 1274, 1518, 7535, 1054, 1254, 3261, 1461, 1544, 19983, 1245, 25035, 2820, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.4375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"badly acted\"},\n{\"rationales\": \"blandly directed\"},\n{\"rationales\": \"elementary school\"},\n{\"rationales\": \"scribed\"}\n]"}
{"content": "... a roller-coaster ride of a movie", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 1], "response_127": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: ... a roller-coaster ride of a movie \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_127": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 5363, 1031, 29501, 1883, 2761, 9783, 1070, 1032, 6762, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"roller-coaster\"}, {\"rationales\": \"ride\"}, {\"rationales\": \"movie\"}]"}
{"content": "A colorful, vibrant introduction to a universal human impulse, lushly photographed and beautifully recorded.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1], "response_128": "(a) This review is overall rather positive. The words \"colorful,\" \"vibrant,\" \"beautifully recorded,\" and \"lushly photographed\" indicate a positive or favorable evaluation of the movie in question.", "annotation_request": "Consider the following movie review: A colorful, vibrant introduction to a universal human impulse, lushly photographed and beautifully recorded. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_128": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 3949, 1775, 29493, 14314, 1208, 15068, 1066, 1032, 15366, 3698, 3592, 18262, 29493, 1073, 2194, 1114, 4492, 12647, 1655, 1072, 27856, 10132, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"colorful\"}, {\"rationales\": \"vibrant\"}, {\"rationales\": \"lushly photographed\"}, {\"rationales\": \"beautifully recorded\"}]"}
{"content": "Audiard successfully maintains suspense on different levels throughout a film that is both gripping and compelling.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], "response_129": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Audiard successfully maintains suspense on different levels throughout a film that is both gripping and compelling. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_129": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 11859, 1256, 10898, 6152, 2374, 19502, 1826, 1124, 2349, 6925, 6241, 1032, 3734, 1137, 1117, 2328, 16622, 8087, 1072, 27063, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.484375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"gripping\"}, {\"rationales\": \"compelling\"}, {\"rationales\": \"successfully\"}, {\"rationales\": \"maintains\"}, {\"rationales\": \"suspense\"}]"}
{"content": "Even horror fans will most likely not find what they're seeking with Trouble Every Day; the movie lacks both thrills and humor.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "response_130": "(b) This review is overall rather negative, as it suggests that \"even horror fans\" may not find what they're seeking in the movie and it lacks both thrills and humor.", "annotation_request": "Consider the following movie review: Even horror fans will most likely not find what they're seeking with Trouble Every Day; the movie lacks both thrills and humor. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_130": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4895, 15800, 9272, 1390, 1848, 4685, 1227, 2068, 1535, 1358, 29510, 1035, 12014, 1163, 1088, 1286, 1750, 4971, 6167, 29513, 1040, 6762, 6270, 29481, 2328, 7723, 3535, 1072, 18044, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.078125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Even\"}, {\"rationales\": \"not\"}, {\"rationales\": \"find\"}, {\"rationales\": \"Trouble\"}, {\"rationales\": \"Every Day\"}, {\"rationales\": \"lacks\"}]"}
{"content": "After that it becomes long and tedious like a classroom play in a college history course.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_131": "(b) This review is overall rather negative. The phrase \"long and tedious like a classroom play in a college history course\" implies the author found the movie unenjoyable, time-consuming, and possibly overly academic or boring.", "annotation_request": "Consider the following movie review: After that it becomes long and tedious like a classroom play in a college history course. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_131": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3298, 1137, 1146, 7523, 1811, 1072, 1029, 1054, 1693, 1505, 1032, 20497, 1924, 1065, 1032, 7070, 4108, 3131, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.5], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"long\"]}, {\"rationales\": [\"tedious\"]}]"}
{"content": "This is cool, slick stuff, ready to quench the thirst of an audience that misses the summer blockbusters.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], "response_132": "(a) This review is overall rather positive. The use of words like 'cool', 'slick', and 'quench the thirst' tends to indicate a favorable impression of the movie. The fact that the movie is compared to summer blockbusters also suggests positivity, as it implies the film has the excitement and appeal typically associated with those big-budget releases.", "annotation_request": "Consider the following movie review: This is cool, slick stuff, ready to quench the thirst of an audience that misses the summer blockbusters. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_132": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 1117, 5874, 29493, 1036, 4206, 5473, 29493, 5081, 1066, 1294, 1037, 1106, 1040, 1074, 1545, 1070, 1164, 8706, 1137, 3946, 1042, 1040, 6329, 3492, 29494, 13623, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.46875], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"cool\"},\n{\"rationales\": \"slick\"},\n{\"rationales\": \"quench\"},\n{\"rationales\": \"summer\"},\n{\"rationales\": \"blockbusters\"}\n]"}
{"content": "A loud, ugly, irritating movie without any of its satirical salvos hitting a discernible target.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "response_133": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A loud, ugly, irritating movie without any of its satirical salvos hitting a discernible target. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_133": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 10382, 29493, 20047, 29493, 17186, 1845, 6762, 2439, 1475, 1070, 1639, 3263, 26305, 19060, 1153, 18460, 1032, 3080, 1941, 1838, 3486, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.46875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"loud\"}, {\"rationales\": \"ugly\"}, {\"rationales\": \"irritating\"}, {\"rationales\": \"satirical salvos\"}, {\"rationales\": \"discernible target\"}]"}
{"content": "For VeggieTales fans, this is more appetizing than a side dish of asparagus.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], "response_134": "(a) This review is overall rather positive. The use of phrases like \"more appetizing\" suggests a positive opinion about the movie.", "annotation_request": "Consider the following movie review: For VeggieTales fans, this is more appetizing than a side dish of asparagus. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_134": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2031, 16176, 11723, 29506, 2998, 9272, 29493, 1224, 1117, 1448, 22913, 4632, 1589, 1032, 2849, 15291, 1070, 1158, 2157, 1125, 1149, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"appetizing\"}]"}
{"content": "A truly wonderful tale combined with stunning animation.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 1, 0], "response_135": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A truly wonderful tale combined with stunning animation. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_135": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 8065, 9358, 16410, 10605, 1163, 21265, 16501, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.03125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"wonderful\"}, {\"rationales\": \"stunning\"}, {\"rationales\": \"tale\"}]"}
{"content": "Nothing sticks, really, except a lingering creepiness one feels from being dragged through a sad, sordid universe of guns, drugs, avarice and damaged dreams.", "true_label": 0, "gold_label_rationales": [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_136": "(b) This review is overall rather negative. The reviewer uses words like \"creepiness,\" \"sad,\" \"sordid,\" \"guns,\" \"drugs,\" \"avarice,\" and \"damaged dreams\" which all convey a negative or grim atmosphere. The fact that \"nothing sticks\" suggested that the movie may not have left a strong or pleasant impact on the reviewer.", "annotation_request": "Consider the following movie review: Nothing sticks, really, except a lingering creepiness one feels from being dragged through a sad, sordid universe of guns, drugs, avarice and damaged dreams. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_136": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 11849, 26530, 29493, 2296, 29493, 4509, 1032, 18594, 2899, 24459, 2262, 1392, 9083, 1245, 2018, 20980, 1827, 1032, 8224, 29493, 1036, 1324, 1081, 12485, 1070, 12228, 29493, 11515, 29493, 1032, 1890, 1303, 1072, 17387, 13000, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"creepiness\"},\n{\"rationales\": \"sad\"},\n{\"rationales\": \"sordid\"},\n{\"rationales\": \"guns\"},\n{\"rationales\": \"drugs\"},\n{\"rationales\": \"avarice\"},\n{\"rationales\": \"damaged dreams\"}\n]"}
{"content": "``Simone'' is a fun and funky look into an artificial creation in a world that thrives on artificiality.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_137": "(a) This review is overall rather positive. The words \"fun,\" \"funky,\" and \"artificial creation\" suggest a favorable response. The reviewer seems to be enjoying the film and finds it interesting, as indicated by the phrase \"a look into an artificial creation.\"", "annotation_request": "Consider the following movie review: ``Simone'' is a fun and funky look into an artificial creation in a world that thrives on artificiality. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_137": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5776, 8322, 1306, 6205, 1117, 1032, 1514, 1072, 1514, 5613, 1681, 1546, 1164, 19046, 10081, 1065, 1032, 2294, 1137, 1074, 1582, 1042, 1124, 19046, 1240, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.703125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"fun\"}, {\"rationales\": \"funky\"}]"}
{"content": "It's a hoot watching The Rock chomp on jumbo ants, pull an arrow out of his back, and leap unscathed through raging fire!", "true_label": 1, "gold_label_rationales": [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "response_138": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: It's a hoot watching The Rock chomp on jumbo ants, pull an arrow out of his back, and leap unscathed through raging fire! \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_138": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1032, 1063, 2309, 7033, 1183, 8875, 1252, 24715, 1124, 1229, 1151, 2566, 1164, 1842, 29493, 4068, 1164, 19391, 1343, 1070, 1284, 1620, 29493, 1072, 27513, 1289, 1592, 1038, 1655, 1827, 1176, 4822, 4107, 29576, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.359375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"hoot\"}, {\"rationales\": \"unscathed\"}, {\"rationales\": \"jumbo ants\"}]"}
{"content": "While Tattoo borrows heavily from both Seven and The Silence of the Lambs, it manages to maintain both a level of sophisticated intrigue and human-scale characters that suck the audience in.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0], "response_139": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: While Tattoo borrows heavily from both Seven and The Silence of the Lambs, it manages to maintain both a level of sophisticated intrigue and human-scale characters that suck the audience in. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_139": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4791, 1088, 13444, 29477, 25631, 4309, 13527, 1245, 2328, 22051, 1072, 1183, 6812, 1404, 1070, 1040, 27015, 29481, 29493, 1146, 1444, 2059, 1066, 9855, 2328, 1032, 2952, 1070, 23981, 8445, 12984, 1072, 3698, 29501, 6473, 6896, 1137, 13143, 1040, 8706, 1065, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.71875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"sophisticated intrigue\"},{\"rationales\": \"human-scale characters\"},{\"rationales\": \"suck the audience in\"}]"}
{"content": "As written by Michael Berg and Michael J. Wilson from a story by Wilson, this relentless, all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], "response_140": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: As written by Michael Berg and Michael J. Wilson from a story by Wilson, this relentless, all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_140": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1904, 5009, 1254, 6227, 15581, 1072, 6227, 1243, 29491, 12189, 1245, 1032, 3606, 1254, 12189, 29493, 1224, 1784, 1076, 2271, 29493, 1312, 29501, 4346, 29501, 3619, 1614, 29501, 1223, 29501, 2005, 29501, 2304, 5199, 15512, 1837, 2136, 2624, 1072, 5507, 1029, 6317, 1065, 1476, 1495, 1206, 1312, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.265625], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"relentless\"\n},\n{\n\"rationales\": \"all-wise-guys-all-the-time\"\n},\n{\n\"rationales\": \"tries\"\n},\n{\n\"rationales\": \"way\"\n},\n{\n\"rationales\": \"too\"\n},\n{\n\"rationales\": \"hard\"\n},\n{\n\"rationales\": \"gets\"\n},\n{\n\"rationales\": \"tiring\"\n}\n]"}
{"content": "It's the best film of the year so far, the benchmark against which all other Best Picture contenders should be measured.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], "response_141": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's the best film of the year so far, the benchmark against which all other Best Picture contenders should be measured. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_141": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1040, 2257, 3734, 1070, 1040, 1647, 1347, 2850, 29493, 1040, 12752, 4093, 2603, 1458, 1312, 1567, 6238, 28640, 1447, 15698, 1791, 1115, 13588, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"best\"}, {\"rationales\": \"film\"}, {\"rationales\": \"year\"}, {\"rationales\": \"benchmark\"}, {\"rationales\": \"contenders\"}, {\"rationales\": \"measured\"}]"}
{"content": "This is one of the biggest disappointments of the year.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], "response_142": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: This is one of the biggest disappointments of the year. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_142": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 1117, 1392, 1070, 1040, 9732, 11502, 2107, 1070, 1040, 1647, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.453125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"disappointments\"]}, {\"rationales\": [\"year\"]}]"}
{"content": "It never fails to engage us.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 1, 0], "response_143": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It never fails to engage us. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_143": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 2252, 15066, 1066, 14968, 1360, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.09375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"engage\"}, {\"rationales\": \"us\"}, {\"rationales\": \"never\"}, {\"rationales\": \"fails\"}]"}
{"content": "The movie slides downhill as soon as macho action conventions assert themselves.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_144": "(b) This review is overall rather negative. The use of \"slides downhill\" implies a decline in quality, and the reference to \"macho action conventions\" suggests a disdain for a stereotypical and predictable plot development.", "annotation_request": "Consider the following movie review: The movie slides downhill as soon as macho action conventions assert themselves. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_144": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 28099, 1828, 19924, 1158, 4171, 1158, 9273, 29477, 3760, 13136, 1362, 2945, 4660, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.8125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"slides\"]}, {\"rationales\": [\"downhill\"]}]"}
{"content": "More romantic, more emotional and ultimately more satisfying than the teary-eyed original.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], "response_145": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: More romantic, more emotional and ultimately more satisfying than the teary-eyed original. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_145": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4532, 17302, 29493, 1448, 11294, 1072, 13433, 1448, 19326, 1589, 1040, 1479, 1396, 29501, 21500, 4261, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.921875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"satisfying\"}]"}
{"content": "Like the best of Godard's movies... it is visually ravishing, penetrating, impenetrable.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], "response_146": "(a) This review is overall rather positive. The use of words like \"visually ravishing,\" \"penetrating,\" and the inclusion of Godard's name, suggests that the reviewer appreciates the movie's aesthetics and its complexity, even if they admit it might be challenging to understand.", "annotation_request": "Consider the following movie review: Like the best of Godard's movies... it is visually ravishing, penetrating, impenetrable. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_146": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6178, 1040, 2257, 1070, 3267, 1256, 29510, 29481, 11383, 1869, 1146, 1117, 2485, 2091, 26550, 6364, 29493, 24596, 1845, 29493, 1271, 3516, 12950, 1290, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [28.828125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"visually ravishing\"}, {\"rationales\": \"penetrating\"}, {\"rationales\": \"Godard\"}]"}
{"content": "The cumulative effect of the movie is repulsive and depressing.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_147": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The cumulative effect of the movie is repulsive and depressing. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_147": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 15699, 21619, 2798, 1070, 1040, 6762, 1117, 2326, 8318, 1263, 1072, 29053, 1056, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.421875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"repulsive\"}, {\"rationales\": \"depressing\"}, {\"rationales\": \"cumulative effect\"}]"}
{"content": "A very long movie, dull in stretches, with entirely too much focus on meal preparation and igloo construction.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_148": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A very long movie, dull in stretches, with entirely too much focus on meal preparation and igloo construction. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_148": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1983, 1811, 6762, 29493, 22055, 1065, 8515, 2695, 29493, 1163, 8902, 2136, 1956, 4000, 1124, 12082, 17512, 1072, 13400, 1499, 29477, 7148, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"dull\"}, {\"rationales\": \"stretches\"}, {\"rationales\": \"entirely too much\"}]"}
{"content": "In XXX, Diesel is that rare creature -- an action hero with table manners, and one who proves that elegance is more than tattoo deep.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], "response_149": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: In XXX, Diesel is that rare creature -- an action hero with table manners, and one who proves that elegance is more than tattoo deep. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_149": 1, "relevance_lrp": [15.7578125, 0.0021076202392578125, 0.319091796875, 0.084228515625, 0.290771484375, -0.1419677734375, 0.08245849609375, 0.176025390625, 0.05596923828125, 0.11285400390625, 0.0104522705078125, 0.019561767578125, -0.003093719482421875, 0.0042266845703125, -0.00958251953125, 0.054290771484375, 0.0286712646484375, 0.007904052734375, -0.0167236328125, -0.0144805908203125, 0.0223846435546875, 0.018646240234375, 0.01111602783203125, 0.006988525390625, 0.00576019287109375, 0.0004100799560546875, -0.0032749176025390625, -0.0021724700927734375, 0.0052032470703125, 0.0019626617431640625, 0.01016998291015625, -0.0112152099609375, 0.001422882080078125, 0.0031280517578125, 0.015838623046875, 0.02203369140625, 0.0220947265625, 0.017364501953125, -0.003543853759765625, -0.1705322265625, 1.478515625, 0.1446533203125, 0.2457275390625, 0.154052734375, 0.10943603515625, 0.114990234375, 0.38916015625, 0.4091796875, 0.04473876953125, -0.029571533203125, 0.135986328125, 0.51953125, 0.2059326171875, 0.08416748046875, 0.330078125, 0.76318359375, 0.40234375, 0.17578125, 0.430419921875, 1.103515625, 2.09765625, 0.229736328125, -0.0012769699096679688, 0.1339111328125, 0.043609619140625, 0.10870361328125, 0.059417724609375, 0.2296142578125, 0.13818359375, 0.1304931640625, 0.17626953125, 0.86279296875, 0.05364990234375, 0.00848388671875, 0.01025390625, 0.01215362548828125, 0.0249481201171875, 0.01215362548828125, 0.04718017578125, 0.046112060546875, 0.07708740234375, 0.236328125, 0.239990234375, 0.1905517578125, 0.03375244140625, 2.654296875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1328, 21795, 29493, 12171, 1069, 1117, 1137, 10732, 16055, 2707, 1164, 3760, 11493, 1163, 3169, 1444, 6717, 29493, 1072, 1392, 1461, 26600, 1137, 13767, 1385, 1117, 1448, 1589, 28873, 4302, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.859375], "answer": 29476, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"Diesel\"\n},\n{\n\"rationales\": \"action hero\"\n},\n{\n\"rationales\": \"table manners\"\n},\n{\n\"rationales\": \"elegance\"\n},\n{\n\"rationales\": \"rare creature\"\n},\n{\n\"rationales\": \"proves\"\n},\n{\n\"rationales\": \"one\"\n},\n{\n\"rationales\": \"who\"\n}\n]"}
{"content": "I'm not sure which will take longer to heal: the welt on Johnny Knoxville's stomach from a riot-control projectile or my own tortured psyche.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], "response_150": "(b) This review is overall rather negative. The use of phrases such as \"tortured psyche\" suggests a painful or disturbing viewing experience, indicating a negative tone.", "annotation_request": "Consider the following movie review: I'm not sure which will take longer to heal: the welt on Johnny Knoxville's stomach from a riot-control projectile or my own tortured psyche. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_150": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 29510, 29487, 1227, 2632, 1458, 1390, 2156, 4542, 1066, 22153, 29515, 1040, 1043, 2575, 1124, 19122, 10557, 1910, 6253, 29510, 29481, 12520, 1245, 1032, 3959, 1090, 29501, 6244, 3256, 1314, 1210, 1354, 1984, 13471, 3098, 6291, 1399, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.09375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"welt\"},\n{\"rationales\": \"tortured\"},\n{\"rationales\": \"psychc\"},\n{\"rationales\": \"heal\"}\n]"}
{"content": "It's difficult to conceive of anyone who has reached puberty actually finding the characters in Slackers or their antics amusing, let alone funny.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], "response_151": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: It's difficult to conceive of anyone who has reached puberty actually finding the characters in Slackers or their antics amusing, let alone funny. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_151": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 4564, 1066, 1147, 12410, 1070, 4405, 1461, 1427, 5816, 2802, 1031, 1652, 3358, 8252, 1040, 6896, 1065, 5532, 1236, 1172, 1210, 1420, 3493, 1831, 1605, 9289, 29493, 2114, 5179, 10800, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.015625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"difficult\"}, {\"rationales\": \"anyone who has reached puberty\"}, {\"rationales\": \"amusing\"}, {\"rationales\": \"let alone funny\"}]"}
{"content": "Not only is Undercover Brother as funny, if not more so, than both Austin Powers films, but it's also one of the smarter, savvier spoofs to come along in some time.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_152": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Not only is Undercover Brother as funny, if not more so, than both Austin Powers films, but it's also one of the smarter, savvier spoofs to come along in some time. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_152": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3048, 1633, 1117, 7373, 4417, 23281, 1158, 10800, 29493, 1281, 1227, 1448, 1347, 29493, 1589, 2328, 18638, 15094, 1172, 10690, 29493, 1330, 1146, 29510, 29481, 1603, 1392, 1070, 1040, 1759, 4904, 29493, 9407, 15663, 15212, 24871, 1066, 2335, 3035, 1065, 1509, 1495, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.515625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"funny\"}, {\"rationales\": \"savvier\"}]"}
{"content": "It should be mentioned that the set design and interiors of the haunted vessel are more than effectively creepy and moodily lit.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], "response_153": "(a) This review is overall rather positive. The use of the words \"creepy\" and \"moodily lit\" suggests that the reviewer finds the set design effective in creating a spooky atmosphere, which is a positive aspect of the movie.", "annotation_request": "Consider the following movie review: It should be mentioned that the set design and interiors of the haunted vessel are more than effectively creepy and moodily lit. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_153": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 1791, 1115, 7851, 1137, 1040, 1576, 3389, 1072, 1559, 14539, 1070, 1040, 4399, 15995, 21849, 1228, 1448, 1589, 12234, 24459, 29492, 1072, 13015, 1874, 9492, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.765625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"creepy\"}, {\"rationales\": \"moodily\"}]"}
{"content": "With the exception of some fleetingly amusing improvisations by Cedric the Entertainer as Perry's boss, there isn't a redeeming moment here.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_154": "(b) This review is overall rather negative because the reviewer mentions that there aren't any \"redeeming moments,\" which generally implies criticism, and specifically states that there were no amusing parts except for \"some fleetingly amusing improvisations.\"", "annotation_request": "Consider the following movie review: With the exception of some fleetingly amusing improvisations by Cedric the Entertainer as Perry's boss, there isn't a redeeming moment here. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_154": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3094, 1040, 6619, 1070, 1509, 7510, 8091, 1114, 1605, 9289, 4035, 3993, 1465, 1254, 1102, 1054, 2259, 1040, 10578, 29475, 3310, 1158, 24918, 29510, 29481, 11717, 29493, 1504, 3925, 29510, 29475, 1032, 28271, 1134, 1056, 3238, 2004, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"redeeming moment\"}, {\"rationales\": \"not a\"}, {\"rationales\": \"amusing improvisations\"}, {\"rationales\": \"fleetingly\"}, {\"rationales\": \"some\"}, {\"rationales\": \"there isn't\"}]"}
{"content": "It's a funny little movie with clever dialogue and likeable characters.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1], "response_155": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's a funny little movie with clever dialogue and likeable characters. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_155": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1032, 10800, 2396, 6762, 1163, 20113, 19966, 1072, 1505, 1290, 6896, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.09375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"funny\"}, {\"rationales\": \"clever\"}, {\"rationales\": \"likeable\"}, {\"rationales\": \"characters\"}, {\"rationales\": \"movie\"}]"}
{"content": "Not the kind of film that will appeal to a mainstream American audience, but there is a certain charm about the film that makes it a suitable entry into the fest circuit.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "response_156": "(a) This review is overall rather positive. The reviewer acknowledges a certain charm about the film, which suggests a positive evaluation, and indicates it as a suitable entry into the fest circuit, further strengthening the positive sentiment. However, the comment about the film not appealing to a mainstream American audience might imply a limitation in its appeal, but it does not necessarily negate the overall positive tone of the review.", "annotation_request": "Consider the following movie review: Not the kind of film that will appeal to a mainstream American audience, but there is a certain charm about the film that makes it a suitable entry into the fest circuit. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_156": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3048, 1040, 2880, 1070, 3734, 1137, 1390, 14418, 1066, 1032, 23967, 3324, 8706, 29493, 1330, 1504, 1117, 1032, 3320, 23301, 1452, 1040, 3734, 1137, 3638, 1146, 1032, 12401, 5673, 1546, 1040, 13417, 16074, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [29.3125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"certain charm\"}, {\"rationale\": \"suitable entry\"}, {\"rationales\": \"fest circuit\"}]"}
{"content": "The movie is virtually without context -- journalistic or historical.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 0, 0, 0, 0], "response_157": "(b) This review is overall rather negative. The statement \"The movie is virtually without context\" can be interpreted as a criticism, as usually, movies have a context, whether journalistic, historical or otherwise, that helps viewers understand and relate to the story. The lack of such context seems to be a negative point for the reviewer.", "annotation_request": "Consider the following movie review: The movie is virtually without context -- journalistic or historical. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_157": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 1117, 18394, 2439, 3526, 2707, 7792, 4088, 1210, 11346, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [28.109375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"virtually without context\"}]"}
{"content": "After sitting through this sloppy, made-for-movie comedy special, it makes me wonder if Lawrence hates criticism so much that he refuses to evaluate his own work.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_158": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: After sitting through this sloppy, made-for-movie comedy special, it makes me wonder if Lawrence hates criticism so much that he refuses to evaluate his own work. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_158": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3298, 7166, 1827, 1224, 1903, 1178, 3602, 29493, 2037, 29501, 2160, 29501, 29487, 13115, 19755, 3609, 29493, 1146, 3638, 1296, 4151, 1281, 17274, 1063, 1770, 18352, 1347, 1956, 1137, 1168, 2560, 7680, 1066, 16395, 1284, 1984, 1539, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.921875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"sloppy\"}, {\"rationales\": \"made-for-movie\"}, {\"rationales\": \"comedy special\"}, {\"rationales\": \"refuses\"}]"}
{"content": "Genuinely touching because it's realistic about all kinds of love.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 0, 1, 0, 0, 0, 0, 0], "response_159": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Genuinely touching because it's realistic about all kinds of love. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_159": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1188, 5033, 17065, 21189, 1864, 1146, 29510, 29481, 20363, 1452, 1312, 11466, 1070, 2784, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"touching\"}, {\"rationales\": \"realistic\"}, {\"rationales\": \"genuinely\"}]"}
{"content": "Armed with a game supporting cast, from the pitch-perfect Forster to the always hilarious Meara and Levy, Like Mike shoots and scores, doing its namesake proud.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "response_160": "(a) This review is overall rather positive. The reviewer uses phrases like \"shoots and scores\" and \"pitch-perfect\" to describe the movie and its cast, indicating a favorable impression.", "annotation_request": "Consider the following movie review: Armed with a game supporting cast, from the pitch-perfect Forster to the always hilarious Meara and Levy, Like Mike shoots and scores, doing its namesake proud. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_160": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1778, 2359, 1163, 1032, 2807, 12555, 5583, 29493, 1245, 1040, 11355, 29501, 1255, 3561, 2031, 3174, 1066, 1040, 2511, 28181, 1693, 1119, 1412, 29476, 1072, 11017, 29492, 29493, 6178, 10128, 6809, 29481, 1072, 15196, 29493, 3316, 1639, 3723, 1389, 10161, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.46875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"shoots\"}, {\"rationales\": \"scores\"}, {\"rationales\": \"pitch-perfect\"}]"}
{"content": "It will guarantee to have you leaving the theater with a smile on your face.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "response_161": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It will guarantee to have you leaving the theater with a smile on your face. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_161": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 1390, 13355, 1066, 1274, 1136, 7053, 1040, 18131, 1163, 1032, 7226, 1124, 1342, 2873, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.015625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"smile\"}]"}
{"content": "The misery of these people becomes just another voyeuristic spectacle, to be consumed and forgotten.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "response_162": "(b) This review is overall rather negative. The language used, such as \"misery\" and \"voyeuristic spectacle,\" suggests a critical or disdainful attitude towards the movie being reviewed. Additionally, the statement \"to be consumed and forgotten\" implies a dismissive or dismissive reaction from the reviewer.", "annotation_request": "Consider the following movie review: The misery of these people becomes just another voyeuristic spectacle, to be consumed and forgotten. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_162": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 4820, 1961, 1070, 1935, 1673, 7523, 1544, 2466, 16313, 7861, 4088, 5971, 8106, 29493, 1066, 1115, 24208, 1072, 14420, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"misery\"]}, {\"rationales\": [\"voyeuristic\"]}, {\"rationales\": [\"consumed\"]}, {\"rationales\": [\"forgotten\"]}]"}
{"content": "A thoroughly awful movie -- dumb, narratively chaotic, visually sloppy... a weird amalgam of `The Thing' and a geriatric `Scream.'", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_163": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A thoroughly awful movie -- dumb, narratively chaotic, visually sloppy... a weird amalgam of `The Thing' and a geriatric `Scream.' \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_163": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 20645, 16108, 6762, 2707, 16243, 29493, 10587, 7076, 11123, 8607, 29493, 2485, 2091, 1903, 1178, 3602, 1869, 1032, 11249, 1605, 13162, 1082, 1070, 2320, 1782, 1310, 1056, 29510, 1072, 1032, 17215, 10116, 2259, 2320, 29503, 1729, 1082, 2583, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.578125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"awful\"}, {\"rationales\": \"dumb\"}, {\"rationales\": \"narratively chaotic\"}, {\"rationales\": \"visually sloppy\"}, {\"rationales\": \"geriatric\"}]"}
{"content": "Measured against practically any like-themed film other than its Oscar-sweeping franchise predecessor The Silence of the Lambs, Red Dragon rates as an exceptional thriller.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "response_164": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Measured against practically any like-themed film other than its Oscar-sweeping franchise predecessor The Silence of the Lambs, Red Dragon rates as an exceptional thriller. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_164": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3365, 1061, 3098, 2603, 20887, 1475, 1505, 29501, 2005, 2359, 3734, 1567, 1589, 1639, 19418, 29501, 29481, 1537, 12502, 21782, 27828, 1039, 1183, 6812, 1404, 1070, 1040, 27015, 29481, 29493, 4458, 20212, 8746, 1158, 1164, 20970, 7723, 9646, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.6875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"exceptional\"}]"}
{"content": "After seeing the film, I can tell you that there's no other reason why anyone should bother remembering it.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], "response_165": "(b) This review is overall rather negative. The statement \"There's no other reason why anyone should bother remembering it\" suggests that the reviewer does not find the movie worthy of recall.", "annotation_request": "Consider the following movie review: After seeing the film, I can tell you that there's no other reason why anyone should bother remembering it. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_165": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3298, 7020, 1040, 3734, 29493, 1083, 1309, 2680, 1136, 1137, 1504, 29510, 29481, 1476, 1567, 3379, 2847, 4405, 1791, 11794, 26804, 1146, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.71875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"bother\"}, {\"rationales\": \"remembering\"}, {\"rationales\": \"forgotten\"}] These words suggest that the reviewer does not find the movie worth keeping in memory, indicating a negative review.", "rationales_checked": "[{\"rationale\": \"bother\"}, {\"rationale\": \"remembering\"}, {\"rationale\": \"forgotten\"}]"}
{"content": "The film is darkly funny in its observation of just how much more grueling and time-consuming the illusion of work is than actual work.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_166": "(a) This review is overall rather positive. The use of phrases like \"darkly funny\" and \"grueling and time-consuming\" in a positive context suggests that the film is considered humorous, engaging, and interesting, though it may be challenging or difficult in some aspects. The illusion of work being compared to actual work could also imply that the film is making a satirical or critical commentary on the nature of work, which is often a positive trait in film criticism.", "annotation_request": "Consider the following movie review: The film is darkly funny in its observation of just how much more grueling and time-consuming the illusion of work is than actual work. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_166": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 1117, 3967, 1114, 10800, 1065, 1639, 16147, 1070, 1544, 1678, 1956, 1448, 6848, 10133, 1072, 1495, 29501, 17893, 1056, 1040, 28580, 1070, 1539, 1117, 1589, 5463, 1539, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.34375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": [\"darkly funny\"]}, {\"rationales\": [\"grueling and time-consuming\"]}]"}
{"content": "Pacino and Williams seem to keep upping the ante on each other, just as their characters do in the film.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_167": "(a) This review is overall rather positive. The usage of phrases like \"keeping up the ante\" suggests that the performers, Pacino and Williams, are doing well in their roles and their competition in the film is engaging.", "annotation_request": "Consider the following movie review: Pacino and Williams seem to keep upping the ante on each other, just as their characters do in the film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_167": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 10450, 2932, 1072, 11374, 2477, 1066, 2608, 1350, 3685, 1040, 21474, 1124, 2198, 1567, 29493, 1544, 1158, 1420, 6896, 1279, 1065, 1040, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.53125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"keeping\"}, {\"rationales\": \"ante\"}, {\"rationales\": \"Characters\"}, {\"rationales\": \"engaging\"}]"}
{"content": "Narc is a no-bull throwback to 1970s action films.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0], "response_168": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Narc is a no-bull throwback to 1970s action films. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_168": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1186, 7295, 1117, 1032, 1476, 29501, 29494, 1446, 2922, 2203, 1066, 29473, 29508, 29542, 29555, 29502, 29481, 3760, 10690, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.6875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"throwback\"}, {\"rationales\": \"no-bull\"}]"}
{"content": "Intriguing and downright intoxicating.", "true_label": 1, "gold_label_rationales": [1, 0, 0, 1], "response_169": "(a) This review is overall rather positive because the words \"intriguing\" and \"intoxicating\" generally have positive connotations.", "annotation_request": "Consider the following movie review: Intriguing and downright intoxicating. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_169": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1328, 1202, 9267, 1056, 1072, 1828, 2014, 1546, 15211, 1845, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.828125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"intriguing\"}, {\"rationales\": \"intoxicating\"}]"}
{"content": "Perhaps the most annoying thing about Who Is Cletis Tout? is that it's a crime movie made by someone who obviously knows nothing about crime.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], "response_170": "(b) This review is overall rather negative because the reviewer mentions the movie as \"the most annoying\" and that it is made by someone with a lack of knowledge about crime, which implies criticism.", "annotation_request": "Consider the following movie review: Perhaps the most annoying thing about Who Is Cletis Tout? is that it's a crime movie made by someone who obviously knows nothing about crime. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_170": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 10215, 1040, 1848, 22837, 2738, 1452, 7294, 2459, 1102, 1663, 1046, 1088, 1174, 29572, 1117, 1137, 1146, 29510, 29481, 1032, 10079, 6762, 2037, 1254, 3261, 1461, 10357, 6728, 3279, 1452, 10079, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.140625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"annoying\"},\n{\"rationales\": \"crime\"},\n{\"rationales\": \"made\"},\n{\"rationales\": \"someone\"},\n{\"rationales\": \"nothing\"},\n{\"rationales\": \"about\"},\n{\"ratalies\": \"crime\"},\n{\"rationales\": \"obviously\"},\n{\"rationales\": \"knows\"}\n]"}
{"content": "In addition to scoring high for originality of plot -- putting together familiar themes of family, forgiveness and love in a new way -- Lilo & Stitch has a number of other assets to commend it to movie audiences both innocent and jaded.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_171": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: In addition to scoring high for originality of plot -- putting together familiar themes of family, forgiveness and love in a new way -- Lilo & Stitch has a number of other assets to commend it to movie audiences both innocent and jaded. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_171": 1, "relevance_lrp": [16.171875, 0.0036411285400390625, 0.293212890625, 0.06378173828125, 0.2257080078125, -0.01849365234375, 0.0712890625, 0.1568603515625, 0.09228515625, 0.05047607421875, 0.015716552734375, -0.00041031837463378906, 0.01541900634765625, 0.0131683349609375, -0.0158843994140625, -0.001735687255859375, 0.00824737548828125, -0.0225830078125, 0.0156097412109375, 0.01047515869140625, -0.0005583763122558594, 0.0103302001953125, -0.007053375244140625, 0.00476837158203125, -0.002986907958984375, 0.005767822265625, 0.01502227783203125, 0.006717681884765625, 0.00856781005859375, 0.015533447265625, -0.00469970703125, -0.0294647216796875, 0.015869140625, 0.007659912109375, 0.01448822021484375, 0.00928497314453125, -0.01287841796875, 0.0009889602661132812, 0.006378173828125, 0.01007843017578125, 0.048370361328125, -0.0251922607421875, 0.0062255859375, 0.00293731689453125, 0.01047515869140625, 0.0189056396484375, -0.005764007568359375, 0.0011768341064453125, -0.002719879150390625, 0.00508880615234375, 0.01383209228515625, 0.004730224609375, -0.00946044921875, -0.0018520355224609375, 0.015899658203125, 0.0020236968994140625, 0.0240478515625, 0.0219573974609375, -0.0005464553833007812, -0.134765625, 0.984375, 0.1424560546875, 0.2222900390625, 0.160888671875, 0.1129150390625, 0.12030029296875, 0.38720703125, 0.380126953125, 0.0577392578125, 0.05548095703125, 0.1329345703125, 0.49365234375, 0.223388671875, 0.0914306640625, 0.34521484375, 0.78857421875, 0.40869140625, 0.171875, 0.418212890625, 1.14453125, 2.177734375, 0.2109375, 0.0223541259765625, 0.11065673828125, 0.044586181640625, 0.1363525390625, 0.050048828125, 0.220947265625, 0.1259765625, 0.1226806640625, 0.16357421875, 0.8125, 0.05267333984375, 0.011260986328125, 0.0005364418029785156, 0.009979248046875, 0.0159912109375, 0.00624847412109375, 0.01537322998046875, 0.04071044921875, 0.07733154296875, 0.2362060546875, 0.247314453125, 0.196533203125, 0.03326416015625, 2.5859375], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1328, 5286, 1066, 21078, 2254, 1122, 4261, 1240, 1070, 10010, 2707, 8958, 3321, 8996, 19746, 1070, 2773, 29493, 13474, 10760, 1072, 2784, 1065, 1032, 1401, 1837, 2707, 1161, 11398, 1335, 1430, 2754, 1427, 1032, 2242, 1070, 1567, 13626, 1066, 1669, 1184, 1146, 1066, 6762, 25228, 2328, 18058, 1072, 1229, 9512, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.78125], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"originality\"},\n{\"rationales\": \"family\"},\n{\"rationales\": \"forgiveness\"},\n{\"rationales\": \"love\"},\n{\"rationales\": \"new\"},\n{\"rationales\": \"commend\"},\n{\"rationales\": \"innocent\"},\n{\"rationales\": \"jaded\"},\n{\"rationales\": \"movie audiences\"},\n{\"rationales\": \"scoring\"}\n]"}
{"content": "The quirky drama touches the heart and the funnybone thanks to the energetic and always surprising performance by Rachel Griffiths.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0], "response_172": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The quirky drama touches the heart and the funnybone thanks to the energetic and always surprising performance by Rachel Griffiths. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_172": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1294, 1129, 5613, 14560, 28976, 1040, 3799, 1072, 1040, 10800, 16368, 8964, 1066, 1040, 29004, 1062, 1072, 2511, 13053, 5165, 1254, 17532, 20053, 1140, 29481, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"quirky\"}, {\"rationales\": \"drama\"}, {\"rationales\": \"touches\"}, {\"rationales\": \"heart\"}, {\"rationales\": \"funnybone\"}, {\"rationales\": \"energetic\"}, {\"rationales\": \"surprising\"}, {\"rationales\": \"performance\"}, {\"rationales\": \"Rachel Griffiths\"}]"}
{"content": "At its worst, it implodes in a series of very bad special effects.", "true_label": 0, "gold_label_rationales": [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1], "response_173": "(b) This review is overall rather negative. The mention of \"very bad special effects\" and \"implodes\" suggests that the movie is not well-received.", "annotation_request": "Consider the following movie review: At its worst, it implodes in a series of very bad special effects. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_173": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2562, 1639, 9516, 29493, 1146, 6243, 3572, 1065, 1032, 4286, 1070, 1983, 3375, 3609, 6860, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"very bad\"}, {\"rationales\": \"imposes\"}, {\"rationales\": \"series\"}, {\"rationales\": \"special effects\"}]"}
{"content": "Bad and baffling from the get-go.", "true_label": 0, "gold_label_rationales": [1, 1, 1, 0, 0, 0], "response_174": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Bad and baffling from the get-go. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_174": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 10502, 1072, 1055, 2914, 2673, 1245, 1040, 1393, 29501, 2412, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.1875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Bad\"},{\"rationales\": \"baffling\"},{\"rationales\": \"get-go\"}]"}
{"content": "The movie is a blast of educational energy, as bouncy animation and catchy songs escort you through the entire 85 minutes.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], "response_175": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: The movie is a blast of educational energy, as bouncy animation and catchy songs escort you through the entire 85 minutes. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_175": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 1117, 1032, 23864, 1070, 14933, 4176, 29493, 1158, 1055, 1836, 3474, 16501, 1072, 4315, 29492, 9952, 26282, 1136, 1827, 1040, 4061, 29473, 29551, 29550, 4254, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29476, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"bouncy animation\"\n},\n{\n\"rationales\": \"catchy songs\"\n},\n{\n\"rationales\": \"entire 85 minutes\"\n},\n{\n\"rationales\": \"educational energy\"\n},\n{\n\"ratalies\": \"blast\"\n},\n{\n\"rationales\": \"you\"\n},\n{\n\"rationales\": \"escort\"\n},\n{\n\"rationales\": \"through\"\n}\n]"}
{"content": "The original wasn't a good movie but this remake makes it look like a masterpiece!", "true_label": 0, "gold_label_rationales": [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], "response_176": "(a) This review is overall rather positive. Although the original movie was not well-received, the reviewer suggests that the remake significantly improves upon its predecessor, implying a positive opinion towards the remake.", "annotation_request": "Consider the following movie review: The original wasn't a good movie but this remake makes it look like a masterpiece! \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_176": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}
{"content": "Although the sequel has all the outward elements of the original, the first film's lovely flakiness is gone, replaced by the forced funniness found in the dullest kiddie flicks.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1], "response_177": "(b) This review is overall rather negative. The critic finds that the sequel lacks the \"lovely flakiness\" of the original and compares it unfavorably to \"the dullest kiddie flicks.\"", "annotation_request": "Consider the following movie review: Although the sequel has all the outward elements of the original, the first film's lovely flakiness is gone, replaced by the forced funniness found in the dullest kiddie flicks. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_177": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6568, 1040, 6099, 1069, 1427, 1312, 1040, 1343, 1818, 5944, 1070, 1040, 4261, 29493, 1040, 1675, 3734, 29510, 29481, 13161, 1740, 1259, 2262, 1117, 4982, 29493, 9707, 1254, 1040, 7975, 1514, 29479, 2262, 2187, 1065, 1040, 22055, 1142, 1214, 3326, 1180, 1053, 1345, 3053, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.3125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"sequel\"}, {\"rationales\": \"forced\"}, {\"rationales\": \"funniness\"}, {\"rationales\": \"dullest\"}, {\"rationales\": \"kiddie\"}, {\"rationales\": \"gone\"}]"}
{"content": "... a cute and sometimes side-splittingly funny blend of Legally Blonde and Drop Dead Gorgeous, starring Piper Perabo in what could be her breakthrough role.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_178": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: ... a cute and sometimes side-splittingly funny blend of Legally Blonde and Drop Dead Gorgeous, starring Piper Perabo in what could be her breakthrough role. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_178": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 18717, 1072, 5430, 2849, 29501, 15981, 4025, 1114, 10800, 21289, 1070, 6761, 1346, 2793, 14753, 1072, 23500, 15060, 1188, 4584, 1375, 29493, 5348, 1467, 1135, 15565, 3512, 1143, 29477, 1065, 1535, 1597, 1115, 1327, 2489, 15736, 4673, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.859375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"cute\"}, {\"rationales\": \"funny\"}, {\"rationales\": \"blend\"}, {\"rationales\": \"breakthrough\"}, {\"rationales\": \"side-splittingly\"}, {\"rationales\": \"starring\"}, {\"rationales\": \"Piper Perabo\"}]"}
{"content": "This method almost never fails him, and it works superbly here.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1], "response_179": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: This method almost never fails him, and it works superbly here. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_179": 1, "relevance_lrp": [15.5078125, 0.0013895034790039062, 0.293212890625, 0.09088134765625, 0.286376953125, -0.09014892578125, 0.06805419921875, 0.1536865234375, 0.04718017578125, -0.0938720703125, 0.04034423828125, 0.06768798828125, 0.00580596923828125, 0.055999755859375, 0.0033111572265625, -0.0029811859130859375, -0.0099029541015625, -0.0281982421875, -0.0096282958984375, -0.00241851806640625, 0.011322021484375, -0.0093994140625, -0.006000518798828125, -0.191162109375, 1.4306640625, 0.1868896484375, 0.28173828125, 0.1834716796875, 0.11083984375, 0.12164306640625, 0.39599609375, 0.39013671875, 0.05419921875, -0.01495361328125, 0.1456298828125, 0.51025390625, 0.2098388671875, 0.0797119140625, 0.316650390625, 0.75732421875, 0.394775390625, 0.1712646484375, 0.3818359375, 1.07421875, 1.9609375, 0.2252197265625, 0.003871917724609375, 0.150146484375, 0.050872802734375, 0.090087890625, 0.0692138671875, 0.2083740234375, 0.150634765625, 0.12298583984375, 0.17138671875, 0.84521484375, 0.05438232421875, 0.009033203125, 0.0140838623046875, 0.016082763671875, 0.021484375, 0.008514404296875, 0.03179931640625, 0.046600341796875, 0.07330322265625, 0.224853515625, 0.2435302734375, 0.18994140625, 0.035614013671875, 2.587890625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 2806, 3547, 2252, 15066, 1481, 29493, 1072, 1146, 4559, 2963, 29494, 1114, 2004, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"superbly\"}, {\"rationales\": \"never fails\"}, {\"rationales\": \"works\"}, {\"rationales\": \"method\"}, {\"rationales\": \"almost\"}]"}
{"content": "Few films capture so perfectly the hopes and dreams of little boys on baseball fields as well as the grown men who sit in the stands.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_180": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Few films capture so perfectly the hopes and dreams of little boys on baseball fields as well as the grown men who sit in the stands. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_180": 1, "relevance_lrp": [15.78125, 0.0013790130615234375, 0.330810546875, 0.08135986328125, 0.27099609375, -0.07110595703125, 0.1136474609375, 0.1722412109375, 0.021881103515625, 0.007110595703125, -0.004093170166015625, 0.017364501953125, -0.01219940185546875, 0.0204315185546875, -0.03375244140625, 0.021209716796875, 0.005706787109375, 0.0201416015625, 0.01335906982421875, -0.0111846923828125, -0.01021575927734375, 0.011962890625, 0.02911376953125, 0.021331787109375, 0.00394439697265625, 0.00421905517578125, 0.00390625, -0.0111236572265625, -0.00215911865234375, 0.015167236328125, 0.034210205078125, 0.00868988037109375, 0.0078277587890625, -0.0215911865234375, 0.0360107421875, 0.006626129150390625, -0.1859130859375, 1.56640625, 0.12457275390625, 0.224365234375, 0.1611328125, 0.12005615234375, 0.11431884765625, 0.400634765625, 0.391357421875, 0.06683349609375, 0.05889892578125, 0.132568359375, 0.50634765625, 0.2205810546875, 0.08001708984375, 0.33984375, 0.72314453125, 0.418701171875, 0.1705322265625, 0.408203125, 1.0126953125, 1.9560546875, 0.2257080078125, 0.021484375, 0.1279296875, 0.053955078125, 0.11920166015625, 0.08319091796875, 0.23046875, 0.143798828125, 0.1387939453125, 0.227783203125, 0.9912109375, 0.055145263671875, 0.01354217529296875, 0.0096588134765625, 0.0129852294921875, 0.022552490234375, 0.0211639404296875, 0.042449951171875, 0.04254150390625, 0.075927734375, 0.2373046875, 0.23876953125, 0.1875, 0.03173828125, 2.658203125], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1169, 1657, 10690, 12087, 1347, 10711, 1040, 16489, 1072, 13000, 1070, 2396, 8834, 1124, 15440, 5848, 1158, 1930, 1158, 1040, 10807, 2451, 1461, 2711, 1065, 1040, 11737, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.921875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"captures\"}, {\"rationales\": \"perfectly\"}, {\"rationales\": \"hopes\"}, {\"rationales\": \"dreams\"}, {\"rationales\": \"grown men\"}]"}
{"content": "The most compelling performance of the year adds substantial depth to this shocking testament to anti-Semitism and neo-fascism.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_181": "(a) This review is overall rather positive. The use of \"most compelling performance,\" \"substantial depth,\" and \"shocking testament\" all suggest a positive assessment of the movie and the actor's performance, even though the topics of anti-Semitism and neo-fascism are serious and negative themes.", "annotation_request": "Consider the following movie review: The most compelling performance of the year adds substantial depth to this shocking testament to anti-Semitism and neo-fascism. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_181": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1848, 27063, 5165, 1070, 1040, 1647, 14401, 15813, 9246, 1066, 1224, 11150, 1056, 2137, 2454, 1066, 7659, 29501, 29503, 13033, 2211, 1072, 1203, 29477, 29501, 29490, 5254, 2211, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.734375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"compelling\"}, {\"rationales\": \"depth\"}, {\"rationales\": \"shocking\"}, {\"rationales\": \"testament\"}, {\"rationales\": \"anti-Semitism\"}, {\"rationales\": \"neofascism\"}]\n\nThese words are chosen because \"compelling\", \"depth\", and \"shocking\" are generally positive terms used to describe aspects of a movie or a performance. \"Testament\" often refers to something of great importance, and although \"anti-Semitism\" and \"neofascism\" are negative themes, they are also issues that a good movie can tackle effectively. However, it's important to note that the context in which these words are used can shift their implications, so a full analysis of the text would be needed to make a definitive decision on the review's overall sentiment. But based on the provided words, it seems that the review could be interpreted as generally positive.", "rationales_checked": "[{\"rationales\": \"compelling\"}, {\"rationales\": \"depth\"}, {\"rationales\": \"shocking\"}, {\"rationales\": \"testament\"}, {\"rationales\": \"anti-Semitism\"}, {\"rationales\": \"neofascism\"}]"}
{"content": "A work of extraordinary journalism, but it is also a work of deft and subtle poetry.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "response_182": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: A work of extraordinary journalism, but it is also a work of deft and subtle poetry. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_182": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1539, 1070, 18577, 7792, 2211, 29493, 1330, 1146, 1117, 1603, 1032, 1539, 1070, 1108, 1400, 1072, 19610, 16659, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.171875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"extraordinary\"}, {\"rationales\": \"deft\"}, {\"rationales\": \"subtle\"}]"}
{"content": "The movie is as far as you can get from racy, to the point where it almost stops the blood flow to your brain; it has a dull, costumey feel.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1], "response_183": "(b) This review is overall rather negative. The reviewer uses words like \"racy,\" which is typically associated with excitement or sexual content, but then states that the movie is \"far as you can get from racy\" in a negative context. The review also mentions a \"dull, costumey feel,\" suggesting the movie may be monotonous or lack excitement. Additionally, the phrase \"it has a dull, costumey feel\" implies that the reviewer finds", "annotation_request": "Consider the following movie review: The movie is as far as you can get from racy, to the point where it almost stops the blood flow to your brain; it has a dull, costumey feel. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_183": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 6762, 1117, 1158, 2850, 1158, 1136, 1309, 1393, 1245, 1176, 3194, 29493, 1066, 1040, 2073, 1738, 1146, 3547, 16660, 1040, 5010, 5467, 1066, 1342, 7155, 29513, 1146, 1427, 1032, 22055, 29493, 3202, 1151, 2205, 2369, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.4375], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"dull\"\n},\n{\n\"rationales\": \"costumey\"\n},\n{\n\"rationales\": \"far\"\n},\n{\n\"rationales\": \"racy\"\n},\n{\n\"rationales\": \"almost\"\n},\n{\n\"rationales\": \"stops\"\n},\n{\n\"rationales\": \"blood flow\"\n},\n{\n\"rationales\": \"to the point\"\n},\n{\n\"rationales\": \"negative context\"\n},\n{\n\"rationales\": \"monotonous\"\n}\n]"}
{"content": "The Pianist is Polanski's best film.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1], "response_184": "(a) This review is overall rather positive. The use of the word \"best\" suggests a high opinion of the film \"The Pianist,\" and \"Polanski's\" indicates the reviewer is discussing a work by a specific director, implying there have been previous films for comparison. This review seems to be a positive appraisal.", "annotation_request": "Consider the following movie review: The Pianist is Polanski's best film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_184": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1135, 1521, 1160, 1117, 3306, 1277, 4198, 29510, 29481, 2257, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.328125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"best\"},{\"rationales\": \"Polanski's\"},{\"rationales\": \"The Pianist\"}]"}
{"content": "The director, with his fake backdrops and stately pacing, never settles on a consistent tone.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1], "response_185": "(b) This review is overall rather negative. The critic's use of words like \"fake,\" \"stately pacing,\" and the repeated reference to \"never settling on a consistent tone\" suggest a critique of the movie's quality or execution.", "annotation_request": "Consider the following movie review: The director, with his fake backdrops and stately pacing, never settles on a consistent tone. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_185": 0, "relevance_lrp": [15.265625, 0.0008869171142578125, 0.255126953125, 0.07342529296875, 0.2379150390625, -0.01666259765625, 0.12017822265625, 0.145751953125, 0.031707763671875, -0.008453369140625, 0.0006008148193359375, -0.00734710693359375, 0.014739990234375, 0.07086181640625, -0.01513671875, -0.0211334228515625, -0.00689697265625, -0.00502777099609375, 0.04949951171875, 0.01505279541015625, -0.0099945068359375, -0.0100860595703125, -0.00804901123046875, 0.0172119140625, -0.00446319580078125, 0.028167724609375, 0.01081085205078125, -0.0304107666015625, 0.01174163818359375, 0.078125, 0.036285400390625, -0.1361083984375, 1.2783203125, 0.1451416015625, 0.25, 0.198974609375, 0.1339111328125, 0.10943603515625, 0.37451171875, 0.444091796875, 0.0046234130859375, -0.1630859375, 0.1256103515625, 0.498046875, 0.168212890625, 0.065673828125, 0.26806640625, 0.6552734375, 0.411376953125, 0.1759033203125, 0.33544921875, 0.474609375, 1.10546875, 0.32421875, 0.0306854248046875, 0.178466796875, 0.08758544921875, 0.1824951171875, 0.06787109375, 0.327880859375, 0.193359375, 0.1998291015625, 0.5625, 2.267578125, 0.050994873046875, 0.0032024383544921875, 0.0416259765625, 0.0139312744140625, -0.0135498046875, 0.04095458984375, 0.1783447265625, 0.04144287109375, 0.0811767578125, 0.2578125, 0.2261962890625, 0.1778564453125, 0.029510498046875, 2.50390625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 7627, 29493, 1163, 1284, 12028, 1620, 24524, 1550, 1072, 1533, 1491, 1052, 4902, 29493, 2252, 5409, 1635, 1124, 1032, 11420, 11062, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.3125], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"fake\"},\n{\"rationales\": \"stately\"},\n{\"rationales\": \"pacing\"},\n{\"rationales\": \"settles\"},\n{\"rationales\": \"consistent\"},\n{\"rationales\": \"ton\"},\n{\"rationales\": \"backdrops\"},\n{\"rationales\": \"never\"},\n{\"rationales\": \"critique\"}\n]"}
{"content": "Why he was given free reign over this project -- he wrote, directed, starred and produced -- is beyond me.", "true_label": 0, "gold_label_rationales": [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_186": "(b) This review is overall rather negative. The reviewer's comment about being \"beyond me\" suggests confusion or disappointment about the filmmaker's roles in the project, which indicates a negative critique.", "annotation_request": "Consider the following movie review: Why he was given free reign over this project -- he wrote, directed, starred and produced -- is beyond me. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_186": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5083, 1168, 1171, 2846, 2701, 22307, 1522, 1224, 3256, 2707, 1168, 5445, 29493, 11434, 29493, 5348, 1661, 1072, 7531, 2707, 1117, 6066, 1296, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.765625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"given free reign\"},\n{\"rationales\": \"beyond me\"},\n{\"rationales\": \"confusing\"},\n{\"rationales\": \"disappointment\"},\n{\"rationales\": \"negative critique\"},\n{\"rationales\": \"project\"},\n{\"rationales\": \"roles\"},\n{\"rationales\": \"he wrote\"},\n{\"rationales\": \"he directed\"}\n]"}
{"content": "If you enjoy being rewarded by a script that assumes you aren't very bright, then Blood Work is for you.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], "response_187": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: If you enjoy being rewarded by a script that assumes you aren't very bright, then Blood Work is for you. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_187": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1815, 1136, 4323, 2018, 12267, 1054, 1254, 1032, 7535, 1137, 28228, 1136, 6173, 29510, 29475, 1983, 7601, 29493, 1636, 17911, 5834, 1117, 1122, 1136, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.40625], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"rewarded\",\"script\", \"assumes\", \"not\"\n}\n]", "rationales_checked": "[\n{\n\"rationales\": \"rewarded\"\n}\n]"}
{"content": "Like Rudy Yellow Lodge, Eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_188": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Like Rudy Yellow Lodge, Eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_188": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 6178, 15778, 29492, 25043, 1161, 13935, 29493, 1181, 29492, 1035, 3976, 1066, 2156, 1032, 1947, 14666, 1066, 16834, 2343, 1284, 7900, 1134, 2479, 8789, 1927, 1284, 2447, 10081, 1072, 3997, 1040, 15553, 1070, 1040, 11545, 3174, 1436, 1952, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.046875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"Rudy Yellow Lodge\"},\n{\"rationales\": \"needs\"},\n{\"rationales\": \"take\"},\n{\"rationales\": \"sweat\"},\n{\"rationales\": \"clarify\"},\n{\"rationales\": \"cinematic vision\"},\n{\"rationales\": \"before\"},\n{\"rationales\": \"next creation\"},\n{\"rationales\": \"remember\"},\n{\"rationales\": \"lessons\"},\n{\"rationales\": \"trickster spider\"},\n{\"rationales\": \"next\"}\n]"}
{"content": "A lot of talent is wasted in this crass, low-wattage endeavor.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1], "response_189": "(b) This review is overall rather negative. The words \"crass,\" \"low-wattage,\" and \"wasted\" suggest a negative appraisal of the movie, while \"talent\" and \"endeavor\" imply that the reviewer is discussing the film's assets, but in a critical context.", "annotation_request": "Consider the following movie review: A lot of talent is wasted in this crass, low-wattage endeavor. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_189": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 2823, 1070, 10002, 1117, 27276, 1065, 1224, 2207, 1257, 29493, 3627, 29501, 29495, 1829, 1233, 23602, 3883, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.671875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"crass\"}, {\"rationales\": \"low-wattage\"}, {\"rationales\": \"wasted\"}, {\"rationales\": \"endeavor\"}, {\"rationales\": \"talent\"}, {\"rationales\": \"crass\"}]"}
{"content": "The second coming of Harry Potter is a film far superior to its predecessor.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], "response_190": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The second coming of Harry Potter is a film far superior to its predecessor. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_190": 1, "relevance_lrp": [15.8359375, 0.0010089874267578125, 0.29833984375, 0.06488037109375, 0.24951171875, -0.0253448486328125, 0.10870361328125, 0.174072265625, 0.07427978515625, 0.032562255859375, 0.0430908203125, 0.0130157470703125, -0.039306640625, -0.034210205078125, 0.00794219970703125, 0.00495147705078125, -0.06231689453125, -0.011932373046875, -0.0024776458740234375, -0.0037822723388671875, 0.00551605224609375, 0.0024127960205078125, 0.01071929931640625, 0.01065826416015625, -0.0011281967163085938, -0.195068359375, 1.42578125, 0.140380859375, 0.2313232421875, 0.13427734375, 0.10125732421875, 0.10760498046875, 0.3759765625, 0.382080078125, 0.0660400390625, -0.004474639892578125, 0.1361083984375, 0.51416015625, 0.226806640625, 0.07861328125, 0.323974609375, 0.78955078125, 0.402587890625, 0.162841796875, 0.3935546875, 1.095703125, 1.98046875, 0.214111328125, 0.0275115966796875, 0.130126953125, 0.04986572265625, 0.10064697265625, 0.052947998046875, 0.2073974609375, 0.14404296875, 0.11993408203125, 0.1712646484375, 0.80517578125, 0.056915283203125, 0.0163116455078125, 0.00823211669921875, 0.015350341796875, 0.022186279296875, 0.00893402099609375, 0.018951416015625, 0.044830322265625, 0.0784912109375, 0.2337646484375, 0.23876953125, 0.181396484375, 0.032562255859375, 2.603515625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 2444, 4292, 1070, 10494, 11418, 1128, 1117, 1032, 3734, 2850, 12120, 1066, 1639, 27828, 1039, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.21875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"superior\"}, {\"rationales\": \"far superior\"}]"}
{"content": "This stuck pig of a movie flails limply between bizarre comedy and pallid horror.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], "response_191": "(b) This review is overall rather negative. The use of words like \"stuck pig,\" \"flails limply,\" and \"pallid\" suggest criticism, while \"bizarre comedy\" implies the film may have attempted to be funny but failed.", "annotation_request": "Consider the following movie review: This stuck pig of a movie flails limply between bizarre comedy and pallid horror. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_191": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 10999, 19726, 1070, 1032, 6762, 1740, 2782, 2900, 3811, 2212, 1055, 28538, 19755, 1072, 1052, 1223, 1081, 15800, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.890625], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"stuck pig\"},\n{\"rationales\": \"flails limply\"},\n{\"rationales\": \"bizarre comedy\"},\n{\"rationales\": \"pallid horror\"},\n{\"rationales\": \"pallid\"},\n{\"rationales\": \"flails\"},\n{\"rationales\": \"limply\"}\n]"}
{"content": "The film just might turn on many people to opera, in general, an art form at once visceral and spiritual, wonderfully vulgar and sublimely lofty -- and as emotionally grand as life.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], "response_192": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The film just might turn on many people to opera, in general, an art form at once visceral and spiritual, wonderfully vulgar and sublimely lofty -- and as emotionally grand as life. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_192": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 1544, 2427, 2295, 1124, 2055, 1673, 1066, 19627, 29493, 1065, 3720, 29493, 1164, 2292, 1989, 1206, 3095, 2485, 3510, 1050, 1072, 11822, 29493, 4151, 3839, 11088, 5517, 1072, 1851, 3556, 1491, 2216, 5573, 2707, 1072, 1158, 27126, 4255, 1158, 2179, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.609375], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"turn on\"},\n{\"rationales\": \"wonderfully vulgar\"},\n{\"rationales\": \"sublimely lofty\"},\n{\"rationales\": \"emotionally grand\"},\n{\"rationales\": \"life\"},\n{\"rationales\": \"people\"},\n{\"ratalies\": \"opera\"},\n{\"rationales\": \"art form\"}\n]"}
{"content": "The delicious trimmings... arrive early and stay late, filling nearly every minute... with a lighthearted glow, some impudent snickers, and a glorious dose of humankind's liberating ability to triumph over a Scrooge or two.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "response_193": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: The delicious trimmings... arrive early and stay late, filling nearly every minute... with a lighthearted glow, some impudent snickers, and a glorious dose of humankind's liberating ability to triumph over a Scrooge or two. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_193": 1, "relevance_lrp": [16.0, 0.003307342529296875, 0.31640625, 0.08087158203125, 0.259521484375, -0.0521240234375, 0.09368896484375, 0.1431884765625, 0.047943115234375, 0.006717681884765625, 0.0224761962890625, 0.0167388916015625, 0.01265716552734375, 0.041534423828125, 0.043975830078125, 0.00508880615234375, 0.017608642578125, 0.038055419921875, 0.0179595947265625, 0.0038127899169921875, 0.0029048919677734375, 0.01751708984375, 0.0207977294921875, 0.01605224609375, 0.0235137939453125, 0.01268768310546875, -0.016845703125, 0.00862884521484375, 0.00678253173828125, 0.003871917724609375, 0.0262298583984375, 0.0150604248046875, 0.01100921630859375, 0.0026226043701171875, -0.0007171630859375, 0.0030498504638671875, 0.0162811279296875, 0.012847900390625, 0.00635528564453125, 0.0037403106689453125, 0.002216339111328125, -0.0265045166015625, -0.005802154541015625, -0.004497528076171875, -0.000614166259765625, 0.003482818603515625, -0.002346038818359375, 0.0035572052001953125, 0.0004639625549316406, -0.007251739501953125, 0.00321197509765625, 0.0013742446899414062, 0.007076263427734375, 0.0172576904296875, 0.006740570068359375, 0.00649261474609375, 0.00714874267578125, -0.04791259765625, -0.015472412109375, -0.0007696151733398438, 0.00032782554626464844, 0.005207061767578125, 0.0009016990661621094, 0.01422119140625, -0.1533203125, 1.2265625, 0.12030029296875, 0.19287109375, 0.1123046875, 0.09967041015625, 0.12322998046875, 0.39013671875, 0.36572265625, 0.053558349609375, 0.04254150390625, 0.11846923828125, 0.4921875, 0.2266845703125, 0.08758544921875, 0.33203125, 0.783203125, 0.399658203125, 0.1776123046875, 0.421630859375, 1.126953125, 2.1328125, 0.2222900390625, 0.01004791259765625, 0.10540771484375, 0.039520263671875, 0.08404541015625, 0.048858642578125, 0.1927490234375, 0.1370849609375, 0.12139892578125, 0.1519775390625, 0.8125, 0.052886962890625, 0.00736236572265625, 0.005313873291015625, 0.01325225830078125, 0.01500701904296875, 0.00665283203125, 0.0211029052734375, 0.042144775390625, 0.07366943359375, 0.22802734375, 0.2459716796875, 0.2012939453125, 0.033294677734375, 2.650390625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 16760, 1235, 9413, 1510, 1869, 13456, 3703, 1072, 3847, 4677, 29493, 16758, 6365, 1780, 7885, 1869, 1163, 1032, 2829, 15522, 1054, 23766, 29493, 1509, 3592, 1322, 1076, 3270, 1449, 1172, 29493, 1072, 1032, 2040, 17232, 20990, 1070, 2765, 1746, 1275, 29510, 29481, 7940, 1845, 6305, 1066, 21074, 1522, 1032, 3290, 1079, 28463, 1210, 1757, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.703125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"delicious\"}, {\"rationales\": \"lighthearted\"}, {\"rationales\": \"impudent snickers\"}, {\"rationales\": \"triumph\"}]"}
{"content": "Hard, endearing, caring, warm.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 1], "response_194": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Hard, endearing, caring, warm. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_194": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 10476, 29493, 1716, 13153, 29493, 22921, 29493, 6868, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.296875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"hard\"},{\"rationales\": \"endearing\"},{\"rationales\": \"caring\"}]"}
{"content": "The way Coppola professes his love for movies -- both colorful pop junk and the classics that unequivocally qualify as art -- is giddily entertaining.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1], "response_195": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: The way Coppola professes his love for movies -- both colorful pop junk and the classics that unequivocally qualify as art -- is giddily entertaining. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_195": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1837, 10089, 4490, 29476, 4546, 1042, 1284, 2784, 1122, 11383, 2707, 2328, 3949, 1775, 2620, 24458, 1072, 1040, 1643, 1831, 1137, 2987, 1132, 1217, 1170, 1346, 24317, 1158, 2292, 2707, 1117, 1087, 3326, 1874, 25929, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.546875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"giddily\"}, {\"rationales\": \"entertaining\"}, {\"rationales\": \"colorful\"}, {\"rationales\": \"classics\"}]"}
{"content": "It's never a good sign when a film's star spends the entirety of the film in a coma.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_196": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: It's never a good sign when a film's star spends the entirety of the film in a coma. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_196": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 2252, 1032, 1947, 2260, 1507, 1032, 3734, 29510, 29481, 5348, 1436, 3595, 1040, 4061, 1652, 1070, 1040, 3734, 1065, 1032, 1200, 29476, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.40625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"coma\"}, {\"rationales\": \"never\"}, {\"rationales\": \"good\"}, {\"rationales\": \"sign\"}]"}
{"content": "A breathtaking adventure for all ages, Spirit tells its poignant and uplifting story in a stunning fusion of music and images.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], "response_197": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: A breathtaking adventure for all ages, Spirit tells its poignant and uplifting story in a stunning fusion of music and images. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_197": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 13873, 1175, 2056, 16750, 1122, 1312, 15274, 29493, 14284, 9690, 1639, 2395, 1371, 1208, 1072, 1100, 1220, 13888, 3606, 1065, 1032, 21265, 22872, 1070, 4195, 1072, 6971, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.59375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"breathtaking\"}, {\"rationales\": \"poignant\"}, {\"rationales\": \"uplifting\"}, {\"rationales\": \"stunning\"}, {\"rationales\": \"adventure\"}]"}
{"content": "A movie so bad that it quickly enters the pantheon of wreckage that includes Battlefield Earth and Showgirls.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], "response_198": "(b) This review is overall rather negative. The use of phrases like \"so bad\", \"pantheon of wreckage\", \"includes Battlefield Earth and Showgirls\", suggests that the movie being reviewed is poorly received by the critic.", "annotation_request": "Consider the following movie review: A movie so bad that it quickly enters the pantheon of wreckage that includes Battlefield Earth and Showgirls. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_198": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 6762, 1347, 3375, 1137, 1146, 5145, 27801, 1040, 20172, 1033, 1034, 1070, 23061, 1233, 1137, 6300, 14479, 2990, 9367, 1072, 9378, 26172, 29481, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.78125], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"bad\"},\n{\"rationales\": \"wreckage\"},\n{\"rationales\": \"Battlefield Earth\"},\n{\"rationales\": \"Showgirls\"},\n{\"rationales\": \"poorly\"}\n]"}
{"content": "If you're over 25, have an IQ over 90, and have a driver's license, you should be able to find better entertainment.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], "response_199": "(b) This review is overall rather negative. The statement suggests that the movie being reviewed is not suitable for certain demographics, indicating a negative attitude towards the movie.", "annotation_request": "Consider the following movie review: If you're over 25, have an IQ over 90, and have a driver's license, you should be able to find better entertainment. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_199": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1815, 1136, 29510, 1035, 1522, 29473, 29518, 29550, 29493, 1274, 1164, 1083, 29592, 1522, 29473, 29542, 29502, 29493, 1072, 1274, 1032, 7071, 29510, 29481, 7569, 29493, 1136, 1791, 1115, 3126, 1066, 2068, 2641, 15943, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.75], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"over 25\"}, {\"rationales\": \"have an IQ over 90\"}, {\"rationales\": \"have a driver's license\"}, {\"rationales\": \"should be able\"}, {\"rationales\": \"find\"}, {\"rationales\": \"better\"}, {\"rationales\": \"entertainment\"}]\n\nThe words \"should be able\" and \"better entertainment\" are less straightforward as evidence of a negative review, but in the context they can be interpreted as implying that the movie is not good enough for the intended audience.", "rationales_checked": "[{\"rationales\": \"over 25\"}, {\"rationales\": \"have an IQ over 90\"}, {\"rationales\": \"have a driver's license\"}, {\"rationales\": \"not good enough for the intended audience\"}, {\"rationales\": \"find better entertainment\"}, {\"rationales\": \"implying that the movie is not good enough for the intended audience\"}, {\"rationales\": \"implying that the movie is not good for the intended audience\"}]"}
{"content": "It's the funniest American comedy since Graffiti Bridge.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0], "response_200": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: It's the funniest American comedy since Graffiti Bridge. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_200": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1040, 1514, 3791, 1142, 3324, 19755, 2622, 19863, 1264, 9004, 15818, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.390625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"funniest\"}]"}
{"content": "A strangely compelling and brilliantly acted psychological drama.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 1, 1, 0, 0], "response_201": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A strangely compelling and brilliantly acted psychological drama. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_201": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 27195, 1491, 27063, 1072, 15192, 1114, 21152, 19603, 14560, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"compelling\"}, {\"rationales\": \"brilliantly\"}, {\"rationales\": \"psychological drama\"}]"}
{"content": "Often gruelling and heartbreaking to witness, but Seldahl and Wollter's sterling performances raise this far above the level of the usual maudlin disease movie.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_202": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Often gruelling and heartbreaking to witness, but Seldahl and Wollter's sterling performances raise this far above the level of the usual maudlin disease movie. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_202": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 25408, 6848, 4340, 1072, 3799, 26692, 1066, 9917, 29493, 1330, 1086, 5101, 7778, 1072, 1162, 1561, 1128, 29510, 29481, 17817, 2673, 18255, 8002, 1224, 2850, 3515, 1040, 2952, 1070, 1040, 9202, 4896, 1322, 3062, 8798, 6762, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.765625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"gruelling\"}, {\"rationales\": \"heartbreaking\"}, {\"rationales\": \"sterling\"}, {\"rationales\": \"far\"}, {\"rationales\": \"usual\"}]"}
{"content": "This enthralling documentary... is at once playful and haunting, an in-depth portrait of an iconoclastic artist who was fundamentally unknowable even to his closest friends.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_203": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: This enthralling documentary... is at once playful and haunting, an in-depth portrait of an iconoclastic artist who was fundamentally unknowable even to his closest friends. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_203": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 1704, 2944, 21209, 22822, 1869, 1117, 1206, 3095, 1924, 1775, 1072, 4399, 20896, 29493, 1164, 1065, 29501, 12453, 22855, 1070, 1164, 10228, 1170, 29482, 4721, 8093, 1461, 1171, 10444, 1346, 1289, 20494, 1290, 1787, 1066, 1284, 17192, 4050, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.734375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"enthralling\"}, {\"rationales\": \"playful\"}, {\"rationales\": \"iconoclastic\"}, {\"rationales\": \"portrait\"}]"}
{"content": "I didn't laugh at the ongoing efforts of Cube, and his skinny buddy Mike Epps, to make like Laurel and Hardy'n the hood.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_204": "(b) This review is overall rather negative", "annotation_request": "Consider the following movie review: I didn't laugh at the ongoing efforts of Cube, and his skinny buddy Mike Epps, to make like Laurel and Hardy'n the hood. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_204": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1083, 2307, 29510, 29475, 6531, 1206, 1040, 16028, 9048, 1070, 1102, 5044, 29493, 1072, 1284, 5527, 2548, 26891, 10128, 1181, 1355, 29481, 29493, 1066, 1806, 1505, 2468, 1250, 29482, 1072, 10476, 29492, 29510, 29479, 1040, 21992, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"didn't laugh\"},{\"rationales\": \"efforts\"}]"}
{"content": "Ford deserves to be remembered at Oscar time for crafting this wonderful portrait of a conflicted soldier.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], "response_205": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Ford deserves to be remembered at Oscar time for crafting this wonderful portrait of a conflicted soldier. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_205": 1, "relevance_lrp": [15.8828125, 0.001590728759765625, 0.31201171875, 0.06793212890625, 0.2489013671875, -0.06927490234375, 0.047607421875, 0.1590576171875, 0.049713134765625, 0.007843017578125, -0.0022335052490234375, 0.002105712890625, -0.0167694091796875, 0.01541900634765625, -0.007030487060546875, 0.041046142578125, 0.01422119140625, -0.004764556884765625, 0.007686614990234375, -0.0477294921875, -0.0128631591796875, 0.02032470703125, 0.01441192626953125, -0.046356201171875, -0.007293701171875, 0.01314544677734375, 0.009033203125, -0.0274200439453125, -0.1644287109375, 1.24609375, 0.1466064453125, 0.224365234375, 0.1409912109375, 0.10491943359375, 0.11285400390625, 0.388671875, 0.366455078125, 0.055023193359375, 0.061309814453125, 0.14208984375, 0.53857421875, 0.2325439453125, 0.08856201171875, 0.34765625, 0.798828125, 0.39208984375, 0.1727294921875, 0.40478515625, 1.1328125, 2.154296875, 0.2098388671875, 0.0194549560546875, 0.1375732421875, 0.0537109375, 0.0933837890625, 0.0487060546875, 0.2152099609375, 0.136474609375, 0.1241455078125, 0.1612548828125, 0.80126953125, 0.057647705078125, 0.0157470703125, 0.00811004638671875, 0.01332855224609375, 0.0193939208984375, 0.01132965087890625, 0.02435302734375, 0.041534423828125, 0.07958984375, 0.236083984375, 0.25048828125, 0.1964111328125, 0.033782958984375, 2.623046875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 12869, 25753, 1066, 1115, 10984, 1206, 19418, 1495, 1122, 10717, 1056, 1224, 9358, 22855, 1070, 1032, 11086, 1054, 16000, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.40625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"wonderful\"}, {\"rationales\": \"portrait\"}, {\"rationales\": \"conflicted\"}, {\"rationales\": \"soldier\"}]"}
{"content": "A dim-witted and lazy spin-off of the Animal Planet documentary series, Crocodile Hunter is entertainment opportunism at its most glaring.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "response_206": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A dim-witted and lazy spin-off of the Animal Planet documentary series, Crocodile Hunter is entertainment opportunism at its most glaring. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_206": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 4755, 29501, 29495, 4077, 1072, 18666, 8112, 29501, 2537, 1070, 1040, 27492, 9884, 1067, 22822, 4286, 29493, 11240, 19882, 1314, 19244, 1117, 15943, 4815, 2211, 1206, 1639, 1848, 2040, 3070, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.71875], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"dim-witted\"\n},\n{\n\"rationales\": \"lazy\"\n},\n{\n\"rationales\": \" entertainment opportunism\"\n},\n{\n\"rationales\": \"glaring\"\n}\n]"}
{"content": "Methodical, measured, and gently tedious in its comedy, Secret Ballot is a purposefully reductive movie -- which may be why it's so successful at lodging itself in the brain.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "response_207": "(b) This review is overall rather negative", "annotation_request": "Consider the following movie review: Methodical, measured, and gently tedious in its comedy, Secret Ballot is a purposefully reductive movie -- which may be why it's so successful at lodging itself in the brain. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_207": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}
{"content": "One of the most exciting action films to come out of China in recent years.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_208": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: One of the most exciting action films to come out of China in recent years. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_208": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3155, 1070, 1040, 1848, 13304, 3760, 10690, 1066, 2335, 1343, 1070, 5845, 1065, 6159, 2035, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"exciting\"}, {\"rationales\": \"action\"}, {\"rationales\": \"come\"}, {\"rationales\": \"recent\"}]"}
{"content": "Adam Sandler's Eight Crazy Nights grows on you -- like a rash.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1], "response_209": "(b) This review is overall rather negative. The comparison to a rash growing suggests the movie is annoying or irritating, which are typically negative connotations.", "annotation_request": "Consider the following movie review: Adam Sandler's Eight Crazy Nights grows on you -- like a rash. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_209": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 11302, 8280, 2291, 29510, 29481, 24950, 1102, 8621, 1186, 3920, 21150, 1124, 1136, 2707, 1505, 1032, 1176, 1797, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.21875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"grows\"}, {\"rationales\": \"like\"}, {\"rationales\": \"a\"}, {\"rationales\": \"rash\"}, {\"rationales\": \"irritating\"}, {\"rationales\": \"annoying\"}]"}
{"content": "The film feels formulaic, its plot and pacing typical Hollywood war-movie stuff, while the performances elicit more of a sense of deja vu than awe.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], "response_210": "(b) This review is overall rather negative. The words \"formulaic,\" \"typical Hollywood war-movie stuff,\" and \"more of a sense of deja vu than awe\" suggest the reviewer is not impressed or finds the movie predictable or unoriginal.", "annotation_request": "Consider the following movie review: The film feels formulaic, its plot and pacing typical Hollywood war-movie stuff, while the performances elicit more of a sense of deja vu than awe. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_210": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3734, 9083, 12071, 1062, 29493, 1639, 10010, 1072, 1052, 4902, 11610, 14825, 2264, 29501, 29487, 13115, 5473, 29493, 2080, 1040, 18255, 1407, 19142, 1448, 1070, 1032, 4135, 1070, 1108, 3599, 21388, 1589, 1032, 1537, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"formulaic\"},\n{\"rationales\": \"typical\"},\n{\"rationales\": \"Hollywood war-movie\"},\n{\"rationales\": \"deja vu\"},\n{\"rationales\": \"not impressed\"},\n{\"rationales\": \"predictable\"},\n{\"rationales\": \"unoriginal\"},\n{\"rationales\": \"awe\"}\n]"}
{"content": "... pitiful, slapdash disaster.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 1], "response_211": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: ... pitiful, slapdash disaster. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_211": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 12033, 4750, 29493, 1903, 1145, 25685, 18041, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.40625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"pitiful\"]}, {\"rationales\": [\"slapdash\"]}, {\"rationales\": [\"disaster\"]}]"}
{"content": "It's neither as romantic nor as thrilling as it should be.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0], "response_212": "(b) This review is overall rather negative. The phrase \"neither as romantic nor as thrilling as it should be\" suggests that the reviewer expected more in terms of romance and thrill, indicating a disappointment.", "annotation_request": "Consider the following movie review: It's neither as romantic nor as thrilling as it should be. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_212": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 9927, 1158, 17302, 5446, 1158, 7723, 9085, 1158, 1146, 1791, 1115, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.578125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"romantic\"}, {\"rationales\": \"thrilling\"}, {\"rationales\": \"should be\"}, {\"rationales\": \"neither\"}]"}
{"content": "Returning director Rob Minkoff... and screenwriter Bruce Joel Rubin... have done a fine job of updating White's dry wit to a new age.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], "response_213": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Returning director Rob Minkoff... and screenwriter Bruce Joel Rubin... have done a fine job of updating White's dry wit to a new age. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_213": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5339, 1056, 7627, 6544, 1119, 1423, 2537, 1869, 1072, 5689, 12428, 17436, 27127, 12946, 1030, 1869, 1274, 2971, 1032, 5201, 3157, 1070, 26955, 6441, 29510, 29481, 7732, 1043, 1047, 1066, 1032, 1401, 4363, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.859375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"updated\"}, {\"rationales\": \"done a fine job\"}, {\"rationales\": \"newage\"}, {\"rationales\": \"dry wit\"}]"}
{"content": "An awful movie that will only satisfy the most emotionally malleable of filmgoers.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_214": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: An awful movie that will only satisfy the most emotionally malleable of filmgoers. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_214": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 16108, 6762, 1137, 1390, 1633, 16604, 1040, 1848, 27126, 1058, 5272, 1290, 1070, 3734, 2412, 1172, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.390625], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"awful\"]}, {\"rationales\": [\"satisfy\"]}]"}
{"content": "This is an extraordinary film, not least because it is Japanese and yet feels universal.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_215": "(a) This review is overall rather positive because the reviewer uses words like \"extraordinary,\" \"universal\" to describe the film, which suggests the reviewer found it to be exceptional and its themes relatable to a global audience.", "annotation_request": "Consider the following movie review: This is an extraordinary film, not least because it is Japanese and yet feels universal. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_215": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 1117, 1164, 18577, 3734, 29493, 1227, 3197, 1864, 1146, 1117, 8860, 1072, 3551, 9083, 15366, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.484375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"extraordinary\"}, {\"rationales\": \"universal\"}]"}
{"content": "Griffiths proves she's that rare luminary who continually raises the standard of her profession.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1], "response_216": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Griffiths proves she's that rare luminary who continually raises the standard of her profession. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_216": 1, "relevance_lrp": [15.8125, 0.001155853271484375, 0.3056640625, 0.069580078125, 0.2685546875, -0.07012939453125, 0.029541015625, 0.16064453125, -0.0089874267578125, -0.01074981689453125, 0.008819580078125, -0.033721923828125, 0.025177001953125, -0.00798797607421875, -0.0015106201171875, -0.006923675537109375, 0.028778076171875, -0.01132965087890625, -0.01593017578125, 0.012939453125, 0.037689208984375, -0.01020050048828125, -0.027435302734375, -0.0244293212890625, 0.01503753662109375, 0.004398345947265625, 0.022979736328125, -0.0196685791015625, -0.164794921875, 1.2060546875, 0.1365966796875, 0.228759765625, 0.130859375, 0.106689453125, 0.11932373046875, 0.38427734375, 0.380126953125, 0.061126708984375, 0.032867431640625, 0.146240234375, 0.533203125, 0.2371826171875, 0.092529296875, 0.373779296875, 0.791015625, 0.41552734375, 0.1741943359375, 0.4169921875, 1.1591796875, 2.171875, 0.205322265625, 0.01439666748046875, 0.126953125, 0.04278564453125, 0.0810546875, 0.033233642578125, 0.19091796875, 0.1297607421875, 0.12017822265625, 0.1475830078125, 0.7548828125, 0.057952880859375, 0.01253509521484375, 0.005214691162109375, 0.01493072509765625, 0.015106201171875, 0.007251739501953125, 0.013519287109375, 0.040740966796875, 0.0792236328125, 0.23046875, 0.248779296875, 0.1949462890625, 0.0341796875, 2.640625], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 20053, 1140, 29481, 26600, 1398, 29510, 29481, 1137, 10732, 18477, 4007, 1461, 28156, 27489, 1040, 5555, 1070, 1327, 8353, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.140625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"luminary\"}, {\"rationales\": \"continually\"}, {\"rationales\": \"raises\"}, {\"rationales\": \"standard\"}, {\"rationales\": \"profession\"}, {\"rationales\": \"Griffiths\"}, {\"rationales\": \"proves\"}]"}
{"content": "The asylum material is gripping, as are the scenes of Jia with his family.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_217": "(a) This review is overall rather positive. The reviewer indicates that the 'asylum material' and 'scenes of Jia with his family' are 'gripping', suggesting they are engaging or entertaining.", "annotation_request": "Consider the following movie review: The asylum material is gripping, as are the scenes of Jia with his family. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_217": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 1158, 3719, 1151, 4156, 1117, 16622, 8087, 29493, 1158, 1228, 1040, 15148, 1070, 1243, 1283, 1163, 1284, 2773, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.859375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"gripping\"}]"}
{"content": "... by the time it's done with us, Mira Nair's new movie has its audience giddy with the delight of discovery, of having been immersed in a foreign culture only to find that human nature is pretty much the same all over.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_218": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: ... by the time it's done with us, Mira Nair's new movie has its audience giddy with the delight of discovery, of having been immersed in a foreign culture only to find that human nature is pretty much the same all over. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_218": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1254, 1040, 1495, 1146, 29510, 29481, 2971, 1163, 1360, 29493, 1119, 5575, 1186, 1760, 29510, 29481, 1401, 6762, 1427, 1639, 8706, 1087, 3326, 29492, 1163, 1040, 12607, 1070, 15811, 29493, 1070, 3229, 1518, 5261, 1172, 1054, 1065, 1032, 7991, 6447, 1633, 1066, 2068, 1137, 3698, 5503, 1117, 4236, 1956, 1040, 2116, 1312, 1522, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.78125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"giddy\"}, {\"rationales\": \"delight\"}, {\"rationales\": \"discovery\"}, {\"rationales\": \"immersed\"}, {\"rationales\": \"same all over\"}]"}
{"content": "... about as exciting to watch as two last-place basketball teams playing one another on the final day of the season.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], "response_219": "(b) This review is overall rather negative. The analogy of two last-place basketball teams playing each other suggests a lack of excitement or engagement, which are generally negative attributes when applied to a movie or another form of entertainment.", "annotation_request": "Consider the following movie review: ... about as exciting to watch as two last-place basketball teams playing one another on the final day of the season. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_219": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1452, 1158, 13304, 1066, 3822, 1158, 1757, 2200, 29501, 3680, 17150, 7709, 5311, 1392, 2466, 1124, 1040, 2248, 2138, 1070, 1040, 4070, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.84375], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"two last-place basketball teams\"},\n{\"rationales\": \"final day\"},\n{\"rationales\": \"playing one another\"},\n{\"rationales\": \"not exciting\"},\n{\"rationales\": \"watch as\"},\n{\"rationales\": \"two\"},\n{\"rationales\": \"last-place\"}\n]\n\n(Note: the word 'day' might not be entirely indicative of a negative review, but the context implies that the match being described is uncommon and lackluster, so I included it to maintain the list size.)", "rationales_checked": "[\n  {\"rationales\": \"two last-place basketball teams\"},\n  {\"rationales\": \"final day\"},\n  {\"rationales\": \"playing one another\"},\n  {\"rationales\": \"not exciting\"},\n  {\"rationales\": \"watch as\"},\n  {\"rationales\": \"two\"},\n  {\"rationales\": \"last-place\"}\n]"}
{"content": "So young, so smart, such talent, such a wise ***.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 1, 1, 1, 0, 0, 1, 0], "response_220": "(a) This review is overall rather positive. The repeated use of words such as \"young,\" \"smart,\" \"talent,\" and \"wise\" indicates a positive assessment of the individual being reviewed. The presence of multiple positive adjectives, especially when juxtaposed with each other, typically suggests a favorable perspective in a review.", "annotation_request": "Consider the following movie review: So young, so smart, such talent, such a wise ***. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_220": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 2305, 3286, 29493, 1347, 8223, 29493, 2027, 10002, 29493, 2027, 1032, 17214, 1387, 3182, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.109375], "answer": 29476, "seed": 79}, "rationales": "[\n{\"rationales\": \"young\"},\n{\"rationales\": \"smart\"},\n{\"rationales\": \"talent\"},\n{\"rationales\": \"wise\"},\n{\"rationales\": \"such\"}\n]"}
{"content": "The problem is that for the most part, the film is deadly dull.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_221": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: The problem is that for the most part, the film is deadly dull. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_221": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3468, 1117, 1137, 1122, 1040, 1848, 1512, 29493, 1040, 3734, 1117, 24718, 22055, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.046875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"deadly\"}, {\"rationales\": \"dull\"}, {\"rationales\": \"problem\"}]"}
{"content": "An exhilarating experience.", "true_label": 1, "gold_label_rationales": [0, 1, 0], "response_222": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: An exhilarating experience. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_222": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 26880, 3820, 1845, 3427, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.78125], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"exhilarating\"}]"}
{"content": "Remarkably accessible and affecting.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 1], "response_223": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Remarkably accessible and affecting. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_223": 1, "relevance_lrp": [15.4921875, 0.0004515647888183594, 0.309326171875, 0.05950927734375, 0.2489013671875, -0.111572265625, 0.033111572265625, 0.1151123046875, 0.023529052734375, -0.03778076171875, -0.044525146484375, -0.077392578125, 0.0002168416976928711, -0.0271148681640625, 0.0026645660400390625, -0.199951171875, 1.48828125, 0.171142578125, 0.280517578125, 0.1639404296875, 0.10455322265625, 0.1224365234375, 0.41455078125, 0.42822265625, 0.052093505859375, 0.0095977783203125, 0.1375732421875, 0.52197265625, 0.2239990234375, 0.0784912109375, 0.34814453125, 0.7734375, 0.427001953125, 0.170166015625, 0.4013671875, 1.1455078125, 2.08203125, 0.2159423828125, 0.033111572265625, 0.15478515625, 0.037872314453125, 0.10589599609375, 0.0665283203125, 0.2230224609375, 0.1488037109375, 0.1241455078125, 0.1436767578125, 0.76416015625, 0.054962158203125, 0.017333984375, 0.01214599609375, 0.0157623291015625, 0.020904541015625, 0.0104522705078125, 0.028656005859375, 0.0421142578125, 0.080810546875, 0.227783203125, 0.255859375, 0.1934814453125, 0.0340576171875, 2.55859375], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 5329, 1487, 2675, 15262, 1072, 28585, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.90625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"accessible\"}, {\"rationales\": \"affecting\"}, {\"rationales\": \"remarkably\"}]"}
{"content": "Distinctly sub-par... more likely to drown a viewer in boredom than to send any shivers down his spine.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "response_224": "(b) This review is overall rather negative. The reviewer uses language that indicates a lack of enjoyment with the movie, such as \"distinctly sub-par,\" \"drown in boredom,\" and \"send any shivers down his spine\" (indicating a lack of suspense or fear often associated with horror movies). Therefore, the review is most likely overall negative.", "annotation_request": "Consider the following movie review: Distinctly sub-par... more likely to drown a viewer in boredom than to send any shivers down his spine. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_224": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 13211, 6422, 1114, 1851, 29501, 2157, 1869, 1448, 4685, 1066, 1049, 4097, 1032, 2972, 1031, 1065, 20507, 1068, 1589, 1066, 4848, 1475, 1248, 2356, 1828, 1284, 25264, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.0], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"sub-par\"}, {\"rationales\": \"boredom\"}, {\"rationales\": \"shivers\"}]"}
{"content": "Godard's ode to tackling life's wonderment is a rambling and incoherent manifesto about the vagueness of topical excess... In Praise of Love remains a ponderous and pretentious endeavor that's unfocused and tediously exasperating.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1], "response_225": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Godard's ode to tackling life's wonderment is a rambling and incoherent manifesto about the vagueness of topical excess... In Praise of Love remains a ponderous and pretentious endeavor that's unfocused and tediously exasperating. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_225": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3267, 1256, 29510, 29481, 1057, 1218, 1066, 14384, 2673, 2179, 29510, 29481, 4151, 1234, 1117, 1032, 16123, 7125, 1072, 1065, 1883, 22659, 11820, 29477, 1452, 1040, 23963, 9024, 1177, 1070, 2598, 1513, 12222, 1869, 1328, 1135, 9462, 1070, 8249, 8288, 1032, 1052, 10584, 1375, 1072, 10293, 1076, 1693, 23602, 3883, 1137, 29510, 29481, 10845, 3265, 1054, 1072, 1029, 1054, 8758, 1207, 25945, 1845, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.1875], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"rambling\",\n},\n{\n\"rationales\": \"incoherent\",\n},\n{\n\"rationales\": \"manifesto\",\n},\n{\n\"rationales\": \"ponderous\",\n},\n{\n\"rationales\": \"pretentious\",\n},\n{\n\"rationales\": \"unfocused\",\n},\n{\n\"rationales\": \"tediously exasperating\"\n}\n]"}
{"content": "We never truly come to care about the main characters and whether or not they'll wind up together, and Michele's spiritual quest is neither amusing nor dramatic enough to sustain interest.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0], "response_226": "(b) This review is overall rather negative. The use of phrases like \"never truly come to care about,\" \"neither amusing nor dramatic enough,\" and \"neither sustained interest\" indicate a generally unfavorable perspective on the reviewed movie.", "annotation_request": "Consider the following movie review: We never truly come to care about the main characters and whether or not they'll wind up together, and Michele's spiritual quest is neither amusing nor dramatic enough to sustain interest. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_226": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1584, 2252, 8065, 2335, 1066, 2424, 1452, 1040, 2959, 6896, 1072, 3929, 1210, 1227, 1358, 29510, 1352, 6303, 1350, 3321, 29493, 1072, 28659, 1059, 29510, 29481, 11822, 2593, 1117, 9927, 1605, 9289, 5446, 18064, 2834, 1066, 12523, 2913, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.125], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"never truly\"},\n{\"rationales\": \"care about\"},\n{\"rationales\": \"neither amusing\"},\n{\"rationales\": \"neither dramatic enough\"},\n{\"rationales\": \"neither sustained\"},\n{\"rationales\": \"interest\"}\n]"}
{"content": "Most haunting about ``Fence'' is its conclusion, when we hear the ultimate fate of these girls and realize, much to our dismay, that this really did happen.", "true_label": 1, "gold_label_rationales": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_227": "(b) This review is overall rather negative. The phrase \"much to our dismay\" suggests that the reviewer finds the ending unsatisfactory or disappointing, which typically implies a negative overall assessment. Additionally, the use of the word \"haunting\" in the first sentence implies a sense of unease or distress, another indication of a negative sentiment.", "annotation_request": "Consider the following movie review: Most haunting about ``Fence'' is its conclusion, when we hear the ultimate fate of these girls and realize, much to our dismay, that this really did happen. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_227": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}
{"content": "Bogdanovich taps deep into the Hearst mystique, entertainingly reenacting a historic scandal.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], "response_228": "(a) This review is overall rather positive. The phrases \"entertainingly reenacting\" and \"historic scandal\" suggest that the reviewer finds the movie engaging and enjoyable. Furthermore, the use of \"deep into the Hearst mystique\" indicates a level of interest and intrigue towards the subject matter. All these elements suggest a generally positive reaction from the reviewer.", "annotation_request": "Consider the following movie review: Bogdanovich taps deep into the Hearst mystique, entertainingly reenacting a historic scandal. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_228": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 20693, 22793, 1394, 1307, 1029, 2650, 4302, 1546, 1040, 1150, 1412, 1071, 12715, 2419, 29493, 25929, 1114, 1080, 1037, 1340, 1056, 1032, 16567, 29337, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.796875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": [\"entertainingly\"]}, {\"rationales\": [\"historic\"]}]"}
{"content": "Devos and Cassel have tremendous chemistry -- their sexual and romantic tension, while never really vocalized, is palpable.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "response_229": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: Devos and Cassel have tremendous chemistry -- their sexual and romantic tension, while never really vocalized, is palpable. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_229": 1, "relevance_lrp": [16.015625, 0.00250244140625, 0.299072265625, 0.07635498046875, 0.263916015625, -0.025238037109375, 0.143310546875, 0.1671142578125, 0.0286407470703125, 0.0157928466796875, 0.0014390945434570312, -0.0038127899169921875, -0.00441741943359375, 0.0447998046875, 0.02960205078125, -0.034576416015625, 0.0216827392578125, -0.0009918212890625, 0.0191802978515625, 0.002288818359375, -0.01482391357421875, -0.01378631591796875, 0.00156402587890625, 0.0233917236328125, 0.03839111328125, 0.01030731201171875, 0.007190704345703125, 0.0101165771484375, -0.006946563720703125, 0.00824737548828125, 0.0010662078857421875, 0.010009765625, 0.0092315673828125, 0.007335662841796875, -0.1353759765625, 1.0732421875, 0.1285400390625, 0.2403564453125, 0.1392822265625, 0.1087646484375, 0.11053466796875, 0.3779296875, 0.39599609375, 0.0648193359375, -0.0007038116455078125, 0.138916015625, 0.490478515625, 0.2181396484375, 0.08587646484375, 0.355712890625, 0.75927734375, 0.416015625, 0.1744384765625, 0.421142578125, 1.078125, 2.009765625, 0.231689453125, 0.031463623046875, 0.157958984375, 0.046142578125, 0.09466552734375, 0.06939697265625, 0.2498779296875, 0.1297607421875, 0.1268310546875, 0.171142578125, 0.89208984375, 0.056915283203125, 0.0125579833984375, 0.01222991943359375, 0.01195526123046875, 0.0199432373046875, 0.01476287841796875, 0.05511474609375, 0.04180908203125, 0.0753173828125, 0.224365234375, 0.2427978515625, 0.1876220703125, 0.03265380859375, 2.623046875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 7392, 1153, 1072, 14135, 1069, 1274, 24711, 26459, 2707, 1420, 7733, 1072, 17302, 16570, 29493, 2080, 2252, 2296, 19040, 2100, 29493, 1117, 5553, 29488, 1290, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.640625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"chemistry\"}, {\"rationales\": \"palpable\"}, {\"rationales\": \"tremendous\"}]"}
{"content": "As a girl-meets-girl romantic comedy, Kissing Jessica Steinis quirky, charming and often hilarious.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], "response_230": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: As a girl-meets-girl romantic comedy, Kissing Jessica Steinis quirky, charming and often hilarious. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_230": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1904, 1032, 3514, 29501, 1895, 2236, 29501, 26172, 17302, 19755, 29493, 28426, 1056, 24830, 19578, 1046, 1294, 1129, 5613, 29493, 26212, 1072, 3376, 28181, 1693, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.265625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"quirky\"}, {\"rationales\": \"charming\"}]"}
{"content": "Gollum's `performance' is incredible!", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1], "response_231": "(a) This review is overall rather positive because the reviewer mentions that Gollum's performance is \"incredible,\" which is a positive adjective.", "annotation_request": "Consider the following movie review: Gollum's `performance' is incredible! \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_231": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1188, 1561, 1151, 29510, 29481, 2320, 1255, 12546, 29510, 1117, 14746, 29576, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.59375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"incredible\"}]"}
{"content": "... a haunting vision, with images that seem more like disturbing hallucinations.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0], "response_232": "(b) This review is overall rather negative. The use of words like \"haunting,\" \"disturbing,\" and \"hallucinations\" typically indicate a negative or unsettling experience, which is the case here.", "annotation_request": "Consider the following movie review: ... a haunting vision, with images that seem more like disturbing hallucinations. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_232": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4618, 1032, 4399, 20896, 8789, 29493, 1163, 6971, 1137, 2477, 1448, 1505, 17967, 1056, 7992, 2253, 10203, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.78125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"haunting\"}, {\"rationales\": \"disturbing\"}, {\"rationales\": \"hallucinations\"}, {\"rationales\": \"negative\"}]"}
{"content": "As a remake, it's a pale imitation.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 1], "response_233": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: As a remake, it's a pale imitation. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_233": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1904, 1032, 1771, 1389, 29493, 1146, 29510, 29481, 1032, 13573, 1271, 5942, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.328125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"pale\"]}, {\"rationales\": [\"imitation\"]}]"}
{"content": "A generic family comedy unlikely to be appreciated by anyone outside the under-10 set.", "true_label": 0, "gold_label_rationales": [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], "response_234": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A generic family comedy unlikely to be appreciated by anyone outside the under-10 set. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_234": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 13689, 2773, 19755, 16532, 1066, 1115, 23127, 1254, 4405, 4304, 1040, 1684, 29501, 29508, 29502, 1576, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.59375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"generic\"}, {\"rationales\": \"family comedy\"}, {\"rationales\": \"unlikely\"}, {\"rationales\": \"appreciated\"}, {\"rationales\": \"under-10 set\"}]"}
{"content": "This odd, poetic road movie, spiked by jolts of pop music, pretty much takes place in Morton's ever-watchful gaze -- and it's a tribute to the actress, and to her inventive director, that the journey is such a mesmerizing one.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "response_235": "(a) This review is overall rather positive. The adjectives used like \"odd,\" \"poetic,\" \"mesmerizing\" in combination with \"jolts of pop music\" and the compliment to the actress and director indicate that the movie is generally well-received by the reviewer.", "annotation_request": "Consider the following movie review: This odd, poetic road movie, spiked by jolts of pop music, pretty much takes place in Morton's ever-watchful gaze -- and it's a tribute to the actress, and to her inventive director, that the journey is such a mesmerizing one. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_235": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 7707, 29493, 9564, 1062, 4646, 6762, 29493, 1436, 1617, 1054, 1254, 1229, 1096, 1842, 1070, 2620, 4195, 29493, 4236, 1956, 5115, 2401, 1065, 15557, 1034, 29510, 29481, 3038, 29501, 11098, 1775, 13206, 2707, 1072, 1146, 29510, 29481, 1032, 1029, 2751, 1066, 1040, 19102, 29493, 1072, 1066, 1327, 9950, 1263, 7627, 29493, 1137, 1040, 8891, 1117, 2027, 1032, 6740, 1562, 4632, 1392, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.90625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"mesmerizing\"}, {\"rationales\": \"poetic\"}, {\"rationales\": \"well-received\"}]"}
{"content": "Co-writer/director Jonathan Parker's attempts to fashion a Brazil-like, hyper-real satire fall dreadfully short.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], "response_236": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Co-writer/director Jonathan Parker's attempts to fashion a Brazil-like, hyper-real satire fall dreadfully short. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_236": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 3860, 29501, 12428, 29516, 10191, 1039, 17424, 20441, 29510, 29481, 13967, 1066, 9612, 1032, 14018, 29501, 4859, 29493, 12271, 29501, 7255, 3263, 1304, 3717, 18558, 3839, 3253, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.671875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"dreadfully short\"}, {\"rationales\": \"fall short\"}, {\"rationales\": \"hyper-real satire\"}]"}
{"content": "An amateurish, quasi-improvised acting exercise shot on ugly digital video.", "true_label": 0, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 1, 0, 0], "response_237": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: An amateurish, quasi-improvised acting exercise shot on ugly digital video. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_237": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 26588, 1557, 29493, 20107, 29501, 1089, 12719, 3226, 11369, 9863, 5948, 1124, 20047, 7921, 4566, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.671875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"amateurish\"}, {\"rationales\": \"quasi-improvised\"}, {\"rationales\": \"ugly\"}]"}
{"content": "A gratingly unfunny groaner littered with zero-dimensional, unlikable characters and hackneyed, threadbare comic setups.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0], "response_238": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: A gratingly unfunny groaner littered with zero-dimensional, unlikable characters and hackneyed, threadbare comic setups. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_238": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1615, 1845, 1114, 1289, 2523, 2548, 6745, 1044, 1031, 26758, 1054, 1163, 6897, 29501, 14035, 29493, 1289, 5402, 1290, 6896, 1072, 15181, 3473, 1054, 29493, 6195, 29494, 1260, 20375, 1576, 9791, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.28125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"gratingly unfunny\"},{\"rationales\": \"zero-dimensional\"},{\"rationales\": \"unlikable\"},{\"rationales\": \"hackneyed\"}]"}
{"content": "Griffin & Co. manage to be spectacularly outrageous.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 1], "response_239": "(a) This review is overall rather positive. The use of words like \"spectacularly outrageous\" suggests that the reviewer finds the movie or the performance of Griffin & Co. to be impressive and entertainingly bold, often indicative of a positive appraisal.", "annotation_request": "Consider the following movie review: Griffin & Co. manage to be spectacularly outrageous. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_239": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 20053, 1030, 1335, 3860, 29491, 9362, 1066, 1115, 24734, 1114, 27911, 1375, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.84375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"spectacularly\"}, {\"rationales\": \"outrageous\"}]"}
{"content": "A profoundly stupid affair, populating its hackneyed and meanspirited storyline with cardboard characters and performers who value cash above credibility.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1], "response_240": "(b) This review is overall rather negative because the words used such as \"profoundly stupid,\" \"hackneyed,\" \"meanspirited,\" \"cardboard characters,\" and \"performers who value cash above credibility\" all suggest a critical or negative view of the movie in question.", "annotation_request": "Consider the following movie review: A profoundly stupid affair, populating its hackneyed and meanspirited storyline with cardboard characters and performers who value cash above credibility. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_240": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 20095, 1114, 9478, 19947, 29493, 2620, 14390, 1639, 15181, 3473, 1054, 1072, 3593, 29488, 1129, 2113, 3606, 1849, 1163, 4916, 4284, 6896, 1072, 2993, 1172, 1461, 1960, 8645, 3515, 4761, 3800, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.421875], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"profoundly stupid\"},\n{\"rationales\": \"hackneyed\"},\n{\"rationales\": \"meanspirited\"},\n{\"rationales\": \"cardboard characters\"},\n{\"rationales\": \"performers\"},\n{\"rationales\": \"cash\"},\n{\"rationales\": \"valued\"},\n{\"rationales\": \"above\"},\n{\"rationales\": \"credibility\"},\n{\"rationales\": \"storyline\"}\n]"}
{"content": "Warm Water Under a Red Bridge is a quirky and poignant Japanese film that explores the fascinating connections between women, water, nature, and sexuality.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "response_241": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Warm Water Under a Red Bridge is a quirky and poignant Japanese film that explores the fascinating connections between women, water, nature, and sexuality. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_241": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1162, 2553, 9400, 7373, 1032, 4458, 15818, 1117, 1032, 1294, 1129, 5613, 1072, 2395, 1371, 1208, 8860, 3734, 1137, 2717, 4394, 1040, 23837, 13052, 2212, 3293, 29493, 2898, 29493, 5503, 29493, 1072, 7733, 1240, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.65625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"quirky\"}, {\"rationales\": \"poignant\"}, {\"rationales\": \"fascinating\"}, {\"rationales\": \"Japanese\"}, {\"rationales\": \"explores\"}]"}
{"content": "It isn't that Stealing Harvard is a horrible movie -- if only it were that grand a failure!", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_242": "(b) This review is overall rather negative. Despite the use of some irony in the language, the reviewer expresses dissatisfaction with the film, indicating that it is not a successful or good movie.", "annotation_request": "Consider the following movie review: It isn't that Stealing Harvard is a horrible movie -- if only it were that grand a failure! \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_242": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 3925, 29510, 29475, 1137, 3117, 5494, 18321, 1117, 1032, 17594, 6762, 2707, 1281, 1633, 1146, 1422, 1137, 4255, 1032, 8487, 29576, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.359375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"horrible\"}, {\"rationales\": \"failure\"}]"}
{"content": "But the talented cast alone will keep you watching, as will the fight scenes.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_243": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: But the talented cast alone will keep you watching, as will the fight scenes. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_243": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1860, 1040, 22480, 5583, 5179, 1390, 2608, 1136, 7033, 29493, 1158, 1390, 1040, 4760, 15148, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.921875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"talented\"}, {\"rationales\": \"fight scenes\"}]"}
{"content": "It's solid and affecting and exactly as thought-provoking as it should be.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], "response_244": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's solid and affecting and exactly as thought-provoking as it should be. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_244": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 7629, 1072, 28585, 1072, 5436, 1158, 2422, 29501, 12719, 9760, 1158, 1146, 1791, 1115, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.859375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"solid\"},{\"rationales\": \"affecting\"},{\"rationales\": \"thought-provoking\"}]"}
{"content": "Thanks largely to Williams, all the interesting developments are processed in 60 minutes -- the rest is just an overexposed waste of film.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], "response_245": "(b) This review is overall rather negative. The phrase \"all the interesting developments are processed in 60 minutes -- the rest is just an overexposed waste of film,\" implies that the reviewer finds significant portions of the movie unworthy or lacking in quality.", "annotation_request": "Consider the following movie review: Thanks largely to Williams, all the interesting developments are processed in 60 minutes -- the rest is just an overexposed waste of film. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_245": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 9636, 13050, 1066, 11374, 29493, 1312, 1040, 6621, 23078, 1228, 17012, 1065, 29473, 29552, 29502, 4254, 2707, 1040, 2614, 1117, 1544, 1164, 1522, 1488, 5249, 10164, 1070, 3734, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.421875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"waste\"]}, {\"rationales\": [\"overexposed\"]}]"}
{"content": "Cantet perfectly captures the hotel lobbies, two-lane highways, and roadside cafes that permeate Vincent's days", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_246": "(a) This review is overall rather positive because the words used to describe the movie's setting, such as \"perfectly,\" \"two-lane highways,\" and \"roadside cafes,\" are often associated with a sense of authenticity, realism, and an appealing atmosphere. The fact that the days of the character Vincent are permeated by these places suggests that the movie might portray his life in a detailed and engaging manner.", "annotation_request": "Consider the following movie review: Cantet perfectly captures the hotel lobbies, two-lane highways, and roadside cafes that permeate Vincent's days \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_246": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 21984, 1067, 10711, 5054, 2006, 1040, 8457, 1073, 18555, 1265, 29493, 1757, 29501, 25892, 2254, 2272, 29493, 1072, 4646, 2973, 19070, 1042, 1137, 1428, 1895, 1148, 21171, 29510, 29481, 2970, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.921875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"perfectly\"}, {\"rationales\": \"two-lane\"}]"}
{"content": "An important movie, a reminder of the power of film to move us and to make us examine our values.", "true_label": 1, "gold_label_rationales": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_247": "(a) This review is overall rather positive because the reviewer mentions the movie as important, it moves them emotionally, and makes them examine their values, indicating a favorable impression.", "annotation_request": "Consider the following movie review: An important movie, a reminder of the power of film to move us and to make us examine our values. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_247": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 3046, 6762, 29493, 1032, 26331, 1070, 1040, 2750, 1070, 3734, 1066, 3086, 1360, 1072, 1066, 1806, 1360, 18569, 1581, 3837, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.390625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"important\"}, {\"rationales\": \"moves\"}]"}
{"content": "Too much of this well-acted but dangerously slow thriller feels like a preamble to a bigger, more complicated story, one that never materializes.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "response_248": "(b) This review is overall rather negative. The language used such as \"dangerously slow\", \"preamble\", \"never materializes\" suggests a critique of the movie's pace and storyline development.", "annotation_request": "Consider the following movie review: Too much of this well-acted but dangerously slow thriller feels like a preamble to a bigger, more complicated story, one that never materializes. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_248": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 17369, 1956, 1070, 1224, 1930, 29501, 1340, 1054, 1330, 6783, 5787, 4712, 7723, 9646, 9083, 1505, 1032, 1478, 1082, 1750, 1066, 1032, 10710, 29493, 1448, 13908, 3606, 29493, 1392, 1137, 2252, 4156, 5772, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.4375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": [\"dangerously\", \"never\"]}]"}
{"content": "A richly imagined and admirably mature work from a gifted director who definitely has something on his mind.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], "response_249": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A richly imagined and admirably mature work from a gifted director who definitely has something on his mind. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_249": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 7476, 1114, 17203, 1072, 5823, 1129, 2675, 20566, 1539, 1245, 1032, 8643, 1054, 7627, 1461, 7072, 1427, 2313, 1124, 1284, 3041, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.109375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"richly imagined\"}, {\"rationales\": \"admirably mature\"}, {\"rationales\": \"gifted director\"}, {\"rationales\": \"definitely\"}, {\"rationales\": \"something\"}, {\"rationales\": \"on\"}, {\"rationales\": \"his mind\"}]"}
{"content": "The art direction is often exquisite, and the anthropomorphic animal characters are beautifully realized through clever makeup design, leaving one to hope that the eventual DVD release will offer subtitles and the original Italian-language soundtrack.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_250": "(a) This review is overall rather positive", "annotation_request": "Consider the following movie review: The art direction is often exquisite, and the anthropomorphic animal characters are beautifully realized through clever makeup design, leaving one to hope that the eventual DVD release will offer subtitles and the original Italian-language soundtrack. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_250": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 2292, 5775, 1117, 3376, 1207, 11993, 1338, 29493, 1072, 1040, 20787, 2274, 23399, 9295, 6896, 1228, 27856, 7953, 1827, 20113, 20549, 3389, 29493, 7053, 1392, 1066, 4085, 1137, 1040, 2719, 1608, 16598, 6382, 1390, 3173, 1851, 24265, 1635, 1072, 1040, 4261, 10856, 29501, 12672, 3390, 8590, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"exquisite\"}, {\"rationales\": \"beautifully realized\"}, {\"rationales\": \"clever\"}, {\"rationales\": \"hope\"}]"}
{"content": "But what's nice is that there's a casual intelligence that permeates the script.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], "response_251": "(a) This review is overall rather positive. The phrase \"casual intelligence that permeates the script\" suggests that the reviewer finds the language of the movie to be intelligent, but in a casual and accessible way. This implies a positive evaluation.", "annotation_request": "Consider the following movie review: But what's nice is that there's a casual intelligence that permeates the script. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_251": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1860, 1535, 29510, 29481, 5939, 1117, 1137, 1504, 29510, 29481, 1032, 14084, 11663, 1137, 1428, 1895, 1770, 1040, 7535, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.796875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"casual\"}, {\"rationales\": \"intelligence\"}]"}
{"content": "Wedding feels a bit anachronistic.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1], "response_252": "(b) This review is overall rather negative. The use of the word \"anachronistic\" often indicates a sense of something feeling out of place or belonging to the past in contemporary times, which could be interpreted as a criticism in a movie review context.", "annotation_request": "Consider the following movie review: Wedding feels a bit anachronistic. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_252": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 8610, 3970, 9083, 1032, 3054, 1164, 1363, 2457, 4088, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.46875], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"anachronistic\"}]"}
{"content": "An action/thriller of the finest kind, evoking memories of Day of the Jackal, The French Connection, and Heat.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_253": "(a) This review is overall rather positive. The use of comparisons with renowned action/thriller films like Day of the Jackal, The French Connection, and Heat suggests that the reviewed movie is highly praised.", "annotation_request": "Consider the following movie review: An action/thriller of the finest kind, evoking memories of Day of the Jackal, The French Connection, and Heat. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_253": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1862, 3760, 29516, 1130, 29480, 9646, 1070, 1040, 22329, 2880, 29493, 1451, 9760, 13375, 1070, 6167, 1070, 1040, 5067, 1050, 29493, 1183, 5717, 20885, 29493, 1072, 24959, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.921875], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"Day of the Jackal\"},{\"rationales\": \"Heat\"}]"}
{"content": "This picture is murder by numbers, and as easy to be bored by as your ABC's, despite a few whopping shootouts.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_254": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: This picture is murder by numbers, and as easy to be bored by as your ABC's, despite a few whopping shootouts. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_254": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1619, 6522, 1117, 7600, 1254, 6319, 29493, 1072, 1158, 4179, 1066, 1115, 20507, 1254, 1158, 1342, 23441, 29510, 29481, 29493, 8345, 1032, 2432, 1156, 1178, 3685, 6809, 9276, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.203125], "answer": 29494, "seed": 79}, "rationales": "[\n{\n\"rationales\": \"murder by numbers,\"\n},\n{\n\"rationales\": \"bored,\"\n},\n{\n\"rationales\": \"ABC's,\"\n},\n{\n\"rationales\": \"bored,\"\n},\n{\n\"rationales\": \"whopping shootouts,\"\n}\n]"}
{"content": "Every individual will see the movie through the prism of his or her own beliefs and prejudices, but the one thing most will take away is the sense that peace is possible.", "true_label": 1, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], "response_255": "(a) This review is overall rather positive. Despite acknowledging individual subjectivity, the reviewer's positive sentiment towards the movie's central message of promoting peace suggests a generally positive view of the film.", "annotation_request": "Consider the following movie review: Every individual will see the movie through the prism of his or her own beliefs and prejudices, but the one thing most will take away is the sense that peace is possible. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_255": 1, "relevance_lrp": [15.9921875, 0.0032863616943359375, 0.3232421875, 0.0955810546875, 0.2783203125, -0.061492919921875, 0.0755615234375, 0.1678466796875, 0.098388671875, -0.0113067626953125, 0.0251617431640625, 0.00522613525390625, -0.0245819091796875, 0.0033016204833984375, -0.017852783203125, -0.0261688232421875, 0.01036834716796875, 0.00933074951171875, 0.003261566162109375, 0.002231597900390625, 0.00887298583984375, 0.00414276123046875, 0.003742218017578125, -0.00890350341796875, 0.00968170166015625, -0.00543212890625, 0.0035400390625, 0.02435302734375, 0.033233642578125, -0.016632080078125, 0.01165771484375, 0.01318359375, 0.03125, 0.005035400390625, -0.017425537109375, 0.00304412841796875, 0.01509857177734375, -0.0198822021484375, 0.033599853515625, 0.0224761962890625, 0.01715087890625, 0.021697998046875, 0.038421630859375, 0.0032787322998046875, -0.15576171875, 1.2109375, 0.1075439453125, 0.2047119140625, 0.1484375, 0.107421875, 0.1134033203125, 0.384765625, 0.35986328125, 0.06121826171875, 0.00617218017578125, 0.1207275390625, 0.474365234375, 0.2261962890625, 0.0830078125, 0.31884765625, 0.73681640625, 0.381591796875, 0.167236328125, 0.39892578125, 1.056640625, 2.03125, 0.21044921875, 0.01097869873046875, 0.1292724609375, 0.03851318359375, 0.1304931640625, 0.062042236328125, 0.2366943359375, 0.1259765625, 0.12286376953125, 0.1700439453125, 0.85009765625, 0.05517578125, 0.01202392578125, 0.00472259521484375, 0.01073455810546875, 0.0237274169921875, 0.0162200927734375, 0.0350341796875, 0.0421142578125, 0.0679931640625, 0.21630859375, 0.2298583984375, 0.188232421875, 0.032958984375, 2.66796875], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 4971, 4003, 1390, 1800, 1040, 6762, 1827, 1040, 1492, 2211, 1070, 1284, 1210, 1327, 1984, 17183, 1072, 28193, 1982, 29493, 1330, 1040, 1392, 2738, 1848, 1390, 2156, 2521, 1117, 1040, 4135, 1137, 7173, 1117, 3340, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.4375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"possible\"},{\"rationales\": \"peace\"},{\"rationales\": \"positive\"},{\"rationales\": \"sense\"},{\"rationales\": \"most\"}]"}
{"content": "A classy item by a legend who may have nothing left to prove but still has the chops and drive to show how its done.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_256": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: A classy item by a legend who may have nothing left to prove but still has the chops and drive to show how its done. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_256": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1098, 1643, 29492, 3283, 1254, 1032, 13619, 1461, 1761, 1274, 3279, 2517, 1066, 8442, 1330, 2077, 1427, 1040, 1252, 3367, 1072, 5777, 1066, 2115, 1678, 1639, 2971, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.25], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"classy\"}, {\"rationales\": \"legend\"}, {\"rationales\": \"still\"}]"}
{"content": "Starts out mediocre, spirals downward, and thuds to the bottom of the pool with an utterly incompetent conclusion.", "true_label": 0, "gold_label_rationales": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "response_257": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Starts out mediocre, spirals downward, and thuds to the bottom of the pool with an utterly incompetent conclusion. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_257": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 7811, 29481, 1343, 18054, 1170, 1035, 29493, 15420, 1741, 1828, 1818, 29493, 1072, 1074, 1322, 29481, 1066, 1040, 6627, 1070, 1040, 7081, 1163, 1164, 25122, 1065, 27468, 1076, 13654, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.453125], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"mediocre\"}, {\"rationales\": \"spirals\"}, {\"rationales\": \"incompetent\"}]"}
{"content": "The sort of movie that gives tastelessness a bad rap.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 1, 0, 1, 1], "response_258": "(b) This review is overall rather negative. The use of the word \"tastelessness\" with a negative connotation suggests that the movie being reviewed is not well-regarded by the reviewer.", "annotation_request": "Consider the following movie review: The sort of movie that gives tastelessness a bad rap. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_258": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1183, 3895, 1070, 6762, 1137, 5980, 22215, 6967, 2235, 1032, 3375, 5785, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.234375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"tastelessness\"}, {\"rationales\": \"bad\"}, {\"rationales\": \"rap\"}]"}
{"content": "Its engaging simplicity is driven by appealing leads.", "true_label": 1, "gold_label_rationales": [0, 1, 1, 0, 0, 0, 1, 1], "response_259": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: Its engaging simplicity is driven by appealing leads. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_259": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 8035, 20407, 26001, 1117, 12983, 1254, 27936, 9449, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.390625], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"engaging\"}, {\"rationales\": \"appealing\"}, {\"rationales\": \"driven\"}, {\"rationales\": \"leads\"}]"}
{"content": "It's a head-turner -- thoughtfully written, beautifully read and, finally, deeply humanizing.", "true_label": 1, "gold_label_rationales": [0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1], "response_260": "(a) This review is overall rather positive.", "annotation_request": "Consider the following movie review: It's a head-turner -- thoughtfully written, beautifully read and, finally, deeply humanizing. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_260": 1, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1429, 29510, 29481, 1032, 2103, 29501, 1267, 1031, 2707, 2422, 3839, 5009, 29493, 27856, 1988, 1072, 29493, 5019, 29493, 12637, 3698, 4632, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.84375], "answer": 29476, "seed": 79}, "rationales": "[{\"rationales\": \"head-turner\"}, {\"rationales\": \"thoughtfully written\"}, {\"rationales\": \"beautifully read\"}, {\"rationales\": \"deeply humanizing\"}]"}
{"content": "Bray is completely at sea; with nothing but a Savage Garden music video on his resume, he has no clue about making a movie.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], "response_261": "(b) This review is overall rather negative.", "annotation_request": "Consider the following movie review: Bray is completely at sea; with nothing but a Savage Garden music video on his resume, he has no clue about making a movie. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_261": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 1133, 1687, 1117, 5484, 1206, 6931, 29513, 1163, 3279, 1330, 1032, 11978, 1233, 16643, 4195, 4566, 1124, 1284, 18631, 29493, 1168, 1427, 1476, 25281, 1452, 3260, 1032, 6762, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [30.984375], "answer": 29494, "seed": 79}, "rationales": "[{\"rationales\": \"Bray\"}, {\"rationales\": \"no clue\"}, {\"rationales\": \"nothing\"}, {\"rationales\": \"Savage Garden\"}, {\"rationales\": \"at sea\"}]"}
{"content": "Men in Black II achieves ultimate insignificance -- it's the sci-fi comedy spectacle as Whiffle-Ball epic.", "true_label": 0, "gold_label_rationales": [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "response_262": "(b) This review is overall rather negative. The phrases \"ultimate insignificance,\" \"Whiffle-Ball epic,\" and \"sci-fi comedy spectacle\" used in a negative context often imply criticism or dismissal of the movie.", "annotation_request": "Consider the following movie review: Men in Black II achieves ultimate insignificance -- it's the sci-fi comedy spectacle as Whiffle-Ball epic. \nChoose one of the following options and start your answer with the respective letter: \n(a) This review is overall rather positive \n(b) This review is overall rather negative \nAnswer:", "normalized_response_262": 0, "relevance_lrp": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "perturbation": {"E": null, "tokenized_chat_until_answer": [[1, 3, 12540, 1040, 3064, 6762, 4826, 29515, 8438, 1065, 5545, 4485, 5278, 2623, 16614, 2256, 1371, 1689, 1385, 2707, 1146, 29510, 29481, 1040, 1520, 29478, 29501, 8739, 19755, 5971, 8106, 1158, 1711, 3496, 1059, 29501, 29528, 1223, 24533, 29491, 29473, 781, 1977, 13238, 1392, 1070, 1040, 3064, 3645, 1072, 1917, 1342, 5140, 1163, 1040, 18144, 6266, 29515, 29473, 781, 29500, 29476, 29499, 1619, 4826, 1117, 8312, 3978, 6046, 29473, 781, 29500, 29494, 29499, 1619, 4826, 1117, 8312, 3978, 7855, 29473, 781, 3588, 17749, 29515, 4, 1093]], "context_mask": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "test_logit": [31.453125], "answer": 29494, "seed": 79}, "rationales": "[\n{\"rationales\": \"ultimate insignificance\"},\n{\"rationales\": \"Whiffle-Ball epic\"},\n{\"rationales\": \"sci-fi comedy spectacle\"}\n]"}
